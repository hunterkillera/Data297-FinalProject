{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 --- Dovish\\n1 --- Hawkish\\n2 --- Neutral\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "0 --- Dovish\n",
    "1 --- Hawkish\n",
    "2 --- Neutral\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 23:27:09.842696: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the data\n",
    "def preprocess(text):\n",
    "    max_words = 5000\n",
    "    tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    \n",
    "    #convert text to sequences of indices\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "    #padding sequences\n",
    "    max_length = 100\n",
    "    padded_sequence = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "    return np.array(padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/0_7xr4pj1yb9zdvs7vk07dd80000gn/T/ipykernel_4910/2953206703.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combine_training_data = combine_training_data.append(df_5768, ignore_index=True)\n",
      "/var/folders/fr/0_7xr4pj1yb9zdvs7vk07dd80000gn/T/ipykernel_4910/2953206703.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combine_training_data = combine_training_data.append(df_78516, ignore_index=True)\n",
      "/var/folders/fr/0_7xr4pj1yb9zdvs7vk07dd80000gn/T/ipykernel_4910/2953206703.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combine_training_data = combine_training_data.append(df_944601, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#import lab-manual-combine-training data\n",
    "combine_training_data = pd.DataFrame()\n",
    "\n",
    "# Read an Excel file using pandas\n",
    "combine_5768 = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/training_data/lab-manual-combine-train-5768.xlsx'\n",
    "df_5768 = pd.read_excel(combine_5768)\n",
    "\n",
    "combine_training_data = combine_training_data.append(df_5768, ignore_index=True)\n",
    "\n",
    "combine_78516 = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/training_data/lab-manual-combine-train-78516.xlsx'\n",
    "df_78516 = pd.read_excel(combine_78516)\n",
    "combine_training_data = combine_training_data.append(df_78516, ignore_index=True)\n",
    "\n",
    "combine_944601 = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/training_data/lab-manual-combine-train-944601.xlsx'\n",
    "df_944601 = pd.read_excel(combine_944601)\n",
    "combine_training_data = combine_training_data.append(df_944601, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>551</td>\n",
       "      <td>More subtly, my conclusion that the effects on...</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>652</td>\n",
       "      <td>Participants noted that the improved performan...</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>739</td>\n",
       "      <td>Some measures of inflation expectations were d...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>796</td>\n",
       "      <td>The role of the Board vis-à-vis the regional B...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5491</th>\n",
       "      <td>810</td>\n",
       "      <td>The tendency may be natural to allow more flex...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>840</td>\n",
       "      <td>These inferences are supported by some empiric...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>557</td>\n",
       "      <td>Most participants expected that, following the...</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>432</td>\n",
       "      <td>Investor perceptions of a somewhat less accomm...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>567</td>\n",
       "      <td>My colleagues and I are acutely aware that hig...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>530</td>\n",
       "      <td>Moreover, anecdotal evidence suggested that mo...</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                           sentence  year  label\n",
       "5323    551  More subtly, my conclusion that the effects on...  2002      2\n",
       "3276    652  Participants noted that the improved performan...  2011      2\n",
       "730     739  Some measures of inflation expectations were d...  2018      0\n",
       "980     796  The role of the Board vis-à-vis the regional B...  2020      2\n",
       "5491    810  The tendency may be natural to allow more flex...  2021      0\n",
       "72      840  These inferences are supported by some empiric...  2001      2\n",
       "2728    557  Most participants expected that, following the...  2007      2\n",
       "417     432  Investor perceptions of a somewhat less accomm...  2020      0\n",
       "5495    567  My colleagues and I are acutely aware that hig...  2013      1\n",
       "3983    530  Moreover, anecdotal evidence suggested that mo...  2003      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check random sample some data from the combine_training_data\n",
    "combine_training_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the text and label from the combine_training_data\n",
    "X = combine_training_data['sentence']\n",
    "y = combine_training_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    2773\n",
      "0    1504\n",
      "1    1432\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check the label distribution\n",
    "print(combine_training_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 100)\n",
      "(5709,)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/0_7xr4pj1yb9zdvs7vk07dd80000gn/T/ipykernel_4910/709729510.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combine_test_data = combine_test_data.append(df_5768_test, ignore_index=True)\n",
      "/var/folders/fr/0_7xr4pj1yb9zdvs7vk07dd80000gn/T/ipykernel_4910/709729510.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combine_test_data = combine_test_data.append(df_78516_test, ignore_index=True)\n",
      "/var/folders/fr/0_7xr4pj1yb9zdvs7vk07dd80000gn/T/ipykernel_4910/709729510.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combine_test_data = combine_test_data.append(df_944601_test, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#load the test data\n",
    "combine_test_data = pd.DataFrame()\n",
    "\n",
    "# Read an Excel file using pandas\n",
    "combine_5768_test = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/test_data/lab-manual-combine-test-5768.xlsx'\n",
    "df_5768_test = pd.read_excel(combine_5768_test)\n",
    "combine_test_data = combine_test_data.append(df_5768_test, ignore_index=True)\n",
    "\n",
    "combine_78516_test = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/test_data/lab-manual-combine-test-78516.xlsx'\n",
    "df_78516_test = pd.read_excel(combine_78516_test)\n",
    "combine_test_data = combine_test_data.append(df_78516_test, ignore_index=True)\n",
    "\n",
    "combine_944601_test = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/test_data/lab-manual-combine-test-944601.xlsx'\n",
    "df_944601_test = pd.read_excel(combine_944601_test)\n",
    "combine_test_data = combine_test_data.append(df_944601_test, ignore_index=True)\n",
    "\n",
    "X_test = combine_test_data['sentence']\n",
    "y_test = combine_test_data['label']\n",
    "\n",
    "X_test = preprocess(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 100\n",
    "# Build the LSTM model\n",
    "embedding_dim = 50  # Adjust based on your embedding dimension\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(units=64, activation='tanh'))\n",
    "model.add(Dense(units=3, activation='softmax'))  # Assuming 3 classes (dovish, hawkish, neutral)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 30s 25ms/step - loss: 1.0560 - accuracy: 0.4826 - val_loss: 1.0478 - val_accuracy: 0.4965\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 1.0524 - accuracy: 0.4839 - val_loss: 1.0417 - val_accuracy: 0.4974\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 1.0513 - accuracy: 0.4850 - val_loss: 1.0410 - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 1.0487 - accuracy: 0.4854 - val_loss: 1.0422 - val_accuracy: 0.4974\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 1.0479 - accuracy: 0.4852 - val_loss: 1.0431 - val_accuracy: 0.4982\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 33s 29ms/step - loss: 1.0469 - accuracy: 0.4861 - val_loss: 1.0392 - val_accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 1.0450 - accuracy: 0.4857 - val_loss: 1.0403 - val_accuracy: 0.4982\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 1.0444 - accuracy: 0.4861 - val_loss: 1.0378 - val_accuracy: 0.4982\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 1.0514 - accuracy: 0.4837 - val_loss: 1.0389 - val_accuracy: 0.4982\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 30s 26ms/step - loss: 1.0452 - accuracy: 0.4859 - val_loss: 1.0371 - val_accuracy: 0.4982\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.0521 - accuracy: 0.4832\n",
      "Epoch:  10 Batch size:  4 Test loss:  1.0520745515823364 Test accuracy:  0.4831932783126831 F1: 0.6622367012577552\n",
      "Epoch 1/10\n",
      "571/571 [==============================] - 16s 29ms/step - loss: 1.0405 - accuracy: 0.4861 - val_loss: 1.0302 - val_accuracy: 0.4982\n",
      "Epoch 2/10\n",
      "571/571 [==============================] - 17s 29ms/step - loss: 1.0406 - accuracy: 0.4861 - val_loss: 1.0366 - val_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0343 - accuracy: 0.4861 - val_loss: 1.0264 - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0294 - accuracy: 0.4861 - val_loss: 1.0277 - val_accuracy: 0.4982\n",
      "Epoch 5/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0283 - accuracy: 0.4861 - val_loss: 1.0200 - val_accuracy: 0.4982\n",
      "Epoch 6/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0272 - accuracy: 0.4861 - val_loss: 1.0268 - val_accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0237 - accuracy: 0.4865 - val_loss: 1.0209 - val_accuracy: 0.4982\n",
      "Epoch 8/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0308 - accuracy: 0.4861 - val_loss: 1.0259 - val_accuracy: 0.4982\n",
      "Epoch 9/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0264 - accuracy: 0.4861 - val_loss: 1.0271 - val_accuracy: 0.4982\n",
      "Epoch 10/10\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 1.0253 - accuracy: 0.4863 - val_loss: 1.0211 - val_accuracy: 0.4982\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.0552 - accuracy: 0.4839\n",
      "Epoch:  10 Batch size:  8 Test loss:  1.0551776885986328 Test accuracy:  0.4838935434818268 F1: 0.6635088228486402\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 1.0208 - accuracy: 0.4874 - val_loss: 1.0214 - val_accuracy: 0.4991\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 1.0221 - accuracy: 0.4874 - val_loss: 1.0217 - val_accuracy: 0.5018\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 1.0213 - accuracy: 0.4863 - val_loss: 1.0123 - val_accuracy: 0.5009\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 1.0185 - accuracy: 0.4892 - val_loss: 1.0141 - val_accuracy: 0.5026\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 1.0155 - accuracy: 0.4940 - val_loss: 1.0170 - val_accuracy: 0.5009\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.9978 - accuracy: 0.4909 - val_loss: 1.0080 - val_accuracy: 0.5026\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 9s 30ms/step - loss: 0.9178 - accuracy: 0.5684 - val_loss: 0.9082 - val_accuracy: 0.5613\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.8153 - accuracy: 0.6370 - val_loss: 0.8841 - val_accuracy: 0.5823\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.6943 - accuracy: 0.7101 - val_loss: 0.6857 - val_accuracy: 0.7040\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 9s 31ms/step - loss: 0.5458 - accuracy: 0.7900 - val_loss: 0.5391 - val_accuracy: 0.8030\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.6126 - accuracy: 0.3775\n",
      "Epoch:  10 Batch size:  16 Test loss:  1.612636923789978 Test accuracy:  0.37745097279548645 F1: 0.6117231069992668\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.3844 - accuracy: 0.8682 - val_loss: 0.4333 - val_accuracy: 0.8678\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.2819 - accuracy: 0.9129 - val_loss: 0.3937 - val_accuracy: 0.8827\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.2245 - accuracy: 0.9385 - val_loss: 0.3484 - val_accuracy: 0.9046\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.2088 - accuracy: 0.9422 - val_loss: 0.3349 - val_accuracy: 0.9098\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.1666 - accuracy: 0.9558 - val_loss: 0.3576 - val_accuracy: 0.9098\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.1539 - accuracy: 0.9586 - val_loss: 0.3821 - val_accuracy: 0.8940\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.1800 - accuracy: 0.9488 - val_loss: 0.3205 - val_accuracy: 0.9151\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.1533 - accuracy: 0.9606 - val_loss: 0.2979 - val_accuracy: 0.9273\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.1314 - accuracy: 0.9661 - val_loss: 0.2810 - val_accuracy: 0.9308\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.1349 - accuracy: 0.9626 - val_loss: 0.2645 - val_accuracy: 0.9299\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.7555 - accuracy: 0.3725\n",
      "Epoch:  10 Batch size:  32 Test loss:  2.7555367946624756 Test accuracy:  0.37254902720451355 F1: 0.6563583039195784\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 1.0296 - accuracy: 0.5203 - val_loss: 0.8160 - val_accuracy: 0.6462\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 0.7101 - accuracy: 0.7169 - val_loss: 0.6540 - val_accuracy: 0.7566\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 0.5528 - accuracy: 0.7983 - val_loss: 0.5407 - val_accuracy: 0.8074\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 0.5395 - accuracy: 0.8007 - val_loss: 0.6519 - val_accuracy: 0.7417\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 29s 26ms/step - loss: 0.4091 - accuracy: 0.8603 - val_loss: 0.4586 - val_accuracy: 0.8511\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.3195 - accuracy: 0.9017 - val_loss: 0.3768 - val_accuracy: 0.8844\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 0.3139 - accuracy: 0.9021 - val_loss: 0.4323 - val_accuracy: 0.8616\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 32s 28ms/step - loss: 0.3108 - accuracy: 0.9078 - val_loss: 0.4420 - val_accuracy: 0.8608\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 44s 38ms/step - loss: 0.3377 - accuracy: 0.8896 - val_loss: 0.3826 - val_accuracy: 0.8888\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 35s 31ms/step - loss: 0.2851 - accuracy: 0.9135 - val_loss: 0.5374 - val_accuracy: 0.8214\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 36s 32ms/step - loss: 0.2806 - accuracy: 0.9129 - val_loss: 0.4031 - val_accuracy: 0.8800\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 30s 26ms/step - loss: 0.2445 - accuracy: 0.9277 - val_loss: 0.3523 - val_accuracy: 0.9002\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 0.3117 - accuracy: 0.8988 - val_loss: 0.3720 - val_accuracy: 0.8897\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 0.2294 - accuracy: 0.9328 - val_loss: 0.3628 - val_accuracy: 0.8975\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 0.1851 - accuracy: 0.9444 - val_loss: 0.3127 - val_accuracy: 0.9133\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 29s 26ms/step - loss: 0.2036 - accuracy: 0.9383 - val_loss: 0.3146 - val_accuracy: 0.9221\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 0.2109 - accuracy: 0.9380 - val_loss: 0.4026 - val_accuracy: 0.8844\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 29s 25ms/step - loss: 0.2070 - accuracy: 0.9420 - val_loss: 0.3186 - val_accuracy: 0.9037\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 0.1534 - accuracy: 0.9577 - val_loss: 0.2943 - val_accuracy: 0.9221\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 0.1587 - accuracy: 0.9505 - val_loss: 0.3061 - val_accuracy: 0.9203\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.5329 - accuracy: 0.3557\n",
      "Epoch:  20 Batch size:  4 Test loss:  2.532869338989258 Test accuracy:  0.35574230551719666 F1: 0.6238628719367424\n",
      "Epoch 1/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.1170 - accuracy: 0.9658 - val_loss: 0.2530 - val_accuracy: 0.9396\n",
      "Epoch 2/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0754 - accuracy: 0.9772 - val_loss: 0.2452 - val_accuracy: 0.9405\n",
      "Epoch 3/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0795 - accuracy: 0.9759 - val_loss: 0.2637 - val_accuracy: 0.9422\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0809 - accuracy: 0.9735 - val_loss: 0.2829 - val_accuracy: 0.9343\n",
      "Epoch 5/20\n",
      "571/571 [==============================] - 17s 29ms/step - loss: 0.0935 - accuracy: 0.9739 - val_loss: 0.2566 - val_accuracy: 0.9387\n",
      "Epoch 6/20\n",
      "571/571 [==============================] - 270s 474ms/step - loss: 0.1062 - accuracy: 0.9680 - val_loss: 0.2454 - val_accuracy: 0.9413\n",
      "Epoch 7/20\n",
      "571/571 [==============================] - 69s 122ms/step - loss: 0.0970 - accuracy: 0.9702 - val_loss: 0.2467 - val_accuracy: 0.9352\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 48s 84ms/step - loss: 0.0865 - accuracy: 0.9718 - val_loss: 0.2492 - val_accuracy: 0.9396\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 16s 27ms/step - loss: 0.0891 - accuracy: 0.9704 - val_loss: 0.2618 - val_accuracy: 0.9343\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 18s 32ms/step - loss: 0.0807 - accuracy: 0.9746 - val_loss: 0.2644 - val_accuracy: 0.9352\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0897 - accuracy: 0.9722 - val_loss: 0.2718 - val_accuracy: 0.9299\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0985 - accuracy: 0.9702 - val_loss: 0.2483 - val_accuracy: 0.9413\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0892 - accuracy: 0.9737 - val_loss: 0.2610 - val_accuracy: 0.9343\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0939 - accuracy: 0.9711 - val_loss: 0.2327 - val_accuracy: 0.9405\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 16s 29ms/step - loss: 0.0741 - accuracy: 0.9764 - val_loss: 0.2657 - val_accuracy: 0.9378\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0852 - accuracy: 0.9728 - val_loss: 0.2137 - val_accuracy: 0.9431\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0801 - accuracy: 0.9755 - val_loss: 0.2356 - val_accuracy: 0.9422\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0897 - accuracy: 0.9726 - val_loss: 0.2731 - val_accuracy: 0.9238\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0850 - accuracy: 0.9731 - val_loss: 0.2253 - val_accuracy: 0.9457\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0687 - accuracy: 0.9788 - val_loss: 0.2071 - val_accuracy: 0.9448\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 3.0437 - accuracy: 0.3522\n",
      "Epoch:  20 Batch size:  8 Test loss:  3.0437004566192627 Test accuracy:  0.3522408902645111 F1: 0.6314100563143568\n",
      "Epoch 1/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0549 - accuracy: 0.9831 - val_loss: 0.1827 - val_accuracy: 0.9580\n",
      "Epoch 2/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0327 - accuracy: 0.9901 - val_loss: 0.1941 - val_accuracy: 0.9483\n",
      "Epoch 3/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0316 - accuracy: 0.9888 - val_loss: 0.1835 - val_accuracy: 0.9588\n",
      "Epoch 4/20\n",
      "286/286 [==============================] - 8s 27ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.2192 - val_accuracy: 0.9510\n",
      "Epoch 5/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.1820 - val_accuracy: 0.9571\n",
      "Epoch 6/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0357 - accuracy: 0.9875 - val_loss: 0.2187 - val_accuracy: 0.9518\n",
      "Epoch 7/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.2090 - val_accuracy: 0.9536\n",
      "Epoch 8/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0490 - accuracy: 0.9838 - val_loss: 0.1947 - val_accuracy: 0.9501\n",
      "Epoch 9/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.1897 - val_accuracy: 0.9483\n",
      "Epoch 10/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.2420 - val_accuracy: 0.9466\n",
      "Epoch 11/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0468 - accuracy: 0.9827 - val_loss: 0.2325 - val_accuracy: 0.9440\n",
      "Epoch 12/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0523 - accuracy: 0.9840 - val_loss: 0.1983 - val_accuracy: 0.9536\n",
      "Epoch 13/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 0.2146 - val_accuracy: 0.9510\n",
      "Epoch 14/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0383 - accuracy: 0.9869 - val_loss: 0.2080 - val_accuracy: 0.9527\n",
      "Epoch 15/20\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0765 - accuracy: 0.9746 - val_loss: 0.2091 - val_accuracy: 0.9510\n",
      "Epoch 16/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.2214 - val_accuracy: 0.9501\n",
      "Epoch 17/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0502 - accuracy: 0.9827 - val_loss: 0.2133 - val_accuracy: 0.9527\n",
      "Epoch 18/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.2328 - val_accuracy: 0.9501\n",
      "Epoch 19/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.2145 - val_accuracy: 0.9588\n",
      "Epoch 20/20\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0689 - accuracy: 0.9781 - val_loss: 0.2185 - val_accuracy: 0.9510\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.1207 - accuracy: 0.3445\n",
      "Epoch:  20 Batch size:  16 Test loss:  3.1206607818603516 Test accuracy:  0.3445378243923187 F1: 0.6205622237689421\n",
      "Epoch 1/20\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.2078 - val_accuracy: 0.9571\n",
      "Epoch 2/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.2076 - val_accuracy: 0.9588\n",
      "Epoch 3/20\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.2259 - val_accuracy: 0.9562\n",
      "Epoch 4/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.2164 - val_accuracy: 0.9623\n",
      "Epoch 5/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.2166 - val_accuracy: 0.9641\n",
      "Epoch 6/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.2188 - val_accuracy: 0.9667\n",
      "Epoch 7/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.2120 - val_accuracy: 0.9650\n",
      "Epoch 8/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.2396 - val_accuracy: 0.9632\n",
      "Epoch 9/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.2240 - val_accuracy: 0.9632\n",
      "Epoch 10/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.2426 - val_accuracy: 0.9597\n",
      "Epoch 11/20\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.2218 - val_accuracy: 0.9475\n",
      "Epoch 12/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.2292 - val_accuracy: 0.9606\n",
      "Epoch 13/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.2370 - val_accuracy: 0.9562\n",
      "Epoch 14/20\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 0.2324 - val_accuracy: 0.9562\n",
      "Epoch 15/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.2511 - val_accuracy: 0.9492\n",
      "Epoch 16/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.2297 - val_accuracy: 0.9606\n",
      "Epoch 17/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0258 - accuracy: 0.9901 - val_loss: 0.2563 - val_accuracy: 0.9580\n",
      "Epoch 18/20\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.2379 - val_accuracy: 0.9571\n",
      "Epoch 19/20\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.2331 - val_accuracy: 0.9562\n",
      "Epoch 20/20\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0309 - accuracy: 0.9891 - val_loss: 0.2708 - val_accuracy: 0.9518\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.6244 - accuracy: 0.3557\n",
      "Epoch:  20 Batch size:  32 Test loss:  3.6243691444396973 Test accuracy:  0.35574230551719666 F1: 0.6478921264892377\n",
      "Epoch 1/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.2128 - accuracy: 0.9372 - val_loss: 0.3229 - val_accuracy: 0.9037\n",
      "Epoch 2/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.1446 - accuracy: 0.9562 - val_loss: 0.2771 - val_accuracy: 0.9264\n",
      "Epoch 3/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.1091 - accuracy: 0.9676 - val_loss: 0.2159 - val_accuracy: 0.9387\n",
      "Epoch 4/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.0976 - accuracy: 0.9683 - val_loss: 0.2339 - val_accuracy: 0.9335\n",
      "Epoch 5/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.1071 - accuracy: 0.9658 - val_loss: 0.3218 - val_accuracy: 0.9054\n",
      "Epoch 6/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.1484 - accuracy: 0.9549 - val_loss: 0.3755 - val_accuracy: 0.9019\n",
      "Epoch 7/30\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 0.0869 - accuracy: 0.9726 - val_loss: 0.2606 - val_accuracy: 0.9387\n",
      "Epoch 8/30\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 0.0719 - accuracy: 0.9790 - val_loss: 0.2911 - val_accuracy: 0.9186\n",
      "Epoch 9/30\n",
      "1142/1142 [==============================] - 30s 26ms/step - loss: 0.1384 - accuracy: 0.9584 - val_loss: 0.2697 - val_accuracy: 0.9194\n",
      "Epoch 10/30\n",
      "1142/1142 [==============================] - 28s 25ms/step - loss: 0.0830 - accuracy: 0.9737 - val_loss: 0.2180 - val_accuracy: 0.9422\n",
      "Epoch 11/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.0852 - accuracy: 0.9748 - val_loss: 0.2291 - val_accuracy: 0.9396\n",
      "Epoch 12/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0928 - accuracy: 0.9700 - val_loss: 0.2406 - val_accuracy: 0.9413\n",
      "Epoch 13/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.1095 - accuracy: 0.9645 - val_loss: 0.2557 - val_accuracy: 0.9317\n",
      "Epoch 14/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0975 - accuracy: 0.9689 - val_loss: 0.2319 - val_accuracy: 0.9378\n",
      "Epoch 15/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.1286 - accuracy: 0.9597 - val_loss: 0.2438 - val_accuracy: 0.9335\n",
      "Epoch 16/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.1022 - accuracy: 0.9658 - val_loss: 0.2475 - val_accuracy: 0.9326\n",
      "Epoch 17/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.0678 - accuracy: 0.9768 - val_loss: 0.2423 - val_accuracy: 0.9405\n",
      "Epoch 18/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0846 - accuracy: 0.9726 - val_loss: 0.2117 - val_accuracy: 0.9413\n",
      "Epoch 19/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0864 - accuracy: 0.9726 - val_loss: 0.2625 - val_accuracy: 0.9264\n",
      "Epoch 20/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0978 - accuracy: 0.9700 - val_loss: 0.2319 - val_accuracy: 0.9352\n",
      "Epoch 21/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.1161 - accuracy: 0.9619 - val_loss: 0.2721 - val_accuracy: 0.9343\n",
      "Epoch 22/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.1115 - accuracy: 0.9608 - val_loss: 0.2374 - val_accuracy: 0.9335\n",
      "Epoch 23/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0783 - accuracy: 0.9746 - val_loss: 0.1872 - val_accuracy: 0.9536\n",
      "Epoch 24/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.2089 - val_accuracy: 0.9527\n",
      "Epoch 25/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0725 - accuracy: 0.9761 - val_loss: 0.2292 - val_accuracy: 0.9343\n",
      "Epoch 26/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0712 - accuracy: 0.9746 - val_loss: 0.2141 - val_accuracy: 0.9422\n",
      "Epoch 27/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.0860 - accuracy: 0.9707 - val_loss: 0.2212 - val_accuracy: 0.9361\n",
      "Epoch 28/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0691 - accuracy: 0.9777 - val_loss: 0.2133 - val_accuracy: 0.9431\n",
      "Epoch 29/30\n",
      "1142/1142 [==============================] - 27s 24ms/step - loss: 0.0811 - accuracy: 0.9733 - val_loss: 0.2184 - val_accuracy: 0.9510\n",
      "Epoch 30/30\n",
      "1142/1142 [==============================] - 28s 24ms/step - loss: 0.0747 - accuracy: 0.9753 - val_loss: 0.1748 - val_accuracy: 0.9536\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.0226 - accuracy: 0.3263\n",
      "Epoch:  30 Batch size:  4 Test loss:  3.0226268768310547 Test accuracy:  0.3263305425643921 F1: 0.5890642042645334\n",
      "Epoch 1/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0434 - accuracy: 0.9838 - val_loss: 0.1944 - val_accuracy: 0.9536\n",
      "Epoch 2/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0294 - accuracy: 0.9901 - val_loss: 0.2176 - val_accuracy: 0.9562\n",
      "Epoch 3/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.2398 - val_accuracy: 0.9466\n",
      "Epoch 4/30\n",
      "571/571 [==============================] - 30s 52ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.2201 - val_accuracy: 0.9615\n",
      "Epoch 5/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0386 - accuracy: 0.9888 - val_loss: 0.2852 - val_accuracy: 0.9343\n",
      "Epoch 6/30\n",
      "571/571 [==============================] - 16s 27ms/step - loss: 0.0675 - accuracy: 0.9764 - val_loss: 0.1998 - val_accuracy: 0.9580\n",
      "Epoch 7/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0369 - accuracy: 0.9891 - val_loss: 0.2117 - val_accuracy: 0.9588\n",
      "Epoch 8/30\n",
      "571/571 [==============================] - 16s 28ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.2062 - val_accuracy: 0.9571\n",
      "Epoch 9/30\n",
      "571/571 [==============================] - 15s 25ms/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 0.2341 - val_accuracy: 0.9545\n",
      "Epoch 10/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 0.2170 - val_accuracy: 0.9483\n",
      "Epoch 11/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0386 - accuracy: 0.9858 - val_loss: 0.2596 - val_accuracy: 0.9483\n",
      "Epoch 12/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 0.2709 - val_accuracy: 0.9186\n",
      "Epoch 13/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0391 - accuracy: 0.9880 - val_loss: 0.2254 - val_accuracy: 0.9536\n",
      "Epoch 14/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0417 - accuracy: 0.9864 - val_loss: 0.1977 - val_accuracy: 0.9545\n",
      "Epoch 15/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0379 - accuracy: 0.9851 - val_loss: 0.2490 - val_accuracy: 0.9510\n",
      "Epoch 16/30\n",
      "571/571 [==============================] - 14s 24ms/step - loss: 0.0433 - accuracy: 0.9849 - val_loss: 0.2532 - val_accuracy: 0.9457\n",
      "Epoch 17/30\n",
      "571/571 [==============================] - 24s 43ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 0.2397 - val_accuracy: 0.9553\n",
      "Epoch 18/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0421 - accuracy: 0.9862 - val_loss: 0.1883 - val_accuracy: 0.9597\n",
      "Epoch 19/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0418 - accuracy: 0.9864 - val_loss: 0.2538 - val_accuracy: 0.9466\n",
      "Epoch 20/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0393 - accuracy: 0.9888 - val_loss: 0.2430 - val_accuracy: 0.9527\n",
      "Epoch 21/30\n",
      "571/571 [==============================] - 32s 56ms/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.2764 - val_accuracy: 0.9361\n",
      "Epoch 22/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0712 - accuracy: 0.9759 - val_loss: 0.2257 - val_accuracy: 0.9492\n",
      "Epoch 23/30\n",
      "571/571 [==============================] - 14s 25ms/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.2068 - val_accuracy: 0.9571\n",
      "Epoch 24/30\n",
      "571/571 [==============================] - 20s 34ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.2272 - val_accuracy: 0.9475\n",
      "Epoch 25/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0579 - accuracy: 0.9803 - val_loss: 0.1976 - val_accuracy: 0.9562\n",
      "Epoch 26/30\n",
      "571/571 [==============================] - 15s 26ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.1927 - val_accuracy: 0.9641\n",
      "Epoch 27/30\n",
      "571/571 [==============================] - 15s 27ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.2141 - val_accuracy: 0.9597\n",
      "Epoch 28/30\n",
      "571/571 [==============================] - 15s 27ms/step - loss: 0.0368 - accuracy: 0.9888 - val_loss: 0.2151 - val_accuracy: 0.9571\n",
      "Epoch 29/30\n",
      "571/571 [==============================] - 16s 28ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 0.2396 - val_accuracy: 0.9510\n",
      "Epoch 30/30\n",
      "571/571 [==============================] - 16s 29ms/step - loss: 0.0488 - accuracy: 0.9836 - val_loss: 0.2315 - val_accuracy: 0.9536\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.1521 - accuracy: 0.3466\n",
      "Epoch:  30 Batch size:  8 Test loss:  3.152070999145508 Test accuracy:  0.34663864970207214 F1: 0.6245900600918715\n",
      "Epoch 1/30\n",
      "286/286 [==============================] - 9s 30ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.2167 - val_accuracy: 0.9650\n",
      "Epoch 2/30\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.2624 - val_accuracy: 0.9606\n",
      "Epoch 3/30\n",
      "286/286 [==============================] - 9s 30ms/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 0.2027 - val_accuracy: 0.9632\n",
      "Epoch 4/30\n",
      "286/286 [==============================] - 9s 30ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.2093 - val_accuracy: 0.9667\n",
      "Epoch 5/30\n",
      "286/286 [==============================] - 24s 86ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.2082 - val_accuracy: 0.9632\n",
      "Epoch 6/30\n",
      "286/286 [==============================] - 9s 32ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.2275 - val_accuracy: 0.9667\n",
      "Epoch 7/30\n",
      "286/286 [==============================] - 9s 32ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.2331 - val_accuracy: 0.9667\n",
      "Epoch 8/30\n",
      "286/286 [==============================] - 9s 30ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.2164 - val_accuracy: 0.9658\n",
      "Epoch 9/30\n",
      "286/286 [==============================] - 9s 30ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.2292 - val_accuracy: 0.9641\n",
      "Epoch 10/30\n",
      "286/286 [==============================] - 18s 64ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.2393 - val_accuracy: 0.9571\n",
      "Epoch 11/30\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0892 - accuracy: 0.9746 - val_loss: 0.2506 - val_accuracy: 0.9510\n",
      "Epoch 12/30\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0456 - accuracy: 0.9869 - val_loss: 0.2182 - val_accuracy: 0.9562\n",
      "Epoch 13/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.2007 - val_accuracy: 0.9641\n",
      "Epoch 14/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.1918 - val_accuracy: 0.9641\n",
      "Epoch 15/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.2005 - val_accuracy: 0.9658\n",
      "Epoch 16/30\n",
      "286/286 [==============================] - 19s 67ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.2161 - val_accuracy: 0.9632\n",
      "Epoch 17/30\n",
      "286/286 [==============================] - 9s 30ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.2091 - val_accuracy: 0.9641\n",
      "Epoch 18/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.2495 - val_accuracy: 0.9475\n",
      "Epoch 19/30\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0700 - accuracy: 0.9766 - val_loss: 0.2068 - val_accuracy: 0.9597\n",
      "Epoch 20/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.2038 - val_accuracy: 0.9667\n",
      "Epoch 21/30\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.2329 - val_accuracy: 0.9597\n",
      "Epoch 22/30\n",
      "286/286 [==============================] - 22s 76ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.2287 - val_accuracy: 0.9667\n",
      "Epoch 23/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0144 - accuracy: 0.9943 - val_loss: 0.2276 - val_accuracy: 0.9650\n",
      "Epoch 24/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0294 - accuracy: 0.9910 - val_loss: 0.2566 - val_accuracy: 0.9588\n",
      "Epoch 25/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.2318 - val_accuracy: 0.9606\n",
      "Epoch 26/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.2634 - val_accuracy: 0.9422\n",
      "Epoch 27/30\n",
      "286/286 [==============================] - 8s 28ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.2505 - val_accuracy: 0.9571\n",
      "Epoch 28/30\n",
      "286/286 [==============================] - 26s 93ms/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.2382 - val_accuracy: 0.9553\n",
      "Epoch 29/30\n",
      "286/286 [==============================] - 9s 31ms/step - loss: 0.0553 - accuracy: 0.9814 - val_loss: 0.2566 - val_accuracy: 0.9510\n",
      "Epoch 30/30\n",
      "286/286 [==============================] - 8s 29ms/step - loss: 0.0346 - accuracy: 0.9904 - val_loss: 0.2225 - val_accuracy: 0.9615\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.5882 - accuracy: 0.3326\n",
      "Epoch:  30 Batch size:  16 Test loss:  3.5881614685058594 Test accuracy:  0.33263304829597473 F1: 0.6088261355868395\n",
      "Epoch 1/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.2182 - val_accuracy: 0.9615\n",
      "Epoch 2/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.2354 - val_accuracy: 0.9588\n",
      "Epoch 3/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.2276 - val_accuracy: 0.9650\n",
      "Epoch 4/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.2334 - val_accuracy: 0.9623\n",
      "Epoch 5/30\n",
      "143/143 [==============================] - 20s 142ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.2288 - val_accuracy: 0.9632\n",
      "Epoch 6/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.2689 - val_accuracy: 0.9527\n",
      "Epoch 7/30\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.2180 - val_accuracy: 0.9632\n",
      "Epoch 8/30\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.2082 - val_accuracy: 0.9676\n",
      "Epoch 9/30\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.2088 - val_accuracy: 0.9667\n",
      "Epoch 10/30\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.2174 - val_accuracy: 0.9658\n",
      "Epoch 11/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.2250 - val_accuracy: 0.9650\n",
      "Epoch 12/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.2259 - val_accuracy: 0.9615\n",
      "Epoch 13/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0099 - accuracy: 0.9956 - val_loss: 0.2278 - val_accuracy: 0.9641\n",
      "Epoch 14/30\n",
      "143/143 [==============================] - 12s 86ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.2366 - val_accuracy: 0.9650\n",
      "Epoch 15/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.2184 - val_accuracy: 0.9641\n",
      "Epoch 16/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.2067 - val_accuracy: 0.9667\n",
      "Epoch 17/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0104 - accuracy: 0.9950 - val_loss: 0.2171 - val_accuracy: 0.9632\n",
      "Epoch 18/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.2208 - val_accuracy: 0.9641\n",
      "Epoch 19/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0101 - accuracy: 0.9954 - val_loss: 0.2227 - val_accuracy: 0.9623\n",
      "Epoch 20/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0928 - accuracy: 0.9683 - val_loss: 0.2491 - val_accuracy: 0.9396\n",
      "Epoch 21/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0682 - accuracy: 0.9790 - val_loss: 0.1973 - val_accuracy: 0.9588\n",
      "Epoch 22/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.1919 - val_accuracy: 0.9562\n",
      "Epoch 23/30\n",
      "143/143 [==============================] - 18s 129ms/step - loss: 0.0360 - accuracy: 0.9906 - val_loss: 0.1945 - val_accuracy: 0.9658\n",
      "Epoch 24/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.1937 - accuracy: 0.9420 - val_loss: 0.2470 - val_accuracy: 0.9448\n",
      "Epoch 25/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.0746 - accuracy: 0.9790 - val_loss: 0.2055 - val_accuracy: 0.9545\n",
      "Epoch 26/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0517 - accuracy: 0.9866 - val_loss: 0.2058 - val_accuracy: 0.9536\n",
      "Epoch 27/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 0.1922 - val_accuracy: 0.9553\n",
      "Epoch 28/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 0.1935 - val_accuracy: 0.9597\n",
      "Epoch 29/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.1932 - val_accuracy: 0.9588\n",
      "Epoch 30/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.1906 - val_accuracy: 0.9580\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 3.3699 - accuracy: 0.3347\n",
      "Epoch:  30 Batch size:  32 Test loss:  3.3699421882629395 Test accuracy:  0.33473390340805054 F1: 0.6089784234971661\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = [10,20,30]\n",
    "batch_sizes = [4,8,16,32]\n",
    "\n",
    "#create an dictionary to store result\n",
    "result = {}\n",
    "for epoch in epochs:\n",
    "    for batch_size in batch_sizes:\n",
    "        model.fit(X, y, epochs=epoch, batch_size=batch_size, validation_split=0.2)\n",
    "        # Evaluate the model on the test set\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        #print test loss and accuracy with corresponding epoch and batch size\n",
    "        print(\"Epoch: \", epoch, \"Batch size: \", batch_size, \"Test loss: \", loss, \"Test accuracy: \", accuracy,\"F1:\", 2*accuracy*loss/(accuracy+loss))\n",
    "        #store the result in the dictionary\n",
    "        result[(epoch,batch_size)] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result with highest accuracy is:  (10, 8)\n",
      "{(10, 4): 0.4831932783126831, (10, 8): 0.4838935434818268, (10, 16): 0.37745097279548645, (10, 32): 0.37254902720451355, (20, 4): 0.35574230551719666, (20, 8): 0.3522408902645111, (20, 16): 0.3445378243923187, (20, 32): 0.35574230551719666, (30, 4): 0.3263305425643921, (30, 8): 0.34663864970207214, (30, 16): 0.33263304829597473, (30, 32): 0.33473390340805054}\n"
     ]
    }
   ],
   "source": [
    "#print the result with highest accuracy\n",
    "print(\"The result with highest accuracy is: \", max(result, key=result.get))\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml135_env_sp23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
