{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 --- Dovish\\n1 --- Hawkish\\n2 --- Neutral\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "0 --- Dovish\n",
    "1 --- Hawkish\n",
    "2 --- Neutral\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 14:48:30.913404: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sklearn.model_selection as sk\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# Text pre-processing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Modeling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, \\\n",
    "    SpatialDropout1D, Bidirectional\n",
    "import string\n",
    "from string import digits\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lab-manual-combine-training data\n",
    "\n",
    "# Read an Excel file using pandas\n",
    "mm_5768 = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/training_data/lab-manual-mm-split-train-5768.xlsx'\n",
    "df_5768 = pd.read_excel(mm_5768)\n",
    "\n",
    "mm_78516 = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/training_data/lab-manual-mm-split-train-78516.xlsx'\n",
    "df_78516 = pd.read_excel(mm_78516)\n",
    "\n",
    "mm_944601 = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/training_data/lab-manual-mm-split-train-944601.xlsx'\n",
    "df_944601 = pd.read_excel(mm_944601)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/lab-manual-mm-split-test-78516.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fr/0_7xr4pj1yb9zdvs7vk07dd80000gn/T/ipykernel_6305/1495195808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmm_78516_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/lab-manual-mm-split-test-78516.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_78516_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_78516_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmm_944601_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/test_data/lab-manual-mm-split-test-944601.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/lab-manual-mm-split-test-78516.xlsx'"
     ]
    }
   ],
   "source": [
    "# Read an Excel file using pandas\n",
    "mm_5768_test = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/test_data/lab-manual-mm-split-test-5768.xlsx'\n",
    "df_5768_test = pd.read_excel(mm_5768_test)\n",
    "\n",
    "\n",
    "mm_78516_test = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/test_data/lab-manual-mm-split-test-78516.xlsx'\n",
    "df_78516_test = pd.read_excel(mm_78516_test)\n",
    "\n",
    "mm_944601_test = '/Users/simonli/Desktop/data297/fomc-hawkish-dovish-main/training_data/test-and-training/test_data/lab-manual-mm-split-test-944601.xlsx'\n",
    "df_944601_test = pd.read_excel(mm_944601_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(df):\n",
    "    max = 0\n",
    "    for index, row in df.iterrows():  # format sentence for tokenization\n",
    "        sentence = row['sentence'].replace(\",\", \"\").replace(\".\", \" \") \\\n",
    "            .replace(\"—\", \" \").replace(\"â€\", \"\").replace(\"  \", \" \") \\\n",
    "            .replace(\";\", \"\").replace(\"\\n\", \" \").translate(str.maketrans('', '', string.punctuation))\n",
    "        words = word_tokenize(sentence)\n",
    "        if len(words) > max:\n",
    "            max = len(words)\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm(train, test, max_len, seed, epoch_val, b_size):\n",
    "    train, valid = sk.train_test_split(train, train_size=0.8, random_state=seed)\n",
    "\n",
    "    X_train = train['sentence'].tolist()\n",
    "    Y_train = train['label']\n",
    "\n",
    "    X_test = test['sentence'].tolist()\n",
    "    Y_test = test['label']\n",
    "\n",
    "    X_valid = valid['sentence'].tolist()\n",
    "    Y_valid = valid['label']\n",
    "\n",
    "    trunc_type = 'post'\n",
    "    padding_type = 'post'\n",
    "    oov_tok = '<OOV>'  # out of vocabulary token\n",
    "    vocab_size = 2000\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, char_level=False, oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    total_words = len(word_index)\n",
    "\n",
    "    # Padding\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    train_padded = pad_sequences(train_sequences,\n",
    "                                 maxlen=max_len,\n",
    "                                 padding=padding_type,\n",
    "                                 truncating=trunc_type)\n",
    "    test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    test_padded = pad_sequences(test_sequences,\n",
    "                                maxlen=max_len,\n",
    "                                padding=padding_type,\n",
    "                                truncating=trunc_type)\n",
    "    valid_sequences = tokenizer.texts_to_sequences(X_valid)\n",
    "    valid_padded = pad_sequences(valid_sequences,\n",
    "                                 maxlen=max_len,\n",
    "                                 padding=padding_type,\n",
    "                                 truncating=trunc_type)\n",
    "    print('Shape of train tensor: ', train_padded.shape)\n",
    "    print('Shape of test tensor: ', test_padded.shape)\n",
    "    print('Shape of valid tensor: ', valid_padded.shape)\n",
    "        # Define parameter\n",
    "    embedding_dim = 16\n",
    "    batch_size = b_size\n",
    "    epochs = epoch_val\n",
    "\n",
    "    # Define Dense Model Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,\n",
    "                        embedding_dim,\n",
    "                        input_length=max_len,\n",
    "                        mask_zero=True))\n",
    "    model.add(LSTM(4, return_sequences=False)) \n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    history = model.fit(train_padded, Y_train, validation_data=(valid_padded, Y_valid), epochs=epochs, shuffle=True,\n",
    "                        verbose=1, batch_size=batch_size)\n",
    "    res = model.predict(test_padded)\n",
    "    res = res.argmax(axis=-1)\n",
    "    print(res)\n",
    "    cp = skm.classification_report(Y_test.tolist(), res, output_dict=True)\n",
    "\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    test_acc = cp['weighted avg']['f1-score']\n",
    "\n",
    "    return val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "epochs = [10, 20, 30]\n",
    "batch_sizes = [4, 8, 16, 32]\n",
    "\n",
    "res_df = {\"Dataset\": [],\n",
    "          \"Seed\": [],\n",
    "          \"Epoch\": [],\n",
    "          \"Batch-Size\": [],\n",
    "          \"Val-Acc\": [],\n",
    "          \"Test-Acc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 09:34:46.915380: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 4)                 336       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 5s 19ms/step - loss: 1.0942 - accuracy: 0.4199 - val_loss: 1.0930 - val_accuracy: 0.3923\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0827 - accuracy: 0.4530 - val_loss: 1.0898 - val_accuracy: 0.3923\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0569 - accuracy: 0.4669 - val_loss: 1.0835 - val_accuracy: 0.3978\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0154 - accuracy: 0.4641 - val_loss: 1.0711 - val_accuracy: 0.4254\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9729 - accuracy: 0.5221 - val_loss: 1.0801 - val_accuracy: 0.4254\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9539 - accuracy: 0.5580 - val_loss: 1.0632 - val_accuracy: 0.4641\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8738 - accuracy: 0.5870 - val_loss: 1.0600 - val_accuracy: 0.4751\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8621 - accuracy: 0.5773 - val_loss: 1.0714 - val_accuracy: 0.4696\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8224 - accuracy: 0.5994 - val_loss: 1.0910 - val_accuracy: 0.4530\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7936 - accuracy: 0.6326 - val_loss: 1.1053 - val_accuracy: 0.4807\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 1 0 0 1 1 2 1 0 2 1 2 2 1 1 1 1 0 0 1 2 2 0 2 1 0 0 2 1 1 0 0 2 2 2 0 0\n",
      " 1 0 2 2 1 0 0 0 2 1 1 2 0 1 1 2 0 2 0 2 2 0 0 1 0 0 0 1 2 0 0 1 2 0 0 1 1\n",
      " 1 0 1 0 0 2 2 1 0 0 1 0 0 0 0 1 0 1 2 0 1 1 0 1 2 0 1 0 2 2 0 2 2 1 2 2 1\n",
      " 2 1 2 2 2 0 2 1 1 1 1 1 1 1 0 2 1 1 2 0 1 2 2 0 2 0 0 1 1 0 0 2 2 0 0 2 2\n",
      " 0 0 2 0 2 0 2 2 0 2 2 1 0 1 1 2 2 1 0 0 1 1 2 2 2 0 2 0 1 1 0 0 2 0 0 2 2\n",
      " 1 0 1 2 2 0 2 0 1 1 1 0 2 0 2 0 0 0 2 2 1 2 1 0 2 0 0 0 1 2 0 0 2 1 0 0 0\n",
      " 0 1 0 0 2 0 1 0 0 1 0 0 0 2 0 1 0 1 0 1 2 2 1 1 2 0 1 0 1 0 0 2 2 2 0 2 2\n",
      " 0 1 0 2 0 0 2 0 2 2 2 0 0 0 1 2 0 1 0 0 2 1 0 1 2 0 0 2 2 2 1 0 1 0 0 2 1\n",
      " 2 2 2 0 2 0 1 1 1 0 0 1 0 0 0 0 1 0 0 2 2 2 1 0 0 2 2 0 1 2 1 1 0 2 1 2 1\n",
      " 2 2 0 2 2 2 1 0 0 2 0 1 0 2 0 2 2 2 2 0 2 0 1 2 1 2 1 0 0 2 1 2 1 2 2 0 1\n",
      " 2 2 1 1 1 0 2 2 2 0 1 0 0 0 2 0 2 2 0 2 1 2 1 0 0 1 0 0 2 0 0 0 0 1 0 2 2\n",
      " 1 1 0 0 1 1 0 0 0 1 1 0 1 2 1 0 2 1 1 1 2 1 1 2 0 0 1 0 2 2 0 1 0 2 0 0 0\n",
      " 2 2 2 1 0 1 0 0 0 1 1 0 0 2 2 2 1 2 1 0 1 2 0 1 2 0 1 0 1 2 1 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 5s 32ms/step - loss: 1.0947 - accuracy: 0.4102 - val_loss: 1.0948 - val_accuracy: 0.3923\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0870 - accuracy: 0.4323 - val_loss: 1.0918 - val_accuracy: 0.3923\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0795 - accuracy: 0.4268 - val_loss: 1.0911 - val_accuracy: 0.3923\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0636 - accuracy: 0.4530 - val_loss: 1.0873 - val_accuracy: 0.4088\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0318 - accuracy: 0.4862 - val_loss: 1.0836 - val_accuracy: 0.4033\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9559 - accuracy: 0.5345 - val_loss: 1.0684 - val_accuracy: 0.4475\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9137 - accuracy: 0.5801 - val_loss: 1.0754 - val_accuracy: 0.4420\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8478 - accuracy: 0.5815 - val_loss: 1.0874 - val_accuracy: 0.4530\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8142 - accuracy: 0.5981 - val_loss: 1.0958 - val_accuracy: 0.4420\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7837 - accuracy: 0.5884 - val_loss: 1.1281 - val_accuracy: 0.4530\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 0 0 0 0 0 2 2 0 2 0 2 2 2 2 0 0 0 0 2 0 2 0 2 0 2 0 2 0 0 2 0 2 2 2 2 2\n",
      " 2 0 2 2 2 0 0 2 2 0 0 2 0 2 0 2 2 2 0 2 2 0 2 2 0 0 0 2 2 2 2 2 2 2 0 0 2\n",
      " 2 0 2 2 0 2 2 2 0 0 2 0 2 2 0 0 0 2 2 0 0 2 0 0 2 0 0 0 2 2 2 2 2 2 2 2 0\n",
      " 2 0 2 0 2 0 0 2 2 0 2 2 0 0 0 2 2 2 0 0 2 0 0 0 2 0 0 2 2 0 0 2 2 0 2 2 2\n",
      " 2 0 2 2 2 0 2 2 2 2 2 0 0 0 2 2 2 0 0 0 0 2 2 2 2 0 2 0 0 0 0 0 2 0 2 2 2\n",
      " 0 0 0 2 2 0 0 0 0 0 0 0 2 0 0 0 2 2 2 2 0 2 0 0 2 2 0 2 0 2 2 0 2 2 0 2 2\n",
      " 0 2 0 0 2 2 0 2 2 0 0 0 2 2 2 2 0 2 2 2 2 2 0 2 2 0 0 0 0 0 0 2 2 2 0 2 2\n",
      " 0 2 0 2 0 0 2 0 2 2 2 0 0 2 2 2 0 2 0 0 2 2 2 2 2 0 0 2 2 2 0 0 0 2 0 2 2\n",
      " 2 2 0 0 2 0 0 0 0 0 0 2 0 0 0 2 0 0 2 2 0 2 0 0 0 2 2 2 0 2 2 0 0 2 0 2 2\n",
      " 2 2 0 2 2 2 2 0 0 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 0 2\n",
      " 2 2 2 2 0 0 2 2 2 0 0 2 2 2 2 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2\n",
      " 2 0 0 0 0 0 0 0 0 0 0 2 0 2 0 2 2 2 2 0 0 2 2 2 0 0 0 2 2 2 0 0 0 2 0 0 2\n",
      " 2 2 2 0 0 2 0 0 2 2 2 0 0 2 2 2 0 2 0 0 2 2 0 0 2 0 0 2 0 2 2 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 4s 46ms/step - loss: 1.0975 - accuracy: 0.4075 - val_loss: 1.0938 - val_accuracy: 0.3923\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0905 - accuracy: 0.4309 - val_loss: 1.0904 - val_accuracy: 0.3923\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0847 - accuracy: 0.4378 - val_loss: 1.0876 - val_accuracy: 0.3923\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0756 - accuracy: 0.4489 - val_loss: 1.0824 - val_accuracy: 0.3923\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0533 - accuracy: 0.4544 - val_loss: 1.0772 - val_accuracy: 0.4144\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0344 - accuracy: 0.4669 - val_loss: 1.0739 - val_accuracy: 0.4254\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0142 - accuracy: 0.4972 - val_loss: 1.0650 - val_accuracy: 0.4751\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9820 - accuracy: 0.5345 - val_loss: 1.0581 - val_accuracy: 0.4862\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9508 - accuracy: 0.5456 - val_loss: 1.0783 - val_accuracy: 0.4696\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9002 - accuracy: 0.5773 - val_loss: 1.0570 - val_accuracy: 0.4917\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 2 0 0 0 0 2 2 2 2 2 2 2 2 2 1 1 2 0 1 2 2 0 0 2 2 2 2 1 1 0 0 1 2 2 2 2\n",
      " 1 0 2 2 0 0 0 1 1 1 1 2 2 2 0 2 0 2 0 2 2 0 2 1 0 0 2 2 2 2 1 1 2 1 0 1 2\n",
      " 2 2 1 2 0 2 2 1 2 2 1 2 1 2 0 2 0 1 0 1 0 2 0 0 2 0 2 0 2 2 1 2 0 1 2 2 2\n",
      " 2 1 0 0 2 2 0 1 1 2 2 1 2 1 0 2 2 0 0 1 1 0 0 2 0 0 2 0 1 2 0 1 2 0 1 2 2\n",
      " 2 0 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 1 0 0 1 2 2 1 2 0 2 0 0 2 0 0 2 1 0 2 2\n",
      " 2 0 1 2 2 2 2 0 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 0 1 0 1 1 0 2 1 0 2 2\n",
      " 2 1 2 0 0 0 0 2 1 0 0 2 2 1 0 1 2 2 1 1 2 2 2 1 2 0 0 0 1 0 2 0 2 2 2 2 2\n",
      " 0 1 0 2 2 0 2 2 2 2 2 0 0 0 0 2 2 2 2 0 2 1 2 1 1 2 2 2 2 2 1 0 2 2 0 2 1\n",
      " 2 2 2 2 2 0 2 1 1 0 0 1 0 2 1 2 1 0 2 0 2 2 0 2 2 1 2 0 0 2 1 2 0 1 0 2 2\n",
      " 2 2 0 2 2 2 2 0 1 2 2 2 1 2 1 2 2 0 2 1 2 2 1 0 0 2 1 2 2 2 1 2 2 2 2 2 2\n",
      " 2 2 2 2 0 0 1 0 2 2 1 2 2 2 2 0 0 2 2 2 0 0 1 0 2 2 0 0 2 0 0 2 0 2 0 2 2\n",
      " 1 1 2 0 2 1 2 0 2 0 1 2 0 2 2 2 1 1 1 2 2 2 1 2 2 2 0 0 2 2 0 2 2 2 2 0 2\n",
      " 2 2 2 1 1 2 2 2 2 1 1 2 0 2 2 2 1 1 2 0 1 2 2 0 2 0 1 1 2 2 2 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 4s 60ms/step - loss: 1.0970 - accuracy: 0.4130 - val_loss: 1.0955 - val_accuracy: 0.3923\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0919 - accuracy: 0.4213 - val_loss: 1.0922 - val_accuracy: 0.3923\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0848 - accuracy: 0.4268 - val_loss: 1.0893 - val_accuracy: 0.4033\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0729 - accuracy: 0.4641 - val_loss: 1.0861 - val_accuracy: 0.4199\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0564 - accuracy: 0.4779 - val_loss: 1.0809 - val_accuracy: 0.4254\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0329 - accuracy: 0.5055 - val_loss: 1.0776 - val_accuracy: 0.4309\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0192 - accuracy: 0.4945 - val_loss: 1.0745 - val_accuracy: 0.4309\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9734 - accuracy: 0.5414 - val_loss: 1.0674 - val_accuracy: 0.4475\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9453 - accuracy: 0.5387 - val_loss: 1.0699 - val_accuracy: 0.4475\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9165 - accuracy: 0.5262 - val_loss: 1.0721 - val_accuracy: 0.4309\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 2 0 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 0 2 2 2 0 2 2 2 2 2\n",
      " 2 0 2 2 0 2 0 2 2 2 2 2 2 2 0 2 0 2 0 2 2 2 2 2 0 0 0 2 2 2 2 2 2 2 0 2 2\n",
      " 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 2 0 2 0 0 0 0 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 0 2 2 2 0 2 2 2 2 2 2 2 0 2 2 0 2 0 2 2 2 2 2 0 2 2 2 0 0 2 2 0 2 2 2\n",
      " 2 0 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 2 2 0 2 0 0 2 0 0 2 2 0 2 2\n",
      " 2 0 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 2 0 2 0 2 2 2 2 2 0 2 2\n",
      " 2 2 2 0 0 0 0 2 2 0 2 0 0 2 0 2 2 2 0 2 2 2 2 2 2 0 2 0 2 0 2 0 2 2 2 2 2\n",
      " 0 2 0 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 0 2 2\n",
      " 2 2 2 2 2 0 2 2 2 0 0 2 0 0 2 2 2 0 2 2 0 2 2 2 2 2 2 0 2 2 2 0 0 2 2 2 2\n",
      " 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 0 2 2 0 0 2 0 2 2 0 2 0 2 2\n",
      " 2 2 0 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 2\n",
      " 2 2 2 2 0 2 0 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "181/181 [==============================] - 5s 19ms/step - loss: 1.0933 - accuracy: 0.4157 - val_loss: 1.0880 - val_accuracy: 0.3923\n",
      "Epoch 2/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0744 - accuracy: 0.4268 - val_loss: 1.0808 - val_accuracy: 0.3923\n",
      "Epoch 3/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1.0611 - accuracy: 0.4268 - val_loss: 1.0781 - val_accuracy: 0.3923\n",
      "Epoch 4/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0306 - accuracy: 0.4254 - val_loss: 1.0702 - val_accuracy: 0.3923\n",
      "Epoch 5/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9915 - accuracy: 0.4185 - val_loss: 1.0671 - val_accuracy: 0.3923\n",
      "Epoch 6/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9533 - accuracy: 0.4309 - val_loss: 1.0645 - val_accuracy: 0.3923\n",
      "Epoch 7/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9200 - accuracy: 0.5097 - val_loss: 1.0455 - val_accuracy: 0.4199\n",
      "Epoch 8/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9143 - accuracy: 0.5166 - val_loss: 1.0734 - val_accuracy: 0.4033\n",
      "Epoch 9/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8686 - accuracy: 0.5649 - val_loss: 1.0897 - val_accuracy: 0.4144\n",
      "Epoch 10/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8318 - accuracy: 0.5760 - val_loss: 1.1084 - val_accuracy: 0.4144\n",
      "Epoch 11/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7948 - accuracy: 0.5953 - val_loss: 1.1573 - val_accuracy: 0.3867\n",
      "Epoch 12/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8150 - accuracy: 0.5635 - val_loss: 1.0944 - val_accuracy: 0.3867\n",
      "Epoch 13/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8072 - accuracy: 0.5801 - val_loss: 1.1714 - val_accuracy: 0.4420\n",
      "Epoch 14/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7900 - accuracy: 0.5760 - val_loss: 1.1153 - val_accuracy: 0.4033\n",
      "Epoch 15/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7290 - accuracy: 0.6133 - val_loss: 1.2170 - val_accuracy: 0.4033\n",
      "Epoch 16/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7389 - accuracy: 0.5912 - val_loss: 1.2498 - val_accuracy: 0.3757\n",
      "Epoch 17/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7523 - accuracy: 0.5815 - val_loss: 1.3259 - val_accuracy: 0.3481\n",
      "Epoch 18/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6974 - accuracy: 0.6257 - val_loss: 1.2964 - val_accuracy: 0.3867\n",
      "Epoch 19/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6573 - accuracy: 0.6492 - val_loss: 1.3254 - val_accuracy: 0.3812\n",
      "Epoch 20/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6284 - accuracy: 0.6630 - val_loss: 1.3129 - val_accuracy: 0.3867\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 0 1 2 1 1 2 2 0 2 1 2 2 2 0 1 1 2 1 1 1 2 0 2 2 1 2 0 1 0 2 2 2 2 2 1 2\n",
      " 1 2 2 2 1 1 1 2 0 1 1 1 0 0 2 1 2 2 0 2 0 2 1 1 1 0 0 1 2 0 1 2 2 2 0 1 2\n",
      " 1 1 1 2 0 2 2 2 2 2 1 0 1 2 0 0 0 1 2 2 1 1 0 1 2 0 2 0 1 2 2 0 2 1 2 2 1\n",
      " 1 1 2 0 2 1 0 1 1 0 1 1 1 1 0 1 1 0 0 2 1 0 2 2 2 2 1 2 0 2 0 2 2 2 0 2 2\n",
      " 1 0 2 0 2 0 2 2 1 0 0 1 2 1 1 2 2 1 0 0 2 0 0 2 2 1 2 0 2 2 0 0 2 2 1 2 2\n",
      " 0 0 2 0 0 0 0 2 1 1 2 1 1 0 0 0 2 0 0 1 2 2 1 0 2 1 0 1 1 0 2 2 2 1 0 2 0\n",
      " 0 1 2 0 1 0 0 1 1 0 0 2 2 1 0 1 1 2 0 1 0 2 0 1 2 0 1 0 2 0 1 2 2 2 0 0 2\n",
      " 0 0 0 2 2 2 1 2 2 2 2 0 2 1 2 1 2 1 1 2 0 1 2 1 1 1 0 2 1 1 1 0 2 2 0 2 1\n",
      " 2 2 2 0 2 1 2 1 1 0 1 1 2 0 2 0 1 2 0 1 1 2 1 1 2 1 2 0 1 2 1 0 2 2 1 0 2\n",
      " 2 2 0 0 2 2 2 0 1 2 1 0 1 2 0 2 2 2 2 0 0 0 1 2 2 2 1 2 2 2 1 2 2 2 2 2 2\n",
      " 2 2 0 1 2 0 1 1 2 2 1 0 2 0 2 0 2 1 2 2 1 1 0 0 1 1 2 1 1 0 2 0 0 2 0 2 1\n",
      " 1 1 2 0 1 0 2 0 2 1 0 1 2 2 2 2 2 1 1 1 0 2 1 2 0 2 2 2 2 2 2 2 2 2 1 0 2\n",
      " 0 0 2 1 2 1 0 1 0 1 1 2 0 2 2 0 2 1 1 1 1 2 2 0 2 0 2 1 2 2 0 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "91/91 [==============================] - 5s 31ms/step - loss: 1.0936 - accuracy: 0.4157 - val_loss: 1.0919 - val_accuracy: 0.3923\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 1.0778 - accuracy: 0.4213 - val_loss: 1.0802 - val_accuracy: 0.3923\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0424 - accuracy: 0.4254 - val_loss: 1.0590 - val_accuracy: 0.3978\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9861 - accuracy: 0.4765 - val_loss: 1.0357 - val_accuracy: 0.4586\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.9241 - accuracy: 0.4931 - val_loss: 1.0287 - val_accuracy: 0.4641\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.8826 - accuracy: 0.4793 - val_loss: 1.0246 - val_accuracy: 0.4586\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.8523 - accuracy: 0.5124 - val_loss: 1.0512 - val_accuracy: 0.4696\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8265 - accuracy: 0.5580 - val_loss: 1.0626 - val_accuracy: 0.4530\n",
      "Epoch 9/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7880 - accuracy: 0.5829 - val_loss: 1.0672 - val_accuracy: 0.4641\n",
      "Epoch 10/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.7892 - accuracy: 0.5898 - val_loss: 1.0927 - val_accuracy: 0.4807\n",
      "Epoch 11/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.7722 - accuracy: 0.6008 - val_loss: 1.1115 - val_accuracy: 0.4751\n",
      "Epoch 12/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7729 - accuracy: 0.5843 - val_loss: 1.1593 - val_accuracy: 0.4751\n",
      "Epoch 13/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7592 - accuracy: 0.5856 - val_loss: 1.1170 - val_accuracy: 0.4972\n",
      "Epoch 14/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7430 - accuracy: 0.6105 - val_loss: 1.1813 - val_accuracy: 0.4530\n",
      "Epoch 15/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7540 - accuracy: 0.5843 - val_loss: 1.1505 - val_accuracy: 0.4751\n",
      "Epoch 16/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7479 - accuracy: 0.5884 - val_loss: 1.1984 - val_accuracy: 0.4696\n",
      "Epoch 17/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7283 - accuracy: 0.6077 - val_loss: 1.2060 - val_accuracy: 0.4751\n",
      "Epoch 18/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7374 - accuracy: 0.5994 - val_loss: 1.2061 - val_accuracy: 0.4586\n",
      "Epoch 19/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7130 - accuracy: 0.6105 - val_loss: 1.2504 - val_accuracy: 0.4586\n",
      "Epoch 20/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6996 - accuracy: 0.6243 - val_loss: 1.1490 - val_accuracy: 0.4751\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 1 1 1 2 0 2 1 2 2 2 2 2 2 2 1 1 0 1 1 1 2 1 2 0 2 1 2 1 1 1 1 2 2 2 1 1\n",
      " 1 0 2 2 0 1 1 1 2 1 1 2 2 0 1 2 2 2 0 0 2 1 1 2 0 0 2 1 2 1 1 2 2 2 2 1 2\n",
      " 1 2 1 2 0 2 2 2 2 2 1 0 1 2 2 1 1 1 2 1 1 1 2 1 2 2 2 2 1 2 1 2 2 1 2 2 1\n",
      " 1 1 2 0 2 0 2 1 1 1 0 1 0 1 2 0 1 2 1 2 1 2 0 1 2 1 1 1 1 0 1 2 2 2 1 2 2\n",
      " 2 1 2 2 2 2 2 2 1 2 0 2 2 1 1 1 2 2 2 1 0 1 2 2 0 1 2 2 2 2 2 0 2 2 1 2 2\n",
      " 2 0 1 2 2 2 2 1 2 1 1 1 1 1 2 0 1 2 2 2 1 2 1 2 2 1 2 1 0 0 1 2 2 1 1 2 2\n",
      " 1 1 2 0 2 0 2 1 1 1 2 2 2 1 0 1 1 2 0 1 1 2 1 1 2 2 2 2 1 2 1 2 2 2 2 2 2\n",
      " 2 1 0 2 1 2 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 1 1 1 2 1 2 2 0 2 1 0 1 2 0 2 1\n",
      " 2 2 0 1 2 1 2 1 1 0 1 1 2 2 1 2 1 1 1 2 2 2 2 2 2 2 2 2 1 2 1 0 2 2 1 1 2\n",
      " 2 2 2 2 2 2 2 2 1 2 1 1 1 2 1 2 2 2 2 2 2 2 1 1 1 2 1 0 0 2 1 2 2 2 2 1 0\n",
      " 2 2 2 1 2 0 0 2 2 1 1 0 2 2 2 0 2 2 2 2 1 2 1 2 1 1 2 2 1 2 0 2 2 2 1 2 2\n",
      " 1 1 2 0 1 1 2 0 2 1 1 1 1 2 0 1 2 1 1 0 2 2 1 2 2 1 0 2 2 2 2 1 1 2 2 2 2\n",
      " 2 2 2 1 1 0 1 1 1 1 1 2 2 2 2 1 1 2 1 2 0 2 2 1 2 2 1 1 2 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 4s 41ms/step - loss: 1.0956 - accuracy: 0.4033 - val_loss: 1.0943 - val_accuracy: 0.3923\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0914 - accuracy: 0.4240 - val_loss: 1.0918 - val_accuracy: 0.3923\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0854 - accuracy: 0.4268 - val_loss: 1.0888 - val_accuracy: 0.3923\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0778 - accuracy: 0.4268 - val_loss: 1.0863 - val_accuracy: 0.3923\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0684 - accuracy: 0.4323 - val_loss: 1.0834 - val_accuracy: 0.3923\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0526 - accuracy: 0.4448 - val_loss: 1.0756 - val_accuracy: 0.3923\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0349 - accuracy: 0.4613 - val_loss: 1.0759 - val_accuracy: 0.3923\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0185 - accuracy: 0.4959 - val_loss: 1.0683 - val_accuracy: 0.3867\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0083 - accuracy: 0.5041 - val_loss: 1.0717 - val_accuracy: 0.4254\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9596 - accuracy: 0.5414 - val_loss: 1.0646 - val_accuracy: 0.4420\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9590 - accuracy: 0.5843 - val_loss: 1.0595 - val_accuracy: 0.4199\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9143 - accuracy: 0.5773 - val_loss: 1.0512 - val_accuracy: 0.4144\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8910 - accuracy: 0.5981 - val_loss: 1.0496 - val_accuracy: 0.4254\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8846 - accuracy: 0.5925 - val_loss: 1.0427 - val_accuracy: 0.4641\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8270 - accuracy: 0.6160 - val_loss: 1.0378 - val_accuracy: 0.4641\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7788 - accuracy: 0.6616 - val_loss: 1.0619 - val_accuracy: 0.4696\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7722 - accuracy: 0.6782 - val_loss: 1.0834 - val_accuracy: 0.5028\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7586 - accuracy: 0.6685 - val_loss: 1.0591 - val_accuracy: 0.4917\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7085 - accuracy: 0.6906 - val_loss: 1.0631 - val_accuracy: 0.5028\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7176 - accuracy: 0.6713 - val_loss: 1.0601 - val_accuracy: 0.5193\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 1 1 2 1 1 2 2 0 2 2 2 1 2 0 2 1 2 2 1 2 2 2 0 1 2 0 2 1 2 0 1 2 2 2 1 2\n",
      " 1 2 2 1 2 2 2 1 0 1 1 2 2 1 1 2 0 2 0 2 2 1 2 1 2 0 2 2 2 2 1 2 2 2 0 1 2\n",
      " 1 2 1 2 0 2 0 0 2 2 1 2 1 2 2 2 0 1 2 2 1 1 0 0 2 2 2 1 1 2 1 2 2 1 2 2 2\n",
      " 1 1 2 2 2 1 0 1 1 2 2 2 2 1 0 2 1 2 1 1 1 2 2 2 2 0 1 1 1 2 2 2 2 1 0 2 2\n",
      " 2 0 2 2 2 2 2 0 1 2 2 2 1 1 1 1 2 2 0 0 1 1 2 1 2 2 2 2 2 2 1 2 2 2 0 2 2\n",
      " 2 0 2 0 2 2 2 2 1 1 1 1 2 2 2 0 1 2 2 2 2 2 1 0 2 1 0 1 0 2 1 2 2 1 0 2 2\n",
      " 1 1 2 0 0 0 0 2 1 0 2 2 0 1 2 1 2 2 2 1 2 2 1 1 2 0 2 2 1 0 2 0 2 2 2 2 2\n",
      " 0 2 0 2 1 2 2 1 2 2 2 0 2 1 2 1 2 2 2 0 2 1 2 2 2 1 2 2 1 2 1 0 1 2 0 2 1\n",
      " 2 2 1 2 2 1 2 1 1 1 1 1 0 0 1 2 1 1 1 2 2 2 1 2 2 2 2 2 1 2 1 0 0 2 2 0 2\n",
      " 2 2 0 2 2 2 2 0 2 2 2 0 1 2 1 2 2 2 2 1 2 2 1 1 1 2 1 2 2 2 1 2 2 2 2 1 1\n",
      " 2 2 2 1 1 0 2 0 2 2 1 2 0 2 2 0 2 2 2 2 1 2 1 0 2 2 2 0 2 0 1 2 0 2 0 2 2\n",
      " 1 1 2 2 2 2 2 2 0 1 0 1 1 2 2 1 2 1 1 1 0 1 1 2 2 2 2 2 2 2 2 1 2 2 2 0 2\n",
      " 0 2 2 1 0 2 0 2 2 1 1 2 0 2 2 2 1 2 2 0 1 2 2 2 2 0 1 1 1 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 4s 60ms/step - loss: 1.0969 - accuracy: 0.3923 - val_loss: 1.0945 - val_accuracy: 0.3923\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0857 - accuracy: 0.4254 - val_loss: 1.0906 - val_accuracy: 0.3923\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0781 - accuracy: 0.4268 - val_loss: 1.0891 - val_accuracy: 0.3923\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0535 - accuracy: 0.4268 - val_loss: 1.0876 - val_accuracy: 0.3923\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0252 - accuracy: 0.4268 - val_loss: 1.0836 - val_accuracy: 0.3923\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0035 - accuracy: 0.4268 - val_loss: 1.0661 - val_accuracy: 0.3923\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9464 - accuracy: 0.4268 - val_loss: 1.0450 - val_accuracy: 0.3923\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8904 - accuracy: 0.4268 - val_loss: 1.0414 - val_accuracy: 0.3923\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8487 - accuracy: 0.4378 - val_loss: 1.0498 - val_accuracy: 0.4199\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8393 - accuracy: 0.5981 - val_loss: 1.0722 - val_accuracy: 0.3867\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8039 - accuracy: 0.6064 - val_loss: 1.1706 - val_accuracy: 0.4254\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7632 - accuracy: 0.6229 - val_loss: 1.0899 - val_accuracy: 0.4309\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7466 - accuracy: 0.6340 - val_loss: 1.1236 - val_accuracy: 0.4530\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7319 - accuracy: 0.6340 - val_loss: 1.1938 - val_accuracy: 0.4586\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7296 - accuracy: 0.6285 - val_loss: 1.2479 - val_accuracy: 0.4475\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7155 - accuracy: 0.6367 - val_loss: 1.2848 - val_accuracy: 0.4530\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7199 - accuracy: 0.6312 - val_loss: 1.4360 - val_accuracy: 0.4475\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7052 - accuracy: 0.6367 - val_loss: 1.2263 - val_accuracy: 0.4475\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6825 - accuracy: 0.6561 - val_loss: 1.4164 - val_accuracy: 0.4530\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6983 - accuracy: 0.6367 - val_loss: 1.2242 - val_accuracy: 0.4420\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 2 2 2 0 0\n",
      " 0 0 2 2 0 0 0 0 2 0 0 2 0 0 0 2 2 2 0 2 2 0 0 2 0 0 2 0 2 0 0 2 0 0 0 0 0\n",
      " 0 2 0 0 0 2 2 0 2 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 2 0 2 2 0 2 2 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 2\n",
      " 0 0 2 2 2 0 2 2 0 2 2 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 2 2\n",
      " 0 0 0 2 2 2 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 2 2\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 2 2\n",
      " 0 0 0 2 0 0 0 0 2 2 2 0 0 0 0 2 0 2 0 0 2 0 0 2 2 0 0 2 2 2 0 0 0 2 0 2 0\n",
      " 2 2 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0 0 0 0 2 2 0 2 0 0 0 2 0 2 2\n",
      " 2 0 0 2 2 2 0 0 0 2 0 0 0 2 0 2 2 0 2 2 2 0 0 0 0 2 0 0 0 2 0 2 2 2 2 0 0\n",
      " 2 2 0 0 0 0 0 0 2 0 0 2 2 2 2 0 0 2 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2\n",
      " 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 2 0 0 0 2 0 2 0 0 0 2 0 0 0\n",
      " 2 2 2 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 0 0 2 0 0 2 0 0 0 0 2 0 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "181/181 [==============================] - 5s 19ms/step - loss: 1.0955 - accuracy: 0.4088 - val_loss: 1.0937 - val_accuracy: 0.3923\n",
      "Epoch 2/30\n",
      "181/181 [==============================] - 4s 22ms/step - loss: 1.0857 - accuracy: 0.4461 - val_loss: 1.0904 - val_accuracy: 0.3812\n",
      "Epoch 3/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1.0732 - accuracy: 0.4448 - val_loss: 1.0811 - val_accuracy: 0.3923\n",
      "Epoch 4/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1.0507 - accuracy: 0.4765 - val_loss: 1.0741 - val_accuracy: 0.3923\n",
      "Epoch 5/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1.0106 - accuracy: 0.5028 - val_loss: 1.0677 - val_accuracy: 0.3923\n",
      "Epoch 6/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.9859 - accuracy: 0.5387 - val_loss: 1.0577 - val_accuracy: 0.4475\n",
      "Epoch 7/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.9740 - accuracy: 0.5359 - val_loss: 1.0525 - val_accuracy: 0.4641\n",
      "Epoch 8/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.9229 - accuracy: 0.5497 - val_loss: 1.0650 - val_accuracy: 0.4365\n",
      "Epoch 9/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8935 - accuracy: 0.5635 - val_loss: 1.0559 - val_accuracy: 0.4420\n",
      "Epoch 10/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8761 - accuracy: 0.5649 - val_loss: 1.0906 - val_accuracy: 0.4530\n",
      "Epoch 11/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8528 - accuracy: 0.5953 - val_loss: 1.0534 - val_accuracy: 0.4972\n",
      "Epoch 12/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8094 - accuracy: 0.6285 - val_loss: 1.0870 - val_accuracy: 0.4807\n",
      "Epoch 13/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8311 - accuracy: 0.5994 - val_loss: 1.1695 - val_accuracy: 0.4586\n",
      "Epoch 14/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7873 - accuracy: 0.6271 - val_loss: 1.1705 - val_accuracy: 0.4696\n",
      "Epoch 15/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7843 - accuracy: 0.6340 - val_loss: 1.1767 - val_accuracy: 0.4696\n",
      "Epoch 16/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7782 - accuracy: 0.6271 - val_loss: 1.1513 - val_accuracy: 0.5193\n",
      "Epoch 17/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7571 - accuracy: 0.6367 - val_loss: 1.2986 - val_accuracy: 0.4751\n",
      "Epoch 18/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7264 - accuracy: 0.6616 - val_loss: 1.2563 - val_accuracy: 0.4696\n",
      "Epoch 19/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7435 - accuracy: 0.6423 - val_loss: 1.4261 - val_accuracy: 0.4641\n",
      "Epoch 20/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7335 - accuracy: 0.6713 - val_loss: 1.4186 - val_accuracy: 0.4420\n",
      "Epoch 21/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6990 - accuracy: 0.6740 - val_loss: 1.3115 - val_accuracy: 0.4641\n",
      "Epoch 22/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6876 - accuracy: 0.6837 - val_loss: 1.4335 - val_accuracy: 0.4807\n",
      "Epoch 23/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7303 - accuracy: 0.6506 - val_loss: 1.3520 - val_accuracy: 0.5249\n",
      "Epoch 24/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7026 - accuracy: 0.6575 - val_loss: 1.4807 - val_accuracy: 0.4972\n",
      "Epoch 25/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6915 - accuracy: 0.6878 - val_loss: 1.3731 - val_accuracy: 0.5414\n",
      "Epoch 26/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6500 - accuracy: 0.7003 - val_loss: 1.4718 - val_accuracy: 0.4972\n",
      "Epoch 27/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6583 - accuracy: 0.7058 - val_loss: 1.5212 - val_accuracy: 0.5028\n",
      "Epoch 28/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6552 - accuracy: 0.6851 - val_loss: 1.4828 - val_accuracy: 0.5359\n",
      "Epoch 29/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.5954 - accuracy: 0.7348 - val_loss: 1.5079 - val_accuracy: 0.5249\n",
      "Epoch 30/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6296 - accuracy: 0.7086 - val_loss: 1.3769 - val_accuracy: 0.5028\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 0 0 1 0 1 2 2 0 2 1 2 2 1 0 1 2 0 0 1 2 2 0 2 1 0 2 2 1 1 2 2 2 2 2 1 2\n",
      " 1 0 2 1 1 1 0 1 2 2 1 2 0 1 0 2 2 2 0 2 2 1 1 0 0 0 2 2 2 2 1 1 2 0 0 1 0\n",
      " 1 0 1 2 0 2 2 2 2 2 1 0 1 2 0 0 0 1 2 2 0 1 0 0 2 2 2 0 2 2 1 2 2 1 2 2 0\n",
      " 2 1 2 2 2 1 0 1 1 0 2 1 0 1 0 2 1 2 2 1 1 2 2 0 2 0 0 2 1 0 0 2 2 1 1 2 2\n",
      " 2 0 2 2 2 2 2 2 1 2 2 1 0 1 1 1 2 2 0 0 1 1 2 2 2 1 2 0 0 2 0 0 2 2 2 2 2\n",
      " 2 2 1 1 2 2 2 0 2 1 1 1 2 0 1 2 2 0 2 2 2 2 1 2 2 1 0 1 0 2 2 0 2 1 0 2 2\n",
      " 1 1 0 0 2 0 0 1 1 0 0 0 2 1 1 1 0 0 2 1 2 2 2 1 2 0 2 2 1 1 0 2 2 2 0 2 2\n",
      " 0 2 0 2 1 0 2 0 2 2 2 0 2 1 2 2 0 2 2 0 2 1 2 2 2 1 2 2 2 2 0 0 2 2 0 2 1\n",
      " 2 2 1 2 2 0 2 1 1 0 0 1 0 0 0 2 1 2 1 2 2 2 1 0 2 2 2 2 1 2 1 0 0 2 2 2 1\n",
      " 2 2 0 2 2 2 2 0 0 2 1 2 1 2 1 2 2 2 0 2 2 2 1 2 2 2 1 1 2 2 1 2 2 2 2 1 2\n",
      " 2 2 2 2 2 0 2 2 2 2 1 1 2 2 2 0 0 0 2 2 1 2 1 0 0 0 0 0 2 0 1 0 0 2 0 2 2\n",
      " 1 1 1 0 1 0 2 0 2 1 1 1 1 2 2 2 2 0 1 2 0 2 1 2 0 2 2 0 2 2 0 1 0 2 0 0 0\n",
      " 2 2 2 0 1 2 2 0 2 1 1 0 0 2 2 2 2 2 2 0 2 2 1 0 2 0 1 1 0 2 0 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "91/91 [==============================] - 5s 31ms/step - loss: 1.0934 - accuracy: 0.4171 - val_loss: 1.0916 - val_accuracy: 0.3923\n",
      "Epoch 2/30\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 1.0846 - accuracy: 0.4296 - val_loss: 1.0874 - val_accuracy: 0.3923\n",
      "Epoch 3/30\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 1.0686 - accuracy: 0.4517 - val_loss: 1.0800 - val_accuracy: 0.3923\n",
      "Epoch 4/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0275 - accuracy: 0.4613 - val_loss: 1.0590 - val_accuracy: 0.4144\n",
      "Epoch 5/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9620 - accuracy: 0.4710 - val_loss: 1.0317 - val_accuracy: 0.4641\n",
      "Epoch 6/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9024 - accuracy: 0.4890 - val_loss: 1.0306 - val_accuracy: 0.4309\n",
      "Epoch 7/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8847 - accuracy: 0.5110 - val_loss: 1.0166 - val_accuracy: 0.4365\n",
      "Epoch 8/30\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.8404 - accuracy: 0.5359 - val_loss: 1.0177 - val_accuracy: 0.4309\n",
      "Epoch 9/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8109 - accuracy: 0.5470 - val_loss: 1.0198 - val_accuracy: 0.4530\n",
      "Epoch 10/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7982 - accuracy: 0.5525 - val_loss: 1.0172 - val_accuracy: 0.4751\n",
      "Epoch 11/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7610 - accuracy: 0.5442 - val_loss: 1.0053 - val_accuracy: 0.4696\n",
      "Epoch 12/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7448 - accuracy: 0.5235 - val_loss: 1.0471 - val_accuracy: 0.4972\n",
      "Epoch 13/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7462 - accuracy: 0.5235 - val_loss: 1.0398 - val_accuracy: 0.4972\n",
      "Epoch 14/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7230 - accuracy: 0.5331 - val_loss: 1.0289 - val_accuracy: 0.4972\n",
      "Epoch 15/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6851 - accuracy: 0.5939 - val_loss: 1.0369 - val_accuracy: 0.5083\n",
      "Epoch 16/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7069 - accuracy: 0.5442 - val_loss: 1.0365 - val_accuracy: 0.5028\n",
      "Epoch 17/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6839 - accuracy: 0.6215 - val_loss: 1.0523 - val_accuracy: 0.4972\n",
      "Epoch 18/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6818 - accuracy: 0.6381 - val_loss: 1.1526 - val_accuracy: 0.4972\n",
      "Epoch 19/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6636 - accuracy: 0.6395 - val_loss: 1.0895 - val_accuracy: 0.4972\n",
      "Epoch 20/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6498 - accuracy: 0.6298 - val_loss: 1.1552 - val_accuracy: 0.4862\n",
      "Epoch 21/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6589 - accuracy: 0.6174 - val_loss: 1.1356 - val_accuracy: 0.5249\n",
      "Epoch 22/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6516 - accuracy: 0.6354 - val_loss: 1.1106 - val_accuracy: 0.5083\n",
      "Epoch 23/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6398 - accuracy: 0.6478 - val_loss: 1.1709 - val_accuracy: 0.5083\n",
      "Epoch 24/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6419 - accuracy: 0.6381 - val_loss: 1.2891 - val_accuracy: 0.5304\n",
      "Epoch 25/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6182 - accuracy: 0.6823 - val_loss: 1.2241 - val_accuracy: 0.5359\n",
      "Epoch 26/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6087 - accuracy: 0.6865 - val_loss: 1.1886 - val_accuracy: 0.5028\n",
      "Epoch 27/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.5975 - accuracy: 0.6892 - val_loss: 1.2959 - val_accuracy: 0.5249\n",
      "Epoch 28/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.5986 - accuracy: 0.6961 - val_loss: 1.3418 - val_accuracy: 0.5304\n",
      "Epoch 29/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.5987 - accuracy: 0.7072 - val_loss: 1.2128 - val_accuracy: 0.4972\n",
      "Epoch 30/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6302 - accuracy: 0.6823 - val_loss: 1.3061 - val_accuracy: 0.5249\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 1 0 0 1 1 2 2 0 0 2 2 2 0 2 2 1 2 0 1 2 2 0 2 1 2 0 0 1 1 0 0 2 2 2 1 2\n",
      " 1 0 2 2 2 0 2 1 2 1 1 2 2 1 1 2 0 2 0 2 2 1 0 2 0 0 0 2 2 2 1 2 2 2 0 1 0\n",
      " 1 2 1 2 0 2 2 0 2 2 1 2 1 2 0 2 0 1 2 2 1 0 0 1 2 0 2 2 1 2 1 2 2 1 2 2 2\n",
      " 1 1 2 2 2 2 0 1 1 0 2 0 2 1 0 2 1 0 0 0 1 2 2 1 2 1 1 1 1 0 0 2 2 1 1 2 2\n",
      " 2 0 2 2 2 2 2 2 1 2 2 2 1 1 1 1 2 2 0 0 2 1 0 1 2 0 2 0 0 2 2 0 2 2 0 2 2\n",
      " 2 0 1 0 0 2 2 0 2 1 1 1 0 0 2 0 1 2 0 2 1 2 1 2 2 1 0 1 0 0 1 0 2 1 0 2 2\n",
      " 2 1 0 0 2 0 0 0 1 0 0 0 2 1 1 1 2 2 2 1 2 2 1 1 2 0 2 0 1 0 1 2 2 2 0 2 2\n",
      " 0 2 0 2 1 0 2 0 2 2 2 0 2 1 0 2 2 2 0 0 0 1 2 2 2 1 2 2 2 2 1 0 1 2 0 2 1\n",
      " 2 2 1 2 2 1 2 1 1 1 1 1 0 0 1 2 1 0 1 2 2 0 0 2 2 2 2 2 1 2 1 0 2 2 1 2 0\n",
      " 2 2 0 2 2 2 2 0 1 2 1 0 1 2 1 2 2 2 2 2 2 2 1 1 1 2 1 1 2 2 1 2 2 2 2 2 1\n",
      " 2 2 2 1 1 0 1 2 2 0 1 2 2 2 2 0 2 2 0 2 1 2 1 0 1 1 2 0 2 0 0 2 0 2 0 2 2\n",
      " 1 1 1 0 1 2 2 0 2 1 0 1 1 2 2 1 1 1 1 2 2 1 1 2 0 0 2 2 2 2 0 1 1 1 0 0 2\n",
      " 0 2 2 1 2 2 0 0 2 1 1 1 0 2 2 2 2 2 1 0 1 2 2 0 2 0 1 1 1 2 2 1]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 4s 41ms/step - loss: 1.0943 - accuracy: 0.4061 - val_loss: 1.0937 - val_accuracy: 0.3923\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0884 - accuracy: 0.4296 - val_loss: 1.0914 - val_accuracy: 0.3923\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0778 - accuracy: 0.4268 - val_loss: 1.0893 - val_accuracy: 0.3923\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0705 - accuracy: 0.4268 - val_loss: 1.0873 - val_accuracy: 0.3923\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0519 - accuracy: 0.4268 - val_loss: 1.0856 - val_accuracy: 0.3923\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0290 - accuracy: 0.4268 - val_loss: 1.0793 - val_accuracy: 0.3923\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9952 - accuracy: 0.4227 - val_loss: 1.0849 - val_accuracy: 0.3923\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9650 - accuracy: 0.4240 - val_loss: 1.0591 - val_accuracy: 0.3923\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9317 - accuracy: 0.4033 - val_loss: 1.0428 - val_accuracy: 0.3923\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9005 - accuracy: 0.4075 - val_loss: 1.0584 - val_accuracy: 0.3923\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8780 - accuracy: 0.4144 - val_loss: 1.0329 - val_accuracy: 0.3923\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8514 - accuracy: 0.5428 - val_loss: 1.0872 - val_accuracy: 0.4365\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8013 - accuracy: 0.6160 - val_loss: 1.0811 - val_accuracy: 0.4420\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7980 - accuracy: 0.6022 - val_loss: 1.0969 - val_accuracy: 0.4586\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7631 - accuracy: 0.6202 - val_loss: 1.1344 - val_accuracy: 0.4641\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7707 - accuracy: 0.6008 - val_loss: 1.1041 - val_accuracy: 0.4751\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7458 - accuracy: 0.6188 - val_loss: 1.1032 - val_accuracy: 0.4807\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7442 - accuracy: 0.6119 - val_loss: 1.2252 - val_accuracy: 0.4807\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7144 - accuracy: 0.6340 - val_loss: 1.1344 - val_accuracy: 0.4862\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7329 - accuracy: 0.6202 - val_loss: 1.3116 - val_accuracy: 0.5138\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7263 - accuracy: 0.6160 - val_loss: 1.1196 - val_accuracy: 0.4751\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7496 - accuracy: 0.5994 - val_loss: 1.1994 - val_accuracy: 0.4475\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7223 - accuracy: 0.6160 - val_loss: 1.3254 - val_accuracy: 0.4972\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7095 - accuracy: 0.6271 - val_loss: 1.1744 - val_accuracy: 0.4917\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7104 - accuracy: 0.6202 - val_loss: 1.3517 - val_accuracy: 0.4751\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7037 - accuracy: 0.6243 - val_loss: 1.3758 - val_accuracy: 0.4917\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7082 - accuracy: 0.6174 - val_loss: 1.2316 - val_accuracy: 0.5028\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6988 - accuracy: 0.6229 - val_loss: 1.3088 - val_accuracy: 0.4530\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7143 - accuracy: 0.6174 - val_loss: 1.2778 - val_accuracy: 0.4475\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7136 - accuracy: 0.6146 - val_loss: 1.3234 - val_accuracy: 0.4475\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[0 0 0 0 0 0 0 0 0 2 0 2 0 2 2 0 0 0 0 0 2 2 0 2 0 0 0 2 0 0 0 0 2 2 2 1 1\n",
      " 0 0 2 2 2 0 0 0 2 0 0 2 0 0 0 2 2 2 0 2 2 0 0 2 0 0 2 0 2 1 0 2 2 2 0 0 0\n",
      " 0 2 0 2 0 2 2 0 2 1 0 0 0 1 0 0 0 0 2 0 0 2 0 0 2 0 0 0 0 2 2 2 2 0 2 2 0\n",
      " 0 0 2 2 2 0 0 0 0 0 0 2 1 0 0 2 0 0 0 0 0 2 2 0 2 0 0 0 0 0 0 2 0 0 0 2 2\n",
      " 2 0 2 2 2 0 2 2 0 2 2 2 0 0 0 0 2 2 0 0 0 0 2 2 2 0 2 2 0 2 0 0 2 0 0 2 2\n",
      " 2 0 0 2 2 1 2 0 0 0 0 0 0 0 2 0 1 2 2 2 2 2 0 0 2 0 0 0 0 0 0 0 2 0 0 0 2\n",
      " 0 0 0 0 2 0 0 1 0 0 0 0 2 0 0 0 0 2 2 0 2 2 0 0 2 0 0 0 0 0 0 0 2 2 0 0 2\n",
      " 0 0 0 2 0 0 1 0 2 2 2 0 0 0 0 2 0 2 0 0 2 0 0 2 2 0 0 2 2 2 0 0 0 0 0 2 0\n",
      " 2 2 1 0 2 0 2 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0 0 2 0 2 1 0 2 0 0 0 2 0 2 2\n",
      " 2 1 0 2 2 2 0 0 0 2 0 0 0 2 0 2 2 0 2 2 2 2 0 0 0 2 0 0 2 2 0 2 2 2 2 0 2\n",
      " 2 2 2 0 1 0 2 0 2 0 0 2 2 2 2 0 0 2 0 2 0 2 0 0 0 0 2 0 2 0 0 0 0 2 0 2 2\n",
      " 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 0 2 0 0 0 0 0 0 2 0 0 0 2 0 2 0 0 0 2 0 0 2\n",
      " 1 2 2 0 0 2 0 0 2 0 0 0 0 2 2 1 0 2 0 0 0 2 0 0 2 0 0 0 0 2 0 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "23/23 [==============================] - 4s 60ms/step - loss: 1.0960 - accuracy: 0.4199 - val_loss: 1.0946 - val_accuracy: 0.3867\n",
      "Epoch 2/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0897 - accuracy: 0.3936 - val_loss: 1.0922 - val_accuracy: 0.3923\n",
      "Epoch 3/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0824 - accuracy: 0.4544 - val_loss: 1.0909 - val_accuracy: 0.3867\n",
      "Epoch 4/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0720 - accuracy: 0.4738 - val_loss: 1.0880 - val_accuracy: 0.3978\n",
      "Epoch 5/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0526 - accuracy: 0.4848 - val_loss: 1.0843 - val_accuracy: 0.4199\n",
      "Epoch 6/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0412 - accuracy: 0.4959 - val_loss: 1.0811 - val_accuracy: 0.3867\n",
      "Epoch 7/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0203 - accuracy: 0.4917 - val_loss: 1.0752 - val_accuracy: 0.3867\n",
      "Epoch 8/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9821 - accuracy: 0.5207 - val_loss: 1.0648 - val_accuracy: 0.3867\n",
      "Epoch 9/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9553 - accuracy: 0.5359 - val_loss: 1.0628 - val_accuracy: 0.3978\n",
      "Epoch 10/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9390 - accuracy: 0.5055 - val_loss: 1.0548 - val_accuracy: 0.3757\n",
      "Epoch 11/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8936 - accuracy: 0.5428 - val_loss: 1.0544 - val_accuracy: 0.3978\n",
      "Epoch 12/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8667 - accuracy: 0.5760 - val_loss: 1.0402 - val_accuracy: 0.4254\n",
      "Epoch 13/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8389 - accuracy: 0.5704 - val_loss: 1.0388 - val_accuracy: 0.4309\n",
      "Epoch 14/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8306 - accuracy: 0.5594 - val_loss: 1.0205 - val_accuracy: 0.4420\n",
      "Epoch 15/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8329 - accuracy: 0.5856 - val_loss: 1.0295 - val_accuracy: 0.4365\n",
      "Epoch 16/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7780 - accuracy: 0.5843 - val_loss: 1.0261 - val_accuracy: 0.4807\n",
      "Epoch 17/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7623 - accuracy: 0.5939 - val_loss: 1.0164 - val_accuracy: 0.5083\n",
      "Epoch 18/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7695 - accuracy: 0.6105 - val_loss: 1.0276 - val_accuracy: 0.5028\n",
      "Epoch 19/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7427 - accuracy: 0.6367 - val_loss: 1.0183 - val_accuracy: 0.5470\n",
      "Epoch 20/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7516 - accuracy: 0.6478 - val_loss: 1.0273 - val_accuracy: 0.5580\n",
      "Epoch 21/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7212 - accuracy: 0.6450 - val_loss: 1.0448 - val_accuracy: 0.5470\n",
      "Epoch 22/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6972 - accuracy: 0.6575 - val_loss: 1.0565 - val_accuracy: 0.5193\n",
      "Epoch 23/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7025 - accuracy: 0.6312 - val_loss: 1.0733 - val_accuracy: 0.5249\n",
      "Epoch 24/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6585 - accuracy: 0.6699 - val_loss: 1.0857 - val_accuracy: 0.5193\n",
      "Epoch 25/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6393 - accuracy: 0.6561 - val_loss: 1.0734 - val_accuracy: 0.5801\n",
      "Epoch 26/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6733 - accuracy: 0.6423 - val_loss: 1.1178 - val_accuracy: 0.5359\n",
      "Epoch 27/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6637 - accuracy: 0.6782 - val_loss: 1.0987 - val_accuracy: 0.5304\n",
      "Epoch 28/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6416 - accuracy: 0.6533 - val_loss: 1.1322 - val_accuracy: 0.5193\n",
      "Epoch 29/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.6637 - accuracy: 0.6561 - val_loss: 1.0888 - val_accuracy: 0.5138\n",
      "Epoch 30/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6454 - accuracy: 0.6713 - val_loss: 1.1110 - val_accuracy: 0.5359\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 0 0 1 1 0 2 2 2 2 2 2 2 2 0 1 1 2 0 1 2 2 0 0 0 1 0 2 1 0 2 0 2 2 2 1 2\n",
      " 1 0 2 2 0 1 0 1 2 0 1 2 0 2 0 1 0 2 0 1 2 0 0 2 0 0 0 1 1 1 1 2 2 2 0 1 2\n",
      " 1 2 1 2 0 2 2 2 2 2 1 0 1 2 0 0 0 1 2 0 1 1 0 0 2 2 2 0 1 2 2 2 2 1 2 2 2\n",
      " 1 1 2 2 2 2 0 1 1 1 0 2 2 1 0 0 1 2 1 2 1 0 0 0 2 0 1 2 1 0 2 2 2 0 1 2 2\n",
      " 2 0 2 2 2 0 2 2 1 2 2 2 2 1 1 0 2 2 0 0 2 2 2 1 2 0 2 2 0 2 2 0 2 2 0 2 2\n",
      " 0 0 1 1 1 2 2 0 1 1 1 1 1 2 2 0 0 1 0 0 2 2 1 2 2 1 0 1 0 0 0 0 2 1 0 2 2\n",
      " 2 1 2 0 2 0 0 2 1 0 1 0 2 1 0 1 2 1 0 1 2 2 2 1 2 0 2 0 1 0 0 2 2 2 0 0 2\n",
      " 0 2 0 2 1 2 2 0 2 2 2 0 0 0 0 2 2 0 1 0 2 1 2 1 2 1 2 2 0 1 1 0 2 2 0 2 1\n",
      " 2 2 2 2 2 0 2 1 1 0 0 1 0 0 1 2 1 0 2 1 1 2 2 0 2 2 2 0 1 2 1 0 0 0 1 0 2\n",
      " 2 2 0 2 2 2 0 0 1 2 1 1 1 2 2 2 2 0 2 2 2 0 1 0 0 2 1 0 2 2 1 2 2 2 2 0 0\n",
      " 2 2 2 1 2 0 2 2 2 0 1 2 2 1 2 0 0 2 0 2 1 2 1 0 1 1 0 0 2 0 2 0 0 2 0 2 2\n",
      " 1 1 2 0 2 1 0 0 0 0 2 1 2 2 2 0 2 1 1 1 0 2 1 2 0 2 0 0 2 2 0 0 0 2 0 0 2\n",
      " 2 2 2 1 0 1 0 0 2 1 1 0 0 2 2 0 2 2 1 0 0 2 0 0 2 1 0 1 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for e in epochs:\n",
    "    for b in batch_sizes:\n",
    "        max_len = get_max_length(df_5768)\n",
    "        val_acc, test_acc = run_lstm(train=df_5768, test=df_5768_test, max_len=max_len,\n",
    "                                                seed=5768, epoch_val=e, b_size=b)\n",
    "        res_df[\"Dataset\"].append(\"5768\")\n",
    "        res_df[\"Seed\"].append(5768)\n",
    "        res_df[\"Epoch\"].append(e)\n",
    "        res_df[\"Batch-Size\"].append(b)\n",
    "        res_df[\"Val-Acc\"].append(val_acc)\n",
    "        res_df[\"Test-Acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 5s 19ms/step - loss: 1.0937 - accuracy: 0.4157 - val_loss: 1.0878 - val_accuracy: 0.4309\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0831 - accuracy: 0.4227 - val_loss: 1.0815 - val_accuracy: 0.4309\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0719 - accuracy: 0.4240 - val_loss: 1.0706 - val_accuracy: 0.4309\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0238 - accuracy: 0.4669 - val_loss: 1.0515 - val_accuracy: 0.4751\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9733 - accuracy: 0.4848 - val_loss: 1.0243 - val_accuracy: 0.4530\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8786 - accuracy: 0.5470 - val_loss: 1.0170 - val_accuracy: 0.4696\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8432 - accuracy: 0.5511 - val_loss: 1.0201 - val_accuracy: 0.5028\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8381 - accuracy: 0.5359 - val_loss: 0.9968 - val_accuracy: 0.4972\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7515 - accuracy: 0.5594 - val_loss: 1.0281 - val_accuracy: 0.5249\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7142 - accuracy: 0.6119 - val_loss: 1.0623 - val_accuracy: 0.4696\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 1 2 0 1 2 2 2 2 2 0 2 0 0 2 0 0 0 1 2 1 0 0 2 2 2 1 0 0 2 2 0 0 1 0 2\n",
      " 1 0 0 2 2 2 2 1 1 2 0 1 0 1 0 2 2 2 2 0 0 1 2 0 2 1 2 2 1 1 2 2 0 2 2 2 2\n",
      " 0 0 2 1 2 0 2 1 0 2 2 1 2 2 2 2 2 2 0 1 1 0 2 0 0 1 2 0 1 2 1 0 2 1 2 0 1\n",
      " 2 2 0 2 1 1 1 0 2 1 2 0 0 0 1 1 2 1 0 0 1 0 0 2 1 1 1 1 0 1 2 1 0 2 2 0 2\n",
      " 2 2 1 0 2 2 2 2 0 0 1 1 1 2 0 0 2 1 2 1 2 1 0 0 1 1 1 1 2 0 1 0 0 2 0 2 0\n",
      " 2 1 1 2 0 1 1 0 1 1 2 1 1 0 0 2 2 1 1 2 2 2 1 1 0 0 1 0 0 2 1 0 1 1 2 1 0\n",
      " 1 2 1 1 2 1 2 0 1 0 1 2 2 2 2 1 2 1 2 0 2 1 2 2 1 2 0 2 0 2 0 0 0 1 1 2 0\n",
      " 2 0 0 1 0 2 1 1 2 2 1 2 0 0 1 1 0 2 0 2 1 2 1 1 1 2 1 0 1 0 2 0 1 0 2 0 1\n",
      " 0 2 2 0 0 1 1 0 2 0 1 2 2 0 1 0 0 2 2 2 1 0 1 2 2 0 2 1 0 2 2 0 2 1 2 0 0\n",
      " 0 2 0 0 0 2 0 0 0 1 0 0 0 2 1 1 0 0 2 2 2 0 0 2 1 2 2 0 1 0 0 0 0 0 0 2 0\n",
      " 2 1 2 0 1 0 0 0 0 2 2 1 2 2 2 1 0 0 2 2 0 0 2 2 2 1 0 0 2 0 0 0 2 1 2 1 2\n",
      " 1 0 0 2 2 1 0 0 1 2 0 2 1 1 2 1 2 2 2 2 1 2 1 0 1 2 2 2 0 1 2 1 2 2 1 0 1\n",
      " 1 2 2 0 2 2 1 1 0 1 1 2 2 1 1 1 2 0 1 1 2 0 0 1 2 1 2 1 0 1 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 5s 32ms/step - loss: 1.0961 - accuracy: 0.3646 - val_loss: 1.0914 - val_accuracy: 0.4309\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0881 - accuracy: 0.4006 - val_loss: 1.0872 - val_accuracy: 0.4309\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0749 - accuracy: 0.4227 - val_loss: 1.0795 - val_accuracy: 0.4309\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0584 - accuracy: 0.4420 - val_loss: 1.0699 - val_accuracy: 0.4365\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0437 - accuracy: 0.4116 - val_loss: 1.0526 - val_accuracy: 0.4696\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0203 - accuracy: 0.4365 - val_loss: 1.0554 - val_accuracy: 0.4972\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0071 - accuracy: 0.4599 - val_loss: 1.0514 - val_accuracy: 0.4917\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9474 - accuracy: 0.4959 - val_loss: 1.0414 - val_accuracy: 0.4751\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9449 - accuracy: 0.4793 - val_loss: 1.0426 - val_accuracy: 0.5028\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9255 - accuracy: 0.5345 - val_loss: 1.0186 - val_accuracy: 0.5193\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 2 2 0 1 1 2 2 1 2 2 2 2 0 2 1 2 0 2 2 1 2 2 2 2 2 2 0 2 2 2 2 2 1 0 2\n",
      " 1 2 2 2 2 2 2 1 1 2 2 1 2 1 2 2 2 2 2 1 1 1 2 0 2 1 2 2 1 1 2 2 0 2 2 2 2\n",
      " 1 2 2 1 2 2 2 1 2 2 2 0 1 2 2 2 2 2 2 1 0 0 2 1 1 2 2 2 1 2 2 1 2 1 2 2 0\n",
      " 2 2 2 2 1 1 1 0 0 1 2 2 2 2 2 1 0 1 0 1 1 2 2 2 2 1 2 1 0 2 2 1 2 2 2 0 2\n",
      " 2 2 1 0 2 0 2 2 0 0 2 1 0 1 2 2 2 2 2 2 2 1 1 2 1 0 2 1 2 2 1 2 2 2 0 2 2\n",
      " 2 1 2 2 2 1 1 1 1 1 2 1 1 2 0 2 2 1 2 2 2 2 2 1 2 0 2 2 2 2 1 2 1 2 2 2 0\n",
      " 1 2 2 2 2 1 2 1 1 1 1 2 2 2 2 1 2 2 2 2 2 1 2 2 1 1 0 2 2 2 0 0 0 1 1 0 2\n",
      " 2 0 0 0 2 1 2 1 2 2 1 2 0 0 1 1 2 2 2 2 1 2 2 1 0 2 1 1 1 2 2 2 1 2 1 1 2\n",
      " 2 2 2 2 2 2 0 1 2 2 2 2 2 2 1 1 2 2 2 2 1 2 2 2 2 0 0 1 2 0 2 0 2 2 2 1 0\n",
      " 2 2 2 0 2 1 2 2 2 2 2 1 2 2 2 1 1 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 2 0 2 0\n",
      " 2 1 2 1 2 0 0 0 2 2 2 1 2 2 2 1 2 2 2 2 0 0 1 2 2 1 2 0 2 2 1 2 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 1 2 1 1 2 2 2 2 1 2 2 2 2 2 0 2 2 2 2 1 2 1 2 2 1 2 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 2 2 2 2 2 1 2 2 0 2 1 2 1 2 2 2 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 4s 41ms/step - loss: 1.0941 - accuracy: 0.4144 - val_loss: 1.0883 - val_accuracy: 0.4309\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0891 - accuracy: 0.4171 - val_loss: 1.0853 - val_accuracy: 0.4309\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0844 - accuracy: 0.4171 - val_loss: 1.0809 - val_accuracy: 0.4309\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0723 - accuracy: 0.4227 - val_loss: 1.0756 - val_accuracy: 0.4309\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0605 - accuracy: 0.4033 - val_loss: 1.0690 - val_accuracy: 0.4309\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0409 - accuracy: 0.4268 - val_loss: 1.0512 - val_accuracy: 0.4420\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9930 - accuracy: 0.4710 - val_loss: 1.0349 - val_accuracy: 0.4475\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9582 - accuracy: 0.5028 - val_loss: 1.0303 - val_accuracy: 0.4475\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9341 - accuracy: 0.5055 - val_loss: 1.0129 - val_accuracy: 0.4972\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8926 - accuracy: 0.5345 - val_loss: 1.0003 - val_accuracy: 0.5028\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 2 2 0 2 2 2 0 2 2 0 2 2 2 2 2 0 0 2 2 0 2 0 2 2 0 2 2 0 2 2 2 2 2 2 0\n",
      " 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 0 2 0 2 0 0 2 2 2 2 2 0 2 0 2 2 2 2 0 2 2 0 2 2 2 2 0 2\n",
      " 2 2 2 2 0 2 2 0 2 2 0 2 2 2 0 2 0 2 0 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 0 2\n",
      " 0 2 0 0 2 2 2 2 0 0 2 2 2 2 0 2 2 2 2 2 2 0 0 0 2 2 2 2 2 0 2 0 2 2 2 2 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 0 2 2 0 2 2 0 0 2 0 2 2\n",
      " 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 2 2 2 0 0 2 2 2 2 2\n",
      " 2 0 2 2 0 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 0 2\n",
      " 2 0 2 0 0 2 2 2 0 0 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 0 0 2 2 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 0 0 2 0 0 2 2 2 0 0 2 2 0 0 2 2 2 0 2 0 2 0 2 0 0 2 0 2 2\n",
      " 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 0 2 2 2 2 0 0 2 2 2 2 0 2 2 2 0 2 2 2 2 2\n",
      " 2 0 0 2 2 0 0 0 2 0 0 2 2 2 0 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 0 2 2\n",
      " 2 2 2 0 2 2 2 0 2 2 2 2 2 0 0 2 2 0 2 0 2 0 2 2 0 2 2 2 2 2 0 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 4s 61ms/step - loss: 1.0965 - accuracy: 0.4075 - val_loss: 1.0937 - val_accuracy: 0.4309\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0908 - accuracy: 0.4227 - val_loss: 1.0869 - val_accuracy: 0.4309\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0792 - accuracy: 0.4227 - val_loss: 1.0803 - val_accuracy: 0.4309\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0760 - accuracy: 0.4227 - val_loss: 1.0765 - val_accuracy: 0.4309\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0627 - accuracy: 0.4227 - val_loss: 1.0720 - val_accuracy: 0.4309\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0577 - accuracy: 0.4378 - val_loss: 1.0699 - val_accuracy: 0.4309\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0371 - accuracy: 0.4489 - val_loss: 1.0638 - val_accuracy: 0.4309\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0096 - accuracy: 0.4599 - val_loss: 1.0624 - val_accuracy: 0.4144\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9919 - accuracy: 0.4641 - val_loss: 1.0572 - val_accuracy: 0.4199\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9521 - accuracy: 0.4613 - val_loss: 1.0502 - val_accuracy: 0.4420\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 0 2 0 2 0 2 0 2 2 0 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 0 0 0 2 2 2 2 0 0 2\n",
      " 0 2 0 2 2 2 2 2 0 2 0 0 2 0 2 2 2 2 2 0 0 0 2 0 0 0 2 2 2 0 2 2 0 2 2 2 2\n",
      " 2 2 2 0 2 0 2 0 0 2 2 0 0 2 2 2 2 2 2 2 0 0 2 2 0 0 2 0 0 2 2 0 2 0 2 2 2\n",
      " 2 2 2 2 0 0 2 2 0 0 2 2 2 2 2 0 2 0 0 2 2 0 0 0 2 0 2 0 0 2 2 2 0 2 2 0 2\n",
      " 2 2 0 0 2 2 0 2 2 0 0 0 2 2 2 2 2 2 2 0 2 0 0 0 2 0 0 0 2 0 2 2 2 2 0 2 2\n",
      " 2 0 2 2 2 0 0 0 0 0 2 0 0 0 2 2 2 0 0 2 0 2 2 2 2 0 2 2 0 2 0 2 0 2 2 2 0\n",
      " 0 2 0 0 0 0 2 2 0 0 0 2 2 2 2 0 2 2 2 0 2 0 2 0 0 2 0 2 2 2 0 0 0 0 0 2 0\n",
      " 2 0 0 0 2 0 0 0 2 2 0 2 0 0 0 2 2 2 0 2 0 2 0 2 0 2 2 2 0 0 2 0 0 2 2 0 2\n",
      " 0 0 2 2 0 0 0 0 2 2 2 2 2 2 0 2 2 2 2 0 0 2 2 2 2 0 0 2 2 2 2 0 2 2 0 0 0\n",
      " 2 2 2 0 2 2 2 2 2 0 2 0 2 2 0 2 0 2 2 2 2 0 2 2 0 2 2 0 2 0 2 2 0 2 0 2 2\n",
      " 2 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 2 2 2 2 2 0 0 2 2 0 0 0 2 2 0 0 2 0 2 2 2\n",
      " 2 0 0 2 2 2 0 2 2 2 2 0 0 0 0 2 2 2 0 0 2 2 2 2 2 2 2 0 2 0 2 0 2 2 0 0 0\n",
      " 0 2 0 0 2 2 0 2 0 0 2 2 2 0 0 2 2 2 2 0 2 0 2 2 2 0 2 0 2 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "181/181 [==============================] - 5s 19ms/step - loss: 1.0952 - accuracy: 0.3702 - val_loss: 1.0907 - val_accuracy: 0.4309\n",
      "Epoch 2/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1.0864 - accuracy: 0.4309 - val_loss: 1.0856 - val_accuracy: 0.4309\n",
      "Epoch 3/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0792 - accuracy: 0.4406 - val_loss: 1.0823 - val_accuracy: 0.4420\n",
      "Epoch 4/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1.0608 - accuracy: 0.4710 - val_loss: 1.0695 - val_accuracy: 0.4254\n",
      "Epoch 5/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 1.0170 - accuracy: 0.5193 - val_loss: 1.0359 - val_accuracy: 0.5304\n",
      "Epoch 6/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.9647 - accuracy: 0.5373 - val_loss: 1.0075 - val_accuracy: 0.5359\n",
      "Epoch 7/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.9075 - accuracy: 0.5497 - val_loss: 0.9883 - val_accuracy: 0.5193\n",
      "Epoch 8/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8609 - accuracy: 0.5691 - val_loss: 0.9958 - val_accuracy: 0.5193\n",
      "Epoch 9/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8281 - accuracy: 0.5787 - val_loss: 0.9945 - val_accuracy: 0.5138\n",
      "Epoch 10/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8073 - accuracy: 0.5939 - val_loss: 1.0396 - val_accuracy: 0.5193\n",
      "Epoch 11/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8149 - accuracy: 0.5746 - val_loss: 1.0290 - val_accuracy: 0.5083\n",
      "Epoch 12/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8065 - accuracy: 0.5787 - val_loss: 1.0764 - val_accuracy: 0.5083\n",
      "Epoch 13/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8197 - accuracy: 0.5649 - val_loss: 1.0674 - val_accuracy: 0.4972\n",
      "Epoch 14/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7932 - accuracy: 0.5773 - val_loss: 1.0681 - val_accuracy: 0.4917\n",
      "Epoch 15/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8131 - accuracy: 0.5760 - val_loss: 1.0811 - val_accuracy: 0.5083\n",
      "Epoch 16/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7711 - accuracy: 0.6036 - val_loss: 1.0727 - val_accuracy: 0.4972\n",
      "Epoch 17/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7666 - accuracy: 0.5898 - val_loss: 1.0947 - val_accuracy: 0.5193\n",
      "Epoch 18/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7824 - accuracy: 0.5760 - val_loss: 1.1124 - val_accuracy: 0.5193\n",
      "Epoch 19/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7583 - accuracy: 0.5870 - val_loss: 1.0916 - val_accuracy: 0.5249\n",
      "Epoch 20/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7434 - accuracy: 0.5981 - val_loss: 1.1211 - val_accuracy: 0.5193\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 0 2 0 2 2 0 2 0 0 0 2 0 0 2 2 2 0 2 0 0 0 0 2 2 2 0 0 0 2 2 0 2 2 2 2\n",
      " 0 2 0 2 2 2 2 2 2 2 0 2 0 0 2 2 2 0 0 0 0 2 2 0 1 2 2 2 2 1 2 0 0 2 2 2 2\n",
      " 2 2 2 2 2 0 2 2 0 0 2 0 2 0 0 2 2 2 2 2 0 0 0 2 2 0 2 0 2 2 2 2 2 2 0 2 2\n",
      " 0 0 0 2 0 2 0 0 2 2 1 2 0 2 0 2 0 1 0 0 2 0 0 0 2 0 1 2 0 2 2 2 0 2 0 0 2\n",
      " 0 2 0 0 0 2 0 2 2 0 0 2 2 2 0 2 2 0 2 0 2 0 0 0 2 0 1 0 2 0 2 2 2 2 2 0 0\n",
      " 2 2 2 0 2 2 2 0 2 1 2 2 0 0 2 0 2 0 0 2 2 2 0 0 2 0 2 0 0 2 0 2 0 0 0 2 2\n",
      " 2 2 0 0 0 0 0 1 2 2 2 2 2 2 2 2 2 0 2 0 2 0 0 0 0 2 0 2 2 2 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 2 0 2 2 0 0 2 0 0 2 2 2 2 2 2 2 2 0 2 0 2 2 0 0 0 2 0 1 2 0 0 2\n",
      " 2 0 2 0 0 0 0 0 2 0 0 2 2 0 0 1 2 1 2 2 0 0 1 2 0 0 2 0 0 2 1 0 2 2 0 2 2\n",
      " 0 2 2 2 0 2 0 2 0 0 0 0 0 0 0 2 0 0 2 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2 0 2 0\n",
      " 2 2 0 0 0 0 0 0 0 2 2 0 2 2 2 2 0 2 0 2 2 0 0 2 2 2 0 0 2 2 2 0 2 2 2 0 2\n",
      " 0 0 2 2 2 0 0 0 2 0 0 2 0 2 0 2 2 2 0 0 0 0 2 2 0 2 2 2 2 0 2 2 2 2 0 0 2\n",
      " 1 2 0 0 2 2 2 0 0 2 1 2 2 0 2 0 2 0 2 0 0 0 2 2 0 2 2 2 2 0 2 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "91/91 [==============================] - 5s 31ms/step - loss: 1.0895 - accuracy: 0.4268 - val_loss: 1.0822 - val_accuracy: 0.4309\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 1.0736 - accuracy: 0.4227 - val_loss: 1.0771 - val_accuracy: 0.4309\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0600 - accuracy: 0.4503 - val_loss: 1.0658 - val_accuracy: 0.4641\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0171 - accuracy: 0.4820 - val_loss: 1.0482 - val_accuracy: 0.4365\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9362 - accuracy: 0.5221 - val_loss: 1.0308 - val_accuracy: 0.4641\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.8982 - accuracy: 0.5304 - val_loss: 1.0418 - val_accuracy: 0.4862\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8653 - accuracy: 0.5069 - val_loss: 1.0625 - val_accuracy: 0.4641\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.8284 - accuracy: 0.5138 - val_loss: 1.0426 - val_accuracy: 0.4696\n",
      "Epoch 9/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.8077 - accuracy: 0.5373 - val_loss: 1.0465 - val_accuracy: 0.4641\n",
      "Epoch 10/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7663 - accuracy: 0.5732 - val_loss: 1.0802 - val_accuracy: 0.4696\n",
      "Epoch 11/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7653 - accuracy: 0.5608 - val_loss: 1.1319 - val_accuracy: 0.4641\n",
      "Epoch 12/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7644 - accuracy: 0.5746 - val_loss: 1.1181 - val_accuracy: 0.4751\n",
      "Epoch 13/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7142 - accuracy: 0.6008 - val_loss: 1.1696 - val_accuracy: 0.4807\n",
      "Epoch 14/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7088 - accuracy: 0.6119 - val_loss: 1.1390 - val_accuracy: 0.4751\n",
      "Epoch 15/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7351 - accuracy: 0.6008 - val_loss: 1.1247 - val_accuracy: 0.5138\n",
      "Epoch 16/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.7172 - accuracy: 0.5939 - val_loss: 1.1453 - val_accuracy: 0.4696\n",
      "Epoch 17/20\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 0.6735 - accuracy: 0.6395 - val_loss: 1.1700 - val_accuracy: 0.4807\n",
      "Epoch 18/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6917 - accuracy: 0.6409 - val_loss: 1.1607 - val_accuracy: 0.4862\n",
      "Epoch 19/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6218 - accuracy: 0.7017 - val_loss: 1.1985 - val_accuracy: 0.4917\n",
      "Epoch 20/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6223 - accuracy: 0.6961 - val_loss: 1.3816 - val_accuracy: 0.5083\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 1 2 0 1 1 0 2 2 2 0 2 2 1 2 1 2 2 0 0 1 2 2 2 2 2 1 0 2 2 2 2 0 1 1 2\n",
      " 0 0 2 2 2 2 2 1 1 2 2 1 2 0 0 2 2 2 2 1 0 1 2 0 2 1 2 2 0 1 2 2 0 2 2 2 2\n",
      " 0 2 2 1 2 2 2 1 2 0 2 1 1 2 2 2 2 2 2 1 0 2 2 2 2 2 2 0 1 2 2 1 2 1 2 2 2\n",
      " 2 2 2 2 1 1 1 2 1 0 2 2 0 2 2 1 0 1 1 0 0 2 2 2 0 1 1 1 2 2 0 1 2 2 2 0 2\n",
      " 2 0 1 0 2 2 2 2 2 0 0 1 0 0 0 2 2 1 2 0 2 1 2 2 1 1 2 1 2 0 1 2 0 2 1 2 0\n",
      " 2 1 2 2 0 2 1 0 1 1 2 1 1 2 1 2 2 1 2 0 2 2 1 2 2 2 2 2 2 2 1 2 1 2 2 2 1\n",
      " 1 2 2 0 1 0 2 2 1 0 1 2 2 1 2 1 2 1 2 0 2 0 2 2 1 1 2 2 2 2 0 0 2 1 0 0 2\n",
      " 2 0 0 1 2 2 1 0 2 2 1 2 0 2 1 1 0 2 2 2 1 0 2 1 1 2 2 1 1 0 2 2 1 2 2 0 2\n",
      " 1 0 0 2 2 2 0 0 2 2 0 2 2 0 0 1 2 2 2 2 1 0 2 2 2 0 2 1 0 0 2 0 2 2 2 1 2\n",
      " 2 2 2 0 2 1 1 2 2 0 0 0 2 2 0 1 0 2 2 2 0 2 2 2 0 2 2 2 2 0 2 0 0 2 0 2 2\n",
      " 2 1 0 1 2 0 0 0 0 0 2 1 2 2 2 1 2 2 2 2 2 0 1 2 2 1 2 0 2 2 1 2 2 1 2 0 2\n",
      " 2 0 2 2 2 2 0 0 1 2 0 2 2 1 0 2 2 2 2 2 2 2 0 2 0 2 2 2 0 1 2 2 2 2 2 2 1\n",
      " 1 2 1 0 2 2 1 2 0 1 2 2 2 0 2 0 2 0 0 0 2 0 2 1 2 1 2 1 0 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 4s 40ms/step - loss: 1.0958 - accuracy: 0.4075 - val_loss: 1.0924 - val_accuracy: 0.4309\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0874 - accuracy: 0.4227 - val_loss: 1.0871 - val_accuracy: 0.4309\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0773 - accuracy: 0.4227 - val_loss: 1.0819 - val_accuracy: 0.4309\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0605 - accuracy: 0.4296 - val_loss: 1.0746 - val_accuracy: 0.4365\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0414 - accuracy: 0.4669 - val_loss: 1.0684 - val_accuracy: 0.4530\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9988 - accuracy: 0.5124 - val_loss: 1.0646 - val_accuracy: 0.4530\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9335 - accuracy: 0.5262 - val_loss: 1.0609 - val_accuracy: 0.4475\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8919 - accuracy: 0.5635 - val_loss: 1.0742 - val_accuracy: 0.4420\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8688 - accuracy: 0.5594 - val_loss: 1.0723 - val_accuracy: 0.4420\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8380 - accuracy: 0.5691 - val_loss: 1.0584 - val_accuracy: 0.4641\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7845 - accuracy: 0.5912 - val_loss: 1.0955 - val_accuracy: 0.4365\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8115 - accuracy: 0.5663 - val_loss: 1.0928 - val_accuracy: 0.4309\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7973 - accuracy: 0.5718 - val_loss: 1.1208 - val_accuracy: 0.4475\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7883 - accuracy: 0.5815 - val_loss: 1.1322 - val_accuracy: 0.4420\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7527 - accuracy: 0.5939 - val_loss: 1.1611 - val_accuracy: 0.4309\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7647 - accuracy: 0.5884 - val_loss: 1.1515 - val_accuracy: 0.4475\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7414 - accuracy: 0.5912 - val_loss: 1.1830 - val_accuracy: 0.4309\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7340 - accuracy: 0.5884 - val_loss: 1.1276 - val_accuracy: 0.4530\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7530 - accuracy: 0.5180 - val_loss: 1.1243 - val_accuracy: 0.4641\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7127 - accuracy: 0.5552 - val_loss: 1.1650 - val_accuracy: 0.4586\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 2 2 2 1 1 1 2 2 2 2 2 2 1 2 1 2 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 2 1 2 2\n",
      " 1 2 1 2 2 2 2 1 1 2 2 1 2 1 1 1 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 1 2 2 1 2 1 2 1 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 1 2 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 1 2 2 1 2 2 2 1 2 2 2 2 2\n",
      " 2 1 2 2 2 2 1 2 1 2 2 1 1 1 2 2 2 1 2 2 2 2 1 2 1 1 1 2 2 2 1 2 2 2 1 2 2\n",
      " 2 1 1 1 2 2 1 2 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 1 2 2 2 2 1 2 2 2 2 2 2 1 1\n",
      " 1 2 2 2 1 2 2 2 1 2 1 2 2 2 2 1 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 2 2 1 2 2 2\n",
      " 1 1 1 2 2 2 2 1 2 1 2 2 2 2 1 2 2 2 1 2 1 2 1 1 2 2 1 1 1 2 2 2 1 2 2 2 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 1 2 2 1\n",
      " 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 2 2 1 2 2 2 2 2 2 2 1\n",
      " 2 1 2 1 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1\n",
      " 1 2 1 2 2 2 1 2 1 1 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 1 2 1 1 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 4s 61ms/step - loss: 1.0968 - accuracy: 0.4116 - val_loss: 1.0944 - val_accuracy: 0.4309\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0910 - accuracy: 0.4144 - val_loss: 1.0900 - val_accuracy: 0.4309\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0876 - accuracy: 0.4213 - val_loss: 1.0867 - val_accuracy: 0.4309\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0817 - accuracy: 0.4282 - val_loss: 1.0837 - val_accuracy: 0.4309\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0816 - accuracy: 0.4309 - val_loss: 1.0830 - val_accuracy: 0.4309\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0743 - accuracy: 0.4282 - val_loss: 1.0811 - val_accuracy: 0.4309\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0687 - accuracy: 0.4254 - val_loss: 1.0789 - val_accuracy: 0.4309\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0554 - accuracy: 0.4227 - val_loss: 1.0750 - val_accuracy: 0.4309\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0426 - accuracy: 0.4213 - val_loss: 1.0687 - val_accuracy: 0.4309\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.0038 - accuracy: 0.4296 - val_loss: 1.0577 - val_accuracy: 0.4309\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9981 - accuracy: 0.4157 - val_loss: 1.0408 - val_accuracy: 0.4309\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9529 - accuracy: 0.4254 - val_loss: 1.0257 - val_accuracy: 0.4309\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9421 - accuracy: 0.4309 - val_loss: 1.0191 - val_accuracy: 0.4309\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9322 - accuracy: 0.4406 - val_loss: 1.0195 - val_accuracy: 0.4309\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8970 - accuracy: 0.4807 - val_loss: 1.0033 - val_accuracy: 0.4807\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8811 - accuracy: 0.5428 - val_loss: 1.0099 - val_accuracy: 0.4917\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8440 - accuracy: 0.5760 - val_loss: 1.0027 - val_accuracy: 0.5138\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8358 - accuracy: 0.5787 - val_loss: 1.0064 - val_accuracy: 0.5083\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.8173 - accuracy: 0.5787 - val_loss: 1.0064 - val_accuracy: 0.5249\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7771 - accuracy: 0.6119 - val_loss: 0.9985 - val_accuracy: 0.5249\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 0 0 1 1 0 2 2 1 0 0 2 2 0 2 0 2 1 0 2 1 2 2 2 2 2 0 0 0 2 2 1 2 1 1 2\n",
      " 0 1 2 2 2 2 2 1 0 2 0 1 2 0 2 2 2 0 2 1 1 0 2 0 2 1 0 2 0 1 2 2 0 2 2 0 2\n",
      " 2 2 2 1 2 0 2 0 0 0 2 0 1 2 2 2 2 2 2 1 0 1 1 2 2 0 2 0 1 2 2 0 2 1 2 2 1\n",
      " 2 2 2 2 0 0 1 1 1 1 2 2 2 2 2 1 1 1 1 1 0 2 0 2 0 1 1 0 0 2 1 0 2 2 1 0 2\n",
      " 2 0 1 0 2 2 0 2 2 0 0 1 0 2 0 2 2 0 2 0 2 1 1 0 2 1 2 1 2 1 0 2 2 2 0 2 0\n",
      " 2 0 2 2 2 1 1 0 1 1 2 1 1 1 2 1 2 0 2 0 2 2 0 2 2 0 2 2 1 2 0 2 1 0 2 2 1\n",
      " 1 2 2 1 1 0 0 2 1 1 1 2 2 1 2 1 2 0 2 2 2 0 1 2 1 1 0 2 2 2 0 0 0 1 1 0 2\n",
      " 1 0 0 1 2 2 0 1 2 2 0 2 0 0 0 1 2 2 2 2 1 2 2 1 0 2 2 1 1 2 2 1 1 0 1 0 2\n",
      " 1 0 2 2 2 2 0 1 2 0 0 2 2 0 1 0 0 2 2 2 0 0 2 2 2 0 2 1 0 1 2 0 2 2 2 1 2\n",
      " 2 2 2 1 0 0 0 2 2 0 2 0 2 2 1 1 0 0 2 2 0 1 2 2 0 2 2 0 2 0 2 2 0 2 0 2 1\n",
      " 2 1 0 1 0 0 2 1 0 2 2 2 2 2 2 1 0 2 2 2 2 0 1 2 2 1 2 0 2 2 1 0 2 1 2 1 2\n",
      " 1 2 0 2 2 0 0 0 1 0 0 2 1 1 0 0 2 2 1 2 0 2 1 2 1 2 2 2 0 1 2 1 2 2 1 0 0\n",
      " 0 2 1 0 2 1 1 2 1 1 1 2 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 1 0 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "181/181 [==============================] - 5s 19ms/step - loss: 1.0922 - accuracy: 0.4171 - val_loss: 1.0832 - val_accuracy: 0.4309\n",
      "Epoch 2/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0806 - accuracy: 0.4227 - val_loss: 1.0757 - val_accuracy: 0.4309\n",
      "Epoch 3/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0575 - accuracy: 0.4351 - val_loss: 1.0578 - val_accuracy: 0.4365\n",
      "Epoch 4/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0136 - accuracy: 0.5041 - val_loss: 1.0352 - val_accuracy: 0.4917\n",
      "Epoch 5/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9533 - accuracy: 0.5193 - val_loss: 1.0356 - val_accuracy: 0.4586\n",
      "Epoch 6/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9300 - accuracy: 0.5276 - val_loss: 1.0113 - val_accuracy: 0.5028\n",
      "Epoch 7/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8466 - accuracy: 0.5898 - val_loss: 1.0181 - val_accuracy: 0.5304\n",
      "Epoch 8/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8197 - accuracy: 0.6077 - val_loss: 1.0169 - val_accuracy: 0.5138\n",
      "Epoch 9/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7599 - accuracy: 0.6298 - val_loss: 1.0416 - val_accuracy: 0.4972\n",
      "Epoch 10/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7763 - accuracy: 0.6312 - val_loss: 1.0304 - val_accuracy: 0.5359\n",
      "Epoch 11/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7428 - accuracy: 0.6285 - val_loss: 1.0345 - val_accuracy: 0.5414\n",
      "Epoch 12/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7060 - accuracy: 0.6257 - val_loss: 1.0488 - val_accuracy: 0.5359\n",
      "Epoch 13/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7116 - accuracy: 0.6561 - val_loss: 1.0750 - val_accuracy: 0.5249\n",
      "Epoch 14/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6896 - accuracy: 0.6657 - val_loss: 1.0961 - val_accuracy: 0.5414\n",
      "Epoch 15/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6768 - accuracy: 0.6657 - val_loss: 1.1302 - val_accuracy: 0.4917\n",
      "Epoch 16/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6840 - accuracy: 0.6699 - val_loss: 1.0996 - val_accuracy: 0.5249\n",
      "Epoch 17/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6473 - accuracy: 0.6961 - val_loss: 1.2692 - val_accuracy: 0.5193\n",
      "Epoch 18/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6460 - accuracy: 0.6961 - val_loss: 1.1867 - val_accuracy: 0.5249\n",
      "Epoch 19/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6329 - accuracy: 0.6713 - val_loss: 1.1812 - val_accuracy: 0.5304\n",
      "Epoch 20/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6321 - accuracy: 0.6575 - val_loss: 1.2563 - val_accuracy: 0.5304\n",
      "Epoch 21/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6469 - accuracy: 0.6354 - val_loss: 1.3104 - val_accuracy: 0.5470\n",
      "Epoch 22/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6253 - accuracy: 0.6727 - val_loss: 1.2863 - val_accuracy: 0.5028\n",
      "Epoch 23/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.5985 - accuracy: 0.6768 - val_loss: 1.3726 - val_accuracy: 0.5249\n",
      "Epoch 24/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6106 - accuracy: 0.6616 - val_loss: 1.3635 - val_accuracy: 0.5249\n",
      "Epoch 25/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6134 - accuracy: 0.6575 - val_loss: 1.4733 - val_accuracy: 0.5028\n",
      "Epoch 26/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.5619 - accuracy: 0.7017 - val_loss: 1.5351 - val_accuracy: 0.5304\n",
      "Epoch 27/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6215 - accuracy: 0.6644 - val_loss: 1.4993 - val_accuracy: 0.5193\n",
      "Epoch 28/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.5966 - accuracy: 0.6878 - val_loss: 1.6575 - val_accuracy: 0.5470\n",
      "Epoch 29/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.5954 - accuracy: 0.6685 - val_loss: 1.6014 - val_accuracy: 0.5083\n",
      "Epoch 30/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6007 - accuracy: 0.6754 - val_loss: 1.6401 - val_accuracy: 0.5249\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 0 1 0 1 1 1 0 1 0 0 2 2 0 2 1 2 0 1 2 0 0 0 1 2 2 1 0 0 2 2 0 0 1 0 2\n",
      " 0 0 2 2 2 2 2 1 1 2 0 1 2 0 1 2 1 0 2 0 0 1 2 0 2 0 2 2 1 1 0 0 0 2 2 0 2\n",
      " 1 0 2 1 2 0 2 1 0 0 2 0 1 0 1 2 2 1 2 2 0 1 0 1 2 0 2 0 1 1 1 0 2 1 0 0 2\n",
      " 2 0 0 2 0 1 1 0 1 1 2 2 0 1 1 1 0 1 0 0 2 0 0 0 1 1 1 1 0 2 0 1 2 2 2 0 2\n",
      " 2 0 0 0 2 2 2 2 0 0 0 1 1 1 0 2 2 0 2 1 2 0 0 0 1 0 2 0 2 0 1 2 0 2 1 2 0\n",
      " 2 1 0 0 0 1 1 0 1 1 2 1 1 1 0 0 2 1 1 2 2 2 0 2 1 0 2 0 0 2 0 1 0 1 0 2 1\n",
      " 1 0 1 0 0 0 0 0 2 1 1 2 2 1 2 1 2 0 2 0 1 0 1 0 0 1 0 2 2 2 0 0 0 0 0 1 2\n",
      " 2 0 0 0 0 2 0 1 0 2 0 2 0 0 1 2 1 1 2 1 1 2 2 1 0 2 1 0 0 0 2 0 1 2 2 0 2\n",
      " 1 0 1 0 0 1 0 0 2 2 0 2 2 0 1 2 2 2 2 2 0 0 0 2 1 0 2 0 0 0 2 0 2 2 0 1 2\n",
      " 1 2 1 0 0 1 0 2 0 0 1 0 0 0 2 1 1 0 2 0 0 0 0 2 1 0 1 1 2 0 2 0 0 2 0 2 0\n",
      " 2 1 0 0 1 0 0 0 0 0 2 0 2 2 2 1 0 2 0 1 2 0 0 2 2 1 0 0 2 2 1 0 2 1 2 1 2\n",
      " 0 1 2 0 2 0 0 0 2 0 0 2 1 1 0 0 2 2 1 0 0 0 0 1 0 2 2 2 0 1 2 2 2 2 0 0 2\n",
      " 1 2 1 0 2 1 0 2 1 2 0 2 2 0 1 1 2 1 2 1 1 0 0 1 0 1 2 1 2 1 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "91/91 [==============================] - 6s 32ms/step - loss: 1.0937 - accuracy: 0.4157 - val_loss: 1.0873 - val_accuracy: 0.4309\n",
      "Epoch 2/30\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 1.0857 - accuracy: 0.4254 - val_loss: 1.0834 - val_accuracy: 0.4309\n",
      "Epoch 3/30\n",
      "91/91 [==============================] - 102s 1s/step - loss: 1.0826 - accuracy: 0.4227 - val_loss: 1.0801 - val_accuracy: 0.4309\n",
      "Epoch 4/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0708 - accuracy: 0.4392 - val_loss: 1.0741 - val_accuracy: 0.4309\n",
      "Epoch 5/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 1.0459 - accuracy: 0.4655 - val_loss: 1.0628 - val_accuracy: 0.4475\n",
      "Epoch 6/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.9877 - accuracy: 0.5028 - val_loss: 1.0032 - val_accuracy: 0.4972\n",
      "Epoch 7/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9314 - accuracy: 0.5290 - val_loss: 0.9753 - val_accuracy: 0.5304\n",
      "Epoch 8/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.8710 - accuracy: 0.5552 - val_loss: 0.9632 - val_accuracy: 0.5249\n",
      "Epoch 9/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8218 - accuracy: 0.5497 - val_loss: 0.9811 - val_accuracy: 0.5083\n",
      "Epoch 10/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.7895 - accuracy: 0.5704 - val_loss: 0.9745 - val_accuracy: 0.4972\n",
      "Epoch 11/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7922 - accuracy: 0.5746 - val_loss: 0.9775 - val_accuracy: 0.5028\n",
      "Epoch 12/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7620 - accuracy: 0.5691 - val_loss: 0.9636 - val_accuracy: 0.5249\n",
      "Epoch 13/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.7389 - accuracy: 0.5773 - val_loss: 0.9614 - val_accuracy: 0.5304\n",
      "Epoch 14/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.7204 - accuracy: 0.6036 - val_loss: 0.9987 - val_accuracy: 0.5193\n",
      "Epoch 15/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6736 - accuracy: 0.6133 - val_loss: 1.0087 - val_accuracy: 0.5304\n",
      "Epoch 16/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6990 - accuracy: 0.5718 - val_loss: 1.0382 - val_accuracy: 0.5359\n",
      "Epoch 17/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6362 - accuracy: 0.6381 - val_loss: 1.0539 - val_accuracy: 0.5414\n",
      "Epoch 18/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6573 - accuracy: 0.6146 - val_loss: 1.0607 - val_accuracy: 0.5525\n",
      "Epoch 19/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.6379 - accuracy: 0.6285 - val_loss: 1.0733 - val_accuracy: 0.5635\n",
      "Epoch 20/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.6470 - accuracy: 0.6174 - val_loss: 1.0995 - val_accuracy: 0.5470\n",
      "Epoch 21/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6809 - accuracy: 0.6036 - val_loss: 1.1224 - val_accuracy: 0.5304\n",
      "Epoch 22/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6639 - accuracy: 0.6008 - val_loss: 1.1235 - val_accuracy: 0.5525\n",
      "Epoch 23/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6211 - accuracy: 0.6271 - val_loss: 1.1194 - val_accuracy: 0.5691\n",
      "Epoch 24/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6389 - accuracy: 0.6188 - val_loss: 1.1658 - val_accuracy: 0.5856\n",
      "Epoch 25/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6174 - accuracy: 0.6257 - val_loss: 1.1453 - val_accuracy: 0.5856\n",
      "Epoch 26/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6061 - accuracy: 0.6423 - val_loss: 1.1379 - val_accuracy: 0.5691\n",
      "Epoch 27/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6056 - accuracy: 0.6464 - val_loss: 1.1861 - val_accuracy: 0.5635\n",
      "Epoch 28/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6071 - accuracy: 0.6423 - val_loss: 1.2119 - val_accuracy: 0.5580\n",
      "Epoch 29/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6297 - accuracy: 0.6381 - val_loss: 1.2204 - val_accuracy: 0.5746\n",
      "Epoch 30/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6633 - accuracy: 0.6036 - val_loss: 1.2588 - val_accuracy: 0.5470\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 1 2 0 1 2 1 2 1 2 0 2 2 0 2 1 2 0 2 2 0 0 0 0 2 2 1 0 0 2 2 2 0 1 0 1\n",
      " 0 2 2 2 2 2 2 1 1 2 0 1 2 1 1 2 2 0 2 1 0 1 2 0 0 1 2 2 0 1 2 1 0 2 2 1 2\n",
      " 2 2 2 1 2 0 2 1 1 0 2 0 1 0 2 2 2 2 2 1 0 2 1 1 2 1 2 0 1 2 2 0 2 1 1 0 1\n",
      " 2 0 2 2 0 1 1 0 2 1 1 2 0 1 0 1 0 1 0 2 1 0 0 0 1 1 1 1 0 2 0 1 2 2 1 0 2\n",
      " 2 2 0 0 2 2 2 2 1 0 1 1 1 2 0 2 2 1 2 1 2 0 0 2 1 0 2 0 2 0 1 0 0 2 1 2 0\n",
      " 2 1 2 2 0 1 2 0 1 1 2 1 1 2 2 2 2 1 2 2 1 2 1 2 0 0 2 0 0 2 1 1 1 1 0 2 1\n",
      " 1 1 0 1 1 0 0 2 1 1 1 2 2 1 2 1 2 1 2 0 2 0 1 0 1 1 0 2 2 2 0 0 0 1 0 0 2\n",
      " 2 0 1 1 0 2 0 2 0 2 0 2 0 0 1 1 0 2 1 2 1 1 2 1 0 2 1 2 1 1 2 0 1 2 1 0 2\n",
      " 1 0 2 0 0 2 0 0 2 0 0 2 2 0 1 1 2 2 2 2 1 0 0 2 2 0 2 1 0 1 2 0 2 2 2 2 2\n",
      " 2 2 0 2 0 1 1 2 2 0 0 0 2 0 2 1 0 0 2 2 0 0 2 2 1 0 2 2 1 0 2 0 0 2 0 2 0\n",
      " 2 1 1 1 1 0 1 0 2 1 2 1 2 2 2 1 0 2 2 2 0 0 0 2 2 1 0 0 2 2 1 0 2 1 2 1 2\n",
      " 0 0 0 2 2 0 0 0 1 2 1 2 2 1 0 0 2 2 1 2 0 0 1 0 1 2 2 2 1 1 2 1 2 2 0 1 1\n",
      " 1 2 1 1 2 2 1 2 2 1 1 2 2 0 2 1 2 0 2 0 2 0 0 1 1 1 2 1 1 0 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 4s 41ms/step - loss: 1.0949 - accuracy: 0.3867 - val_loss: 1.0905 - val_accuracy: 0.4309\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0873 - accuracy: 0.4282 - val_loss: 1.0871 - val_accuracy: 0.4309\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0762 - accuracy: 0.4268 - val_loss: 1.0807 - val_accuracy: 0.4309\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0629 - accuracy: 0.4337 - val_loss: 1.0743 - val_accuracy: 0.4309\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0422 - accuracy: 0.4420 - val_loss: 1.0684 - val_accuracy: 0.4254\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 1.0099 - accuracy: 0.4544 - val_loss: 1.0592 - val_accuracy: 0.4365\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.9704 - accuracy: 0.5166 - val_loss: 1.0485 - val_accuracy: 0.4586\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9368 - accuracy: 0.4724 - val_loss: 1.0453 - val_accuracy: 0.4696\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.8953 - accuracy: 0.5166 - val_loss: 1.0374 - val_accuracy: 0.4530\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.8796 - accuracy: 0.5028 - val_loss: 1.0361 - val_accuracy: 0.4530\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.8135 - accuracy: 0.5152 - val_loss: 1.0346 - val_accuracy: 0.4751\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8584 - accuracy: 0.5180 - val_loss: 1.0096 - val_accuracy: 0.4917\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8277 - accuracy: 0.5110 - val_loss: 1.0210 - val_accuracy: 0.4807\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7979 - accuracy: 0.5166 - val_loss: 1.0405 - val_accuracy: 0.5028\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7848 - accuracy: 0.5318 - val_loss: 1.0386 - val_accuracy: 0.5193\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7756 - accuracy: 0.5166 - val_loss: 1.0468 - val_accuracy: 0.5083\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7912 - accuracy: 0.5622 - val_loss: 1.0328 - val_accuracy: 0.5028\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7816 - accuracy: 0.5773 - val_loss: 1.0657 - val_accuracy: 0.5138\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7688 - accuracy: 0.5815 - val_loss: 1.1044 - val_accuracy: 0.5083\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7593 - accuracy: 0.5829 - val_loss: 1.0657 - val_accuracy: 0.4972\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7621 - accuracy: 0.5898 - val_loss: 1.0993 - val_accuracy: 0.4807\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7530 - accuracy: 0.5746 - val_loss: 1.0911 - val_accuracy: 0.5083\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7355 - accuracy: 0.6008 - val_loss: 1.0997 - val_accuracy: 0.5083\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7271 - accuracy: 0.6146 - val_loss: 1.1913 - val_accuracy: 0.5083\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7169 - accuracy: 0.6105 - val_loss: 1.1688 - val_accuracy: 0.5028\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7467 - accuracy: 0.6215 - val_loss: 1.1279 - val_accuracy: 0.4972\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.6965 - accuracy: 0.6519 - val_loss: 1.2315 - val_accuracy: 0.5249\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.6983 - accuracy: 0.6354 - val_loss: 1.2409 - val_accuracy: 0.5359\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.7025 - accuracy: 0.6312 - val_loss: 1.1975 - val_accuracy: 0.5359\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.6765 - accuracy: 0.6450 - val_loss: 1.2526 - val_accuracy: 0.5525\n",
      "15/15 [==============================] - 1s 5ms/step\n",
      "[2 2 0 0 0 1 2 1 2 1 0 0 2 2 0 2 1 2 0 1 2 0 0 0 2 2 2 0 0 0 2 2 2 0 1 0 0\n",
      " 0 1 2 2 2 2 2 0 0 2 0 1 2 0 0 2 2 2 2 0 0 1 2 0 2 0 2 2 2 0 2 0 0 2 2 0 2\n",
      " 1 2 2 1 2 2 2 1 0 2 2 0 1 0 2 2 2 2 2 0 0 0 0 2 2 2 2 0 1 1 2 0 2 1 0 2 1\n",
      " 2 2 0 2 0 0 0 0 2 0 2 2 0 2 2 1 0 0 0 2 2 2 0 0 2 0 0 1 0 2 0 0 2 2 2 0 2\n",
      " 2 0 0 0 2 2 2 2 0 0 0 1 0 1 0 2 2 2 2 1 2 0 1 0 1 0 2 0 2 0 1 0 0 2 0 2 0\n",
      " 2 0 2 2 1 1 0 0 0 0 2 1 0 2 0 0 2 0 1 2 2 2 0 2 2 0 2 2 0 0 0 2 0 0 0 2 0\n",
      " 0 1 2 0 0 0 0 0 1 0 1 2 2 2 2 1 2 0 2 0 2 0 1 0 0 1 0 2 2 2 0 0 0 0 0 0 2\n",
      " 2 0 0 0 0 2 1 2 2 2 0 2 0 0 1 0 0 0 1 0 1 2 2 0 0 2 2 0 1 0 2 0 1 2 0 0 2\n",
      " 0 0 2 0 1 1 0 0 2 2 2 2 2 0 0 0 2 2 2 2 0 0 2 2 2 0 0 0 0 0 2 0 2 2 2 0 1\n",
      " 2 2 0 0 0 1 0 2 2 0 0 0 2 0 1 0 0 0 2 0 0 1 1 2 0 2 2 2 2 0 2 0 0 2 0 2 1\n",
      " 2 1 0 0 0 0 0 2 1 2 2 0 2 2 2 1 0 2 0 2 1 0 0 2 2 0 2 0 2 2 0 0 2 1 2 2 2\n",
      " 0 0 0 2 2 0 0 0 2 2 0 2 1 0 0 2 2 2 1 2 2 2 0 2 0 2 2 2 0 0 2 2 2 2 0 2 2\n",
      " 1 2 0 0 2 2 0 2 2 1 0 2 2 2 2 0 2 0 2 0 2 0 2 0 2 2 2 1 0 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "23/23 [==============================] - 4s 73ms/step - loss: 1.0963 - accuracy: 0.3881 - val_loss: 1.0945 - val_accuracy: 0.4309\n",
      "Epoch 2/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0911 - accuracy: 0.4213 - val_loss: 1.0911 - val_accuracy: 0.4309\n",
      "Epoch 3/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0884 - accuracy: 0.4227 - val_loss: 1.0888 - val_accuracy: 0.4309\n",
      "Epoch 4/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 1.0867 - accuracy: 0.4227 - val_loss: 1.0871 - val_accuracy: 0.4309\n",
      "Epoch 5/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0830 - accuracy: 0.4227 - val_loss: 1.0845 - val_accuracy: 0.4309\n",
      "Epoch 6/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0799 - accuracy: 0.4213 - val_loss: 1.0829 - val_accuracy: 0.4309\n",
      "Epoch 7/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0733 - accuracy: 0.4309 - val_loss: 1.0789 - val_accuracy: 0.4309\n",
      "Epoch 8/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0633 - accuracy: 0.4627 - val_loss: 1.0752 - val_accuracy: 0.4309\n",
      "Epoch 9/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0490 - accuracy: 0.4710 - val_loss: 1.0712 - val_accuracy: 0.4807\n",
      "Epoch 10/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0252 - accuracy: 0.5055 - val_loss: 1.0650 - val_accuracy: 0.4586\n",
      "Epoch 11/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0099 - accuracy: 0.5069 - val_loss: 1.0650 - val_accuracy: 0.4365\n",
      "Epoch 12/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9916 - accuracy: 0.5152 - val_loss: 1.0615 - val_accuracy: 0.4696\n",
      "Epoch 13/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9631 - accuracy: 0.5428 - val_loss: 1.0548 - val_accuracy: 0.4475\n",
      "Epoch 14/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9342 - accuracy: 0.5359 - val_loss: 1.0537 - val_accuracy: 0.4033\n",
      "Epoch 15/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9314 - accuracy: 0.5608 - val_loss: 1.0445 - val_accuracy: 0.5028\n",
      "Epoch 16/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9223 - accuracy: 0.5318 - val_loss: 1.0398 - val_accuracy: 0.4807\n",
      "Epoch 17/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9043 - accuracy: 0.5566 - val_loss: 1.0376 - val_accuracy: 0.4641\n",
      "Epoch 18/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8944 - accuracy: 0.5677 - val_loss: 1.0350 - val_accuracy: 0.4917\n",
      "Epoch 19/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8592 - accuracy: 0.5635 - val_loss: 1.0395 - val_accuracy: 0.5083\n",
      "Epoch 20/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8537 - accuracy: 0.5691 - val_loss: 1.0518 - val_accuracy: 0.5028\n",
      "Epoch 21/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8397 - accuracy: 0.5815 - val_loss: 1.0702 - val_accuracy: 0.4751\n",
      "Epoch 22/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8179 - accuracy: 0.6298 - val_loss: 1.1066 - val_accuracy: 0.4862\n",
      "Epoch 23/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7969 - accuracy: 0.6492 - val_loss: 1.0988 - val_accuracy: 0.5028\n",
      "Epoch 24/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7978 - accuracy: 0.6354 - val_loss: 1.0909 - val_accuracy: 0.5028\n",
      "Epoch 25/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7737 - accuracy: 0.6478 - val_loss: 1.1179 - val_accuracy: 0.5028\n",
      "Epoch 26/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7472 - accuracy: 0.6506 - val_loss: 1.1341 - val_accuracy: 0.5193\n",
      "Epoch 27/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7808 - accuracy: 0.6436 - val_loss: 1.1299 - val_accuracy: 0.5083\n",
      "Epoch 28/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7328 - accuracy: 0.6796 - val_loss: 1.1421 - val_accuracy: 0.5138\n",
      "Epoch 29/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7412 - accuracy: 0.6533 - val_loss: 1.1656 - val_accuracy: 0.5249\n",
      "Epoch 30/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7388 - accuracy: 0.6561 - val_loss: 1.1799 - val_accuracy: 0.5193\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 1 0 0 1 1 0 0 1 2 0 2 2 1 2 1 2 2 1 0 1 0 2 2 2 2 1 0 0 2 2 2 0 1 1 2\n",
      " 1 0 0 2 2 2 2 1 1 2 2 1 2 1 0 2 2 2 2 1 0 1 2 0 2 1 0 2 0 1 0 2 0 2 2 2 2\n",
      " 1 2 2 1 2 0 2 1 1 0 2 1 1 2 2 2 2 2 2 1 0 0 0 2 0 0 2 0 1 0 2 1 0 1 2 2 0\n",
      " 2 2 2 2 1 0 1 2 1 1 2 2 1 0 2 1 2 1 0 0 0 2 0 2 0 1 1 1 0 0 0 1 2 2 2 0 0\n",
      " 2 0 1 0 2 2 0 2 1 0 1 1 0 1 0 2 2 1 2 1 2 1 0 0 1 1 2 0 2 0 1 2 0 2 1 2 0\n",
      " 2 1 2 2 0 0 1 0 1 1 2 1 1 0 1 0 2 1 2 0 0 2 1 0 2 0 0 2 0 2 1 2 0 2 2 2 1\n",
      " 1 0 2 1 1 0 0 0 1 1 1 2 2 0 2 1 2 1 2 0 2 0 1 2 1 1 0 2 2 2 0 0 2 1 0 0 2\n",
      " 2 0 0 0 2 0 2 1 2 2 1 2 0 0 1 1 2 2 0 0 1 0 2 1 1 2 0 1 1 0 2 1 1 2 1 0 2\n",
      " 1 0 1 0 2 0 0 0 2 2 0 2 2 0 1 0 0 2 2 2 1 0 2 2 2 0 0 1 0 1 2 0 2 0 0 1 2\n",
      " 2 0 2 1 0 1 1 2 2 0 0 0 2 0 1 1 1 0 2 2 0 2 2 2 0 2 2 2 0 0 2 2 0 2 0 2 0\n",
      " 2 1 0 1 0 1 0 0 1 0 2 1 1 2 2 1 2 2 2 2 2 0 1 2 2 0 0 0 2 2 1 0 0 1 2 1 2\n",
      " 0 2 0 2 2 0 0 0 1 2 2 2 1 1 1 2 2 2 0 0 2 2 0 2 1 2 2 2 0 1 2 2 2 2 0 2 1\n",
      " 1 2 1 1 2 0 1 2 0 1 0 2 2 0 2 0 2 0 1 1 2 0 2 1 0 1 2 0 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "for e in epochs:\n",
    "    for b in batch_sizes:\n",
    "        max_len = get_max_length(df_78516)\n",
    "        val_acc, test_acc = run_lstm(train=df_78516, test=df_78516_test, max_len=max_len,\n",
    "                                                seed=78516, epoch_val=e, b_size=b)\n",
    "        res_df[\"Dataset\"].append(\"78516\")\n",
    "        res_df[\"Seed\"].append(78516)\n",
    "        res_df[\"Epoch\"].append(e)\n",
    "        res_df[\"Batch-Size\"].append(b)\n",
    "        res_df[\"Val-Acc\"].append(val_acc)\n",
    "        res_df[\"Test-Acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 5s 20ms/step - loss: 1.0931 - accuracy: 0.4144 - val_loss: 1.0913 - val_accuracy: 0.4199\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0868 - accuracy: 0.4296 - val_loss: 1.0847 - val_accuracy: 0.4199\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0708 - accuracy: 0.4282 - val_loss: 1.0805 - val_accuracy: 0.4199\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0616 - accuracy: 0.4282 - val_loss: 1.0799 - val_accuracy: 0.4199\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0296 - accuracy: 0.4282 - val_loss: 1.0677 - val_accuracy: 0.4199\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9912 - accuracy: 0.4282 - val_loss: 1.1639 - val_accuracy: 0.4199\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9660 - accuracy: 0.4199 - val_loss: 1.0984 - val_accuracy: 0.4696\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9284 - accuracy: 0.5401 - val_loss: 1.1485 - val_accuracy: 0.4807\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9179 - accuracy: 0.5414 - val_loss: 1.0927 - val_accuracy: 0.4365\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.9052 - accuracy: 0.5401 - val_loss: 1.1985 - val_accuracy: 0.4530\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[0 0 2 2 2 2 0 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 2 2 0 2 0 0 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 0 2 0 2 0 2 2 2 0 0 0 0 2 0 2 2 0 0 2 2\n",
      " 2 2 2 2 2 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 0 2 2 2 2 2 2 2 2 0\n",
      " 2 2 2 2 0 2 2 2 2 0 2 2 0 0 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 0 0 2 2 2 2 0\n",
      " 0 2 0 2 0 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 2 0 0 0 2 2 2 0 2 2 2 0\n",
      " 0 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 2 0 2 2 2 2 0\n",
      " 2 2 2 0 2 0 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 0 0 2 2 0 0 0 0 2 2 2\n",
      " 0 2 0 0 2 2 2 2 2 0 2 2 2 0 0 2 2 2 0 2 2 2 2 2 0 0 2 2 2 0 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 2 2 2 2 2 0 2 0 0 2 0 2 2 0 2 2 2 0 2 2 2 2 0 2 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 0 2\n",
      " 2 0 2 2 0 2 2 2 2 2 0 2 2 2 0 0 2 2 0 0 2 0 0 0 0 2 2 0 0 2 2 2 2 2 0 2 2\n",
      " 0 0 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 0 2 2 2 2 2 0 0 2 0\n",
      " 2 0 2 0 2 0 2 2 2 2 2 0 0 2 2 2 2 2 0 0 2 0 0 2 2 2 0 0 2 0 0 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 5s 32ms/step - loss: 1.0969 - accuracy: 0.3798 - val_loss: 1.0928 - val_accuracy: 0.4199\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0901 - accuracy: 0.4268 - val_loss: 1.0881 - val_accuracy: 0.4199\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 1.0842 - accuracy: 0.4296 - val_loss: 1.0819 - val_accuracy: 0.4199\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0682 - accuracy: 0.4406 - val_loss: 1.0638 - val_accuracy: 0.4420\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 1.0465 - accuracy: 0.4765 - val_loss: 1.0592 - val_accuracy: 0.4641\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 1.0016 - accuracy: 0.5262 - val_loss: 1.0303 - val_accuracy: 0.4751\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9585 - accuracy: 0.5829 - val_loss: 0.9963 - val_accuracy: 0.5414\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.8936 - accuracy: 0.6312 - val_loss: 0.9898 - val_accuracy: 0.5304\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.8510 - accuracy: 0.6616 - val_loss: 0.9982 - val_accuracy: 0.5304\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8288 - accuracy: 0.6754 - val_loss: 0.9715 - val_accuracy: 0.5525\n",
      "15/15 [==============================] - 1s 5ms/step\n",
      "[1 1 2 2 1 2 0 2 2 2 0 2 0 2 2 2 0 2 2 2 2 2 2 1 1 1 0 1 1 1 1 2 2 2 0 0 2\n",
      " 1 1 2 2 2 2 2 2 0 2 2 1 2 1 2 1 2 2 1 0 2 0 0 0 2 0 1 2 2 2 2 2 2 0 2 1 1\n",
      " 1 1 2 1 1 0 1 1 0 2 1 2 2 2 2 2 1 2 2 2 2 2 1 2 2 1 2 0 1 0 2 2 1 1 2 2 2\n",
      " 2 2 2 2 0 2 2 1 2 1 1 2 1 0 2 2 1 1 1 2 1 2 2 2 2 2 1 1 2 2 2 0 2 2 2 1 0\n",
      " 1 2 0 1 0 2 2 2 2 2 2 2 2 2 2 0 1 1 2 2 1 1 2 2 0 0 0 2 0 2 2 1 1 2 2 2 2\n",
      " 2 1 2 2 2 2 2 1 2 2 2 1 0 2 1 2 2 1 1 2 2 2 0 2 0 2 2 0 2 2 2 2 2 2 2 2 1\n",
      " 2 2 2 0 2 2 2 1 1 2 2 2 2 2 2 2 2 0 0 2 2 2 2 1 2 2 2 2 2 2 1 2 1 1 2 2 2\n",
      " 0 1 0 0 1 1 2 0 0 0 2 2 2 0 2 1 2 1 0 1 2 2 0 2 1 0 2 2 2 0 1 0 2 0 2 1 2\n",
      " 1 2 2 1 2 2 1 1 2 2 1 2 0 1 1 1 2 0 1 2 2 2 2 0 2 1 2 0 2 2 2 2 0 2 2 2 2\n",
      " 2 2 2 1 2 0 2 1 2 2 1 2 2 2 1 2 2 2 0 2 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 0 2 2 0 2 1 1 1 0 0 2 2 0 1 2 2 2 2 2 2 2 1\n",
      " 1 0 2 2 1 2 0 2 0 2 2 1 1 0 2 2 2 2 2 2 1 1 2 2 1 0 2 1 1 2 2 2 2 0 0 1 0\n",
      " 2 2 1 2 1 0 0 2 2 2 2 0 2 1 2 2 2 2 0 2 1 1 2 2 2 2 1 1 2 1 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 4s 43ms/step - loss: 1.0964 - accuracy: 0.4157 - val_loss: 1.0949 - val_accuracy: 0.4254\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0920 - accuracy: 0.4434 - val_loss: 1.0912 - val_accuracy: 0.4199\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0861 - accuracy: 0.4544 - val_loss: 1.0872 - val_accuracy: 0.4254\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0755 - accuracy: 0.4669 - val_loss: 1.0806 - val_accuracy: 0.4254\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0511 - accuracy: 0.5083 - val_loss: 1.0705 - val_accuracy: 0.4586\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0071 - accuracy: 0.5331 - val_loss: 1.0751 - val_accuracy: 0.4475\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9665 - accuracy: 0.5608 - val_loss: 1.0855 - val_accuracy: 0.4475\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9318 - accuracy: 0.5704 - val_loss: 1.0539 - val_accuracy: 0.4751\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9346 - accuracy: 0.5594 - val_loss: 1.0605 - val_accuracy: 0.4696\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8978 - accuracy: 0.5787 - val_loss: 1.0558 - val_accuracy: 0.4751\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 1 1 2 2 2 2 2 2\n",
      " 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 1 2 2 1 2 2 2 2 1 2 2 1 2 1 2 2 2 1 1\n",
      " 2 1 2 1 1 1 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 2 2 1 2 2 2 1 1 2 2 2\n",
      " 1 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 1 1 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2\n",
      " 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 1 2 1 2 2 2 1 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 1 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 1 2\n",
      " 2 2 1 2 2 2 2 1 2 2 2 2 2 1 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 1 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1\n",
      " 1 2 2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 1 2 2 1 1 2 2 1 2 1 2 2 2 2 2 2 1 1 1 2\n",
      " 2 1 2 2 1 2 2 1 2 2 2 2 2 1 1 2 2 2 1 2 1 1 2 2 2 2 1 2 2 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 4s 61ms/step - loss: 1.0976 - accuracy: 0.3757 - val_loss: 1.0958 - val_accuracy: 0.4199\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 1.0924 - accuracy: 0.4282 - val_loss: 1.0920 - val_accuracy: 0.4199\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0874 - accuracy: 0.4365 - val_loss: 1.0890 - val_accuracy: 0.4199\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0812 - accuracy: 0.4309 - val_loss: 1.0841 - val_accuracy: 0.4199\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0738 - accuracy: 0.4296 - val_loss: 1.0799 - val_accuracy: 0.4199\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0697 - accuracy: 0.4517 - val_loss: 1.0739 - val_accuracy: 0.4199\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0501 - accuracy: 0.4434 - val_loss: 1.0669 - val_accuracy: 0.4199\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0356 - accuracy: 0.4696 - val_loss: 1.0582 - val_accuracy: 0.4309\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0292 - accuracy: 0.4793 - val_loss: 1.0591 - val_accuracy: 0.4309\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0032 - accuracy: 0.4738 - val_loss: 1.0455 - val_accuracy: 0.4420\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 2 2 2 2 0 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2\n",
      " 2 2 0 2 0 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_28 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "181/181 [==============================] - 6s 20ms/step - loss: 1.0949 - accuracy: 0.4268 - val_loss: 1.0910 - val_accuracy: 0.4199\n",
      "Epoch 2/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0858 - accuracy: 0.4296 - val_loss: 1.0854 - val_accuracy: 0.4199\n",
      "Epoch 3/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0764 - accuracy: 0.4323 - val_loss: 1.0800 - val_accuracy: 0.4254\n",
      "Epoch 4/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0365 - accuracy: 0.4807 - val_loss: 1.0606 - val_accuracy: 0.4475\n",
      "Epoch 5/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.9736 - accuracy: 0.5497 - val_loss: 1.0478 - val_accuracy: 0.4199\n",
      "Epoch 6/20\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8946 - accuracy: 0.5994 - val_loss: 1.0378 - val_accuracy: 0.4751\n",
      "Epoch 7/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8341 - accuracy: 0.6257 - val_loss: 1.0671 - val_accuracy: 0.4751\n",
      "Epoch 8/20\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 0.8278 - accuracy: 0.6243 - val_loss: 1.0889 - val_accuracy: 0.4807\n",
      "Epoch 9/20\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.7806 - accuracy: 0.6395 - val_loss: 1.0955 - val_accuracy: 0.4972\n",
      "Epoch 10/20\n",
      "181/181 [==============================] - 3s 17ms/step - loss: 0.7594 - accuracy: 0.6519 - val_loss: 1.0848 - val_accuracy: 0.5138\n",
      "Epoch 11/20\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.7422 - accuracy: 0.6602 - val_loss: 1.1467 - val_accuracy: 0.4641\n",
      "Epoch 12/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7373 - accuracy: 0.6561 - val_loss: 1.1800 - val_accuracy: 0.5028\n",
      "Epoch 13/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7095 - accuracy: 0.6671 - val_loss: 1.1103 - val_accuracy: 0.5304\n",
      "Epoch 14/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7099 - accuracy: 0.6740 - val_loss: 1.1790 - val_accuracy: 0.5249\n",
      "Epoch 15/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7001 - accuracy: 0.6837 - val_loss: 1.1989 - val_accuracy: 0.5359\n",
      "Epoch 16/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6758 - accuracy: 0.6920 - val_loss: 1.1970 - val_accuracy: 0.5304\n",
      "Epoch 17/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7060 - accuracy: 0.6699 - val_loss: 1.1912 - val_accuracy: 0.5193\n",
      "Epoch 18/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7049 - accuracy: 0.6713 - val_loss: 1.2610 - val_accuracy: 0.5304\n",
      "Epoch 19/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6851 - accuracy: 0.6920 - val_loss: 1.3167 - val_accuracy: 0.5138\n",
      "Epoch 20/20\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6855 - accuracy: 0.6823 - val_loss: 1.3943 - val_accuracy: 0.4807\n",
      "15/15 [==============================] - 1s 5ms/step\n",
      "[1 2 1 0 1 0 0 2 2 1 2 2 0 2 2 1 2 0 2 2 2 1 2 2 1 2 0 1 1 1 1 1 2 2 1 2 2\n",
      " 1 0 1 0 2 1 0 2 2 0 2 1 2 1 0 1 2 2 2 0 2 0 0 0 2 0 0 0 0 2 0 1 0 0 2 1 2\n",
      " 2 1 0 2 2 0 1 1 0 2 1 0 2 0 0 1 2 2 2 0 0 2 1 1 0 1 0 0 1 2 2 0 1 2 2 2 0\n",
      " 1 0 2 2 0 2 2 1 2 0 1 2 0 0 2 2 2 0 2 0 2 2 0 2 1 2 2 1 2 2 0 0 2 0 0 2 0\n",
      " 0 0 0 2 2 2 1 0 2 2 0 2 1 0 2 1 1 2 2 2 2 1 2 2 1 2 0 1 0 0 2 2 0 0 2 0 2\n",
      " 0 2 2 2 2 2 2 1 2 0 1 0 0 2 1 2 0 2 2 0 1 0 2 0 0 2 2 0 0 2 2 2 2 2 2 2 1\n",
      " 1 2 1 0 2 2 1 0 1 0 0 2 1 2 2 2 2 0 2 2 2 2 2 1 2 0 0 1 2 1 0 2 1 2 2 0 2\n",
      " 0 1 0 0 1 1 1 0 0 0 0 2 2 0 0 1 2 2 0 2 2 2 0 1 0 0 2 1 2 0 1 0 2 1 1 1 2\n",
      " 0 2 2 2 0 2 2 1 2 0 1 1 0 1 0 1 2 0 1 1 2 0 1 2 0 1 2 0 2 2 2 0 0 2 2 1 2\n",
      " 2 2 2 2 0 0 2 2 0 2 1 2 2 2 0 2 2 2 0 2 2 1 0 0 2 2 0 1 1 2 2 1 0 2 2 0 2\n",
      " 0 0 1 2 0 2 2 2 2 1 2 1 2 2 0 0 1 2 0 0 1 2 1 0 0 1 2 1 1 2 1 2 2 0 1 0 1\n",
      " 1 0 2 2 2 2 0 0 0 2 1 2 1 0 2 2 2 2 0 0 2 0 2 2 1 0 0 0 2 2 2 2 0 0 1 1 0\n",
      " 2 1 2 0 1 0 2 2 2 2 2 0 0 1 1 2 0 2 0 2 1 1 0 1 1 1 2 1 2 0 0 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_29 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "91/91 [==============================] - 6s 33ms/step - loss: 1.0944 - accuracy: 0.4116 - val_loss: 1.0839 - val_accuracy: 0.4199\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0747 - accuracy: 0.4006 - val_loss: 1.0758 - val_accuracy: 0.4199\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0548 - accuracy: 0.4530 - val_loss: 1.0462 - val_accuracy: 0.4862\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.9857 - accuracy: 0.5110 - val_loss: 1.0420 - val_accuracy: 0.4807\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9472 - accuracy: 0.5331 - val_loss: 1.0297 - val_accuracy: 0.4254\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8971 - accuracy: 0.5387 - val_loss: 1.0359 - val_accuracy: 0.4751\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8749 - accuracy: 0.5470 - val_loss: 1.0574 - val_accuracy: 0.4917\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8122 - accuracy: 0.5718 - val_loss: 1.0979 - val_accuracy: 0.4917\n",
      "Epoch 9/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8189 - accuracy: 0.5594 - val_loss: 1.0543 - val_accuracy: 0.4696\n",
      "Epoch 10/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7455 - accuracy: 0.5787 - val_loss: 1.1231 - val_accuracy: 0.4972\n",
      "Epoch 11/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7473 - accuracy: 0.5801 - val_loss: 1.2389 - val_accuracy: 0.5083\n",
      "Epoch 12/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7364 - accuracy: 0.5801 - val_loss: 1.0937 - val_accuracy: 0.4917\n",
      "Epoch 13/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7390 - accuracy: 0.5718 - val_loss: 1.1315 - val_accuracy: 0.4807\n",
      "Epoch 14/20\n",
      "91/91 [==============================] - 2s 25ms/step - loss: 0.7154 - accuracy: 0.5967 - val_loss: 1.2584 - val_accuracy: 0.5028\n",
      "Epoch 15/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7011 - accuracy: 0.5539 - val_loss: 1.2799 - val_accuracy: 0.4807\n",
      "Epoch 16/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7350 - accuracy: 0.5428 - val_loss: 1.1873 - val_accuracy: 0.4917\n",
      "Epoch 17/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7326 - accuracy: 0.5345 - val_loss: 1.1709 - val_accuracy: 0.4917\n",
      "Epoch 18/20\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.6871 - accuracy: 0.5967 - val_loss: 1.3920 - val_accuracy: 0.4862\n",
      "Epoch 19/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6997 - accuracy: 0.5787 - val_loss: 1.1715 - val_accuracy: 0.4530\n",
      "Epoch 20/20\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6829 - accuracy: 0.6105 - val_loss: 1.3273 - val_accuracy: 0.4530\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[0 0 0 0 2 2 0 2 2 1 2 0 0 2 2 2 0 2 2 2 2 0 2 2 2 2 0 1 2 0 0 2 2 2 0 0 2\n",
      " 0 1 2 1 2 2 0 2 0 0 2 1 2 2 0 1 2 0 1 0 2 0 0 0 2 0 0 0 2 2 0 2 0 0 2 1 2\n",
      " 2 0 0 0 1 0 0 2 0 2 0 0 2 2 2 0 1 2 2 2 1 1 0 2 0 0 2 0 1 0 2 2 1 2 2 2 2\n",
      " 1 1 2 2 0 2 0 1 2 0 1 2 0 0 2 2 2 0 1 2 1 2 2 2 2 2 2 0 2 2 0 0 2 2 2 2 0\n",
      " 0 2 0 2 2 2 2 2 2 2 1 2 2 2 2 0 1 2 2 1 2 2 2 2 0 2 0 2 0 2 2 2 0 2 2 2 2\n",
      " 0 1 2 2 2 1 2 1 2 0 2 1 0 2 0 2 0 1 2 2 2 0 2 1 0 2 2 2 1 2 2 2 1 2 2 2 1\n",
      " 2 1 2 0 0 2 2 2 0 2 0 0 2 2 2 2 2 0 2 2 2 2 2 1 2 0 0 2 2 2 1 2 1 0 2 2 2\n",
      " 1 1 0 0 0 1 2 1 0 0 1 2 0 1 2 0 2 2 0 0 1 2 2 2 0 0 2 0 0 0 0 0 0 0 2 0 2\n",
      " 0 2 2 1 2 2 0 2 2 0 2 2 2 1 2 1 2 0 1 2 0 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2\n",
      " 2 2 2 1 0 2 2 1 0 2 1 2 2 2 0 2 2 2 0 2 1 1 2 1 0 2 2 1 2 0 2 2 1 2 2 0 2\n",
      " 0 1 2 2 2 0 2 2 1 2 2 0 2 2 0 0 1 2 0 0 1 0 1 0 0 2 2 0 2 2 0 2 2 2 2 2 0\n",
      " 0 0 2 1 2 2 0 0 0 2 2 2 1 0 0 2 0 1 1 0 0 0 2 2 2 0 0 0 1 2 2 2 0 0 0 2 0\n",
      " 2 0 2 0 1 0 1 1 2 2 2 0 0 0 1 2 2 2 2 2 1 2 0 2 2 0 1 2 2 0 0 1]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 4s 41ms/step - loss: 1.0965 - accuracy: 0.4088 - val_loss: 1.0925 - val_accuracy: 0.4199\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0889 - accuracy: 0.4282 - val_loss: 1.0867 - val_accuracy: 0.4199\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 1.0800 - accuracy: 0.4282 - val_loss: 1.0812 - val_accuracy: 0.4199\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0780 - accuracy: 0.4282 - val_loss: 1.0772 - val_accuracy: 0.4199\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0637 - accuracy: 0.4282 - val_loss: 1.0675 - val_accuracy: 0.4199\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0376 - accuracy: 0.4876 - val_loss: 1.0484 - val_accuracy: 0.4420\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0051 - accuracy: 0.5235 - val_loss: 1.0383 - val_accuracy: 0.4917\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9878 - accuracy: 0.5511 - val_loss: 1.0202 - val_accuracy: 0.4917\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9132 - accuracy: 0.6119 - val_loss: 0.9958 - val_accuracy: 0.5028\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8987 - accuracy: 0.6271 - val_loss: 1.0055 - val_accuracy: 0.5028\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8879 - accuracy: 0.6077 - val_loss: 1.0050 - val_accuracy: 0.5083\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8684 - accuracy: 0.6215 - val_loss: 1.0238 - val_accuracy: 0.4696\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8203 - accuracy: 0.6464 - val_loss: 1.0669 - val_accuracy: 0.4641\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8306 - accuracy: 0.6298 - val_loss: 1.0345 - val_accuracy: 0.4972\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7952 - accuracy: 0.6561 - val_loss: 1.0332 - val_accuracy: 0.5083\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7668 - accuracy: 0.6671 - val_loss: 1.1092 - val_accuracy: 0.4751\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7542 - accuracy: 0.6575 - val_loss: 1.0979 - val_accuracy: 0.4862\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7414 - accuracy: 0.6492 - val_loss: 1.1058 - val_accuracy: 0.4862\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7332 - accuracy: 0.6837 - val_loss: 1.1076 - val_accuracy: 0.4972\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7163 - accuracy: 0.6892 - val_loss: 1.1878 - val_accuracy: 0.4917\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[0 0 0 0 0 2 0 0 2 0 2 2 0 2 2 2 2 0 2 2 2 0 2 2 1 1 0 2 2 0 0 2 2 0 0 2 2\n",
      " 2 2 0 0 0 2 0 2 0 0 2 0 1 0 2 0 2 0 0 2 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2 0 2\n",
      " 0 0 0 0 2 0 2 2 0 0 0 0 2 2 0 0 2 2 2 2 0 0 0 2 0 0 2 0 0 0 2 2 1 2 2 2 0\n",
      " 0 2 2 2 0 2 0 0 2 0 0 2 0 0 1 2 2 0 0 2 0 2 2 2 2 2 2 0 2 0 0 0 2 2 0 2 0\n",
      " 0 2 0 2 0 2 1 0 2 2 0 2 2 2 2 0 0 2 2 1 0 2 2 0 0 0 0 2 0 2 2 2 0 2 2 2 2\n",
      " 0 2 2 2 2 1 0 0 2 0 2 0 0 2 0 2 0 0 0 2 0 0 2 0 0 2 2 0 1 2 2 2 2 2 2 0 0\n",
      " 2 2 2 0 0 2 2 2 1 2 0 0 0 2 2 0 2 0 2 2 2 2 2 2 2 0 0 2 2 2 0 2 0 0 2 2 2\n",
      " 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 2 2 0 0 0 2 2 2 0 0 2 2 1 0 2 0 2 0 2 0 2\n",
      " 0 2 2 0 2 2 0 2 2 1 0 2 2 0 0 0 2 0 0 2 2 2 0 0 2 2 2 2 0 2 2 2 0 2 2 2 2\n",
      " 2 2 2 2 0 2 2 0 0 2 2 2 2 2 0 2 2 2 0 0 0 0 2 0 1 2 2 0 2 0 2 2 2 2 2 0 0\n",
      " 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 0 0 0 0 0 0 0 2 0 2 2 1 1 2 2 2 2 0\n",
      " 0 0 2 0 0 2 0 0 0 0 2 2 0 0 0 2 1 2 2 0 0 0 2 1 0 0 0 0 0 2 2 2 0 0 0 2 0\n",
      " 2 0 2 0 1 0 2 0 2 2 2 0 0 0 0 2 0 2 2 2 0 1 0 2 2 0 0 2 2 0 0 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 4s 61ms/step - loss: 1.0973 - accuracy: 0.4033 - val_loss: 1.0946 - val_accuracy: 0.4199\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0934 - accuracy: 0.4185 - val_loss: 1.0899 - val_accuracy: 0.4199\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0846 - accuracy: 0.4268 - val_loss: 1.0836 - val_accuracy: 0.4199\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0808 - accuracy: 0.4227 - val_loss: 1.0796 - val_accuracy: 0.4254\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0689 - accuracy: 0.4530 - val_loss: 1.0730 - val_accuracy: 0.4420\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0454 - accuracy: 0.5000 - val_loss: 1.0562 - val_accuracy: 0.4420\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0198 - accuracy: 0.4890 - val_loss: 1.0333 - val_accuracy: 0.4751\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9942 - accuracy: 0.4972 - val_loss: 1.0219 - val_accuracy: 0.4696\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9731 - accuracy: 0.4972 - val_loss: 1.0260 - val_accuracy: 0.4862\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9214 - accuracy: 0.5152 - val_loss: 1.0211 - val_accuracy: 0.4807\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9098 - accuracy: 0.5097 - val_loss: 1.0292 - val_accuracy: 0.4586\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8795 - accuracy: 0.5180 - val_loss: 1.0283 - val_accuracy: 0.4475\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8794 - accuracy: 0.5138 - val_loss: 1.0081 - val_accuracy: 0.4641\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.8739 - accuracy: 0.5318 - val_loss: 1.0062 - val_accuracy: 0.4751\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8554 - accuracy: 0.5318 - val_loss: 1.0105 - val_accuracy: 0.4696\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8564 - accuracy: 0.4876 - val_loss: 1.0227 - val_accuracy: 0.4586\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8468 - accuracy: 0.5276 - val_loss: 1.0257 - val_accuracy: 0.4641\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8179 - accuracy: 0.5401 - val_loss: 1.0291 - val_accuracy: 0.4696\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8205 - accuracy: 0.5470 - val_loss: 1.0487 - val_accuracy: 0.4530\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8243 - accuracy: 0.5290 - val_loss: 1.0622 - val_accuracy: 0.4475\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 1 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 1 2 2 2 2 2 2\n",
      " 1 2 2 2 2 1 2 2 2 2 2 1 2 2 2 1 2 2 1 2 2 1 2 2 2 2 1 2 2 2 2 1 2 2 2 1 1\n",
      " 2 1 2 1 1 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 2 2 1 1 1 1 2 2 1 2 2 2 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 1 1 1 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 1 2\n",
      " 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 1 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 1 2 2 2 2 2 1 2 1 1 2 2 2\n",
      " 2 1 2 2 1 1 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2\n",
      " 2 2 2 2 1 1 1 1 2 2 1 1 2 1 1 2 2 2 1 2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 1 2 2\n",
      " 2 2 2 1 2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 2 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1\n",
      " 1 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 2 2 2 2 1 2 1 2\n",
      " 2 1 1 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/simonli/opt/anaconda3/envs/ml135_env_sp23/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_32 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "181/181 [==============================] - 5s 19ms/step - loss: 1.0956 - accuracy: 0.4033 - val_loss: 1.0898 - val_accuracy: 0.4199\n",
      "Epoch 2/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0749 - accuracy: 0.4296 - val_loss: 1.0798 - val_accuracy: 0.4199\n",
      "Epoch 3/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 1.0343 - accuracy: 0.4876 - val_loss: 1.0851 - val_accuracy: 0.4751\n",
      "Epoch 4/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9758 - accuracy: 0.5235 - val_loss: 1.0381 - val_accuracy: 0.5193\n",
      "Epoch 5/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.9072 - accuracy: 0.5414 - val_loss: 1.0956 - val_accuracy: 0.5083\n",
      "Epoch 6/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8679 - accuracy: 0.5856 - val_loss: 1.1009 - val_accuracy: 0.5028\n",
      "Epoch 7/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.8249 - accuracy: 0.5967 - val_loss: 1.1740 - val_accuracy: 0.5028\n",
      "Epoch 8/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.8102 - accuracy: 0.6119 - val_loss: 1.1343 - val_accuracy: 0.4917\n",
      "Epoch 9/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7842 - accuracy: 0.6008 - val_loss: 1.2273 - val_accuracy: 0.4972\n",
      "Epoch 10/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7525 - accuracy: 0.6174 - val_loss: 1.2209 - val_accuracy: 0.4972\n",
      "Epoch 11/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7288 - accuracy: 0.6367 - val_loss: 1.2401 - val_accuracy: 0.5083\n",
      "Epoch 12/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7414 - accuracy: 0.6243 - val_loss: 1.2710 - val_accuracy: 0.5083\n",
      "Epoch 13/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.7466 - accuracy: 0.6174 - val_loss: 1.3375 - val_accuracy: 0.4917\n",
      "Epoch 14/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7319 - accuracy: 0.6312 - val_loss: 1.3160 - val_accuracy: 0.5028\n",
      "Epoch 15/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7051 - accuracy: 0.6312 - val_loss: 1.4068 - val_accuracy: 0.4751\n",
      "Epoch 16/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7294 - accuracy: 0.6146 - val_loss: 1.3523 - val_accuracy: 0.4972\n",
      "Epoch 17/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6896 - accuracy: 0.6326 - val_loss: 1.4481 - val_accuracy: 0.4972\n",
      "Epoch 18/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7279 - accuracy: 0.6160 - val_loss: 1.4207 - val_accuracy: 0.4807\n",
      "Epoch 19/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7050 - accuracy: 0.6285 - val_loss: 1.4164 - val_accuracy: 0.4972\n",
      "Epoch 20/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7023 - accuracy: 0.6229 - val_loss: 1.4182 - val_accuracy: 0.4862\n",
      "Epoch 21/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6961 - accuracy: 0.6160 - val_loss: 1.4015 - val_accuracy: 0.4972\n",
      "Epoch 22/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.7089 - accuracy: 0.6133 - val_loss: 1.4362 - val_accuracy: 0.4751\n",
      "Epoch 23/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6943 - accuracy: 0.6215 - val_loss: 1.4649 - val_accuracy: 0.4862\n",
      "Epoch 24/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6767 - accuracy: 0.6312 - val_loss: 1.4318 - val_accuracy: 0.4972\n",
      "Epoch 25/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6336 - accuracy: 0.6506 - val_loss: 1.3281 - val_accuracy: 0.4972\n",
      "Epoch 26/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6347 - accuracy: 0.6188 - val_loss: 1.4820 - val_accuracy: 0.4972\n",
      "Epoch 27/30\n",
      "181/181 [==============================] - 3s 14ms/step - loss: 0.6643 - accuracy: 0.5635 - val_loss: 1.3601 - val_accuracy: 0.4917\n",
      "Epoch 28/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6626 - accuracy: 0.6022 - val_loss: 1.5629 - val_accuracy: 0.5138\n",
      "Epoch 29/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6348 - accuracy: 0.6243 - val_loss: 1.4623 - val_accuracy: 0.5138\n",
      "Epoch 30/30\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.6254 - accuracy: 0.6160 - val_loss: 1.5267 - val_accuracy: 0.5414\n",
      "15/15 [==============================] - 1s 5ms/step\n",
      "[1 2 2 0 2 1 0 2 1 1 1 2 0 2 2 2 1 1 2 2 2 0 2 2 0 2 0 2 1 1 1 0 2 0 0 1 2\n",
      " 2 1 1 0 2 1 0 2 1 0 2 2 2 2 2 1 2 1 1 1 2 1 2 0 2 0 1 0 2 1 0 2 2 0 1 1 2\n",
      " 1 2 2 2 1 0 1 1 0 1 1 0 2 1 2 0 2 2 2 2 0 1 0 1 0 1 2 0 1 2 2 2 1 2 2 2 0\n",
      " 2 1 2 2 0 2 2 1 2 0 0 2 0 0 1 2 2 0 1 2 2 2 2 2 1 2 2 1 1 2 0 0 2 2 2 2 0\n",
      " 0 1 0 2 1 2 2 2 2 2 0 2 2 1 2 0 1 1 2 0 1 2 2 1 1 2 0 2 0 1 2 2 0 2 2 2 2\n",
      " 0 0 1 2 1 1 2 1 2 0 2 2 0 2 1 2 0 1 2 1 2 0 2 1 0 2 0 2 1 2 2 2 2 2 2 2 1\n",
      " 2 1 2 0 1 0 2 1 1 0 0 2 2 2 2 1 2 0 1 2 2 2 2 1 2 0 0 1 2 2 0 2 1 2 2 2 2\n",
      " 0 1 0 0 1 1 2 0 0 0 2 2 0 0 0 2 2 2 0 1 2 2 2 2 0 0 2 2 0 0 2 0 2 1 1 1 2\n",
      " 2 2 2 1 1 2 2 1 2 1 2 1 1 1 2 1 2 0 1 2 2 2 2 2 2 1 2 0 1 2 2 1 0 2 2 1 2\n",
      " 2 2 2 2 1 1 2 1 1 2 0 2 2 2 0 2 2 2 0 2 2 1 2 2 2 2 2 1 2 2 2 2 1 0 2 0 2\n",
      " 0 0 2 2 1 2 2 2 2 2 2 2 2 2 0 0 2 2 0 0 1 1 2 0 0 1 2 0 1 2 0 2 2 1 1 1 1\n",
      " 1 0 2 2 2 2 0 0 0 1 1 2 1 0 0 2 2 2 1 0 1 0 2 0 2 0 0 0 1 2 0 0 2 0 1 1 0\n",
      " 1 1 1 1 1 0 1 1 2 2 2 0 0 1 2 2 1 2 1 1 1 2 0 2 2 1 2 1 2 0 0 0]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_33 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "91/91 [==============================] - 5s 32ms/step - loss: 1.0920 - accuracy: 0.4130 - val_loss: 1.0870 - val_accuracy: 0.4199\n",
      "Epoch 2/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0839 - accuracy: 0.4254 - val_loss: 1.0754 - val_accuracy: 0.4199\n",
      "Epoch 3/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0530 - accuracy: 0.4254 - val_loss: 1.0549 - val_accuracy: 0.4199\n",
      "Epoch 4/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0321 - accuracy: 0.4213 - val_loss: 1.0463 - val_accuracy: 0.4199\n",
      "Epoch 5/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 1.0118 - accuracy: 0.4558 - val_loss: 1.0216 - val_accuracy: 0.4254\n",
      "Epoch 6/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9583 - accuracy: 0.5097 - val_loss: 1.0226 - val_accuracy: 0.4530\n",
      "Epoch 7/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.9218 - accuracy: 0.4876 - val_loss: 1.0177 - val_accuracy: 0.4420\n",
      "Epoch 8/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8660 - accuracy: 0.5193 - val_loss: 1.0199 - val_accuracy: 0.4530\n",
      "Epoch 9/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8836 - accuracy: 0.5401 - val_loss: 1.0035 - val_accuracy: 0.4475\n",
      "Epoch 10/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.8402 - accuracy: 0.5511 - val_loss: 1.0151 - val_accuracy: 0.4862\n",
      "Epoch 11/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7673 - accuracy: 0.5511 - val_loss: 1.0655 - val_accuracy: 0.4696\n",
      "Epoch 12/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7595 - accuracy: 0.5566 - val_loss: 1.0679 - val_accuracy: 0.4586\n",
      "Epoch 13/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7779 - accuracy: 0.5290 - val_loss: 1.0441 - val_accuracy: 0.4751\n",
      "Epoch 14/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6974 - accuracy: 0.6105 - val_loss: 1.1429 - val_accuracy: 0.4309\n",
      "Epoch 15/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.7075 - accuracy: 0.5898 - val_loss: 1.1158 - val_accuracy: 0.4530\n",
      "Epoch 16/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6746 - accuracy: 0.6160 - val_loss: 1.1684 - val_accuracy: 0.4696\n",
      "Epoch 17/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6802 - accuracy: 0.6285 - val_loss: 1.2372 - val_accuracy: 0.4530\n",
      "Epoch 18/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6779 - accuracy: 0.6091 - val_loss: 1.2178 - val_accuracy: 0.4199\n",
      "Epoch 19/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6599 - accuracy: 0.6215 - val_loss: 1.3014 - val_accuracy: 0.4420\n",
      "Epoch 20/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6408 - accuracy: 0.6713 - val_loss: 1.2148 - val_accuracy: 0.4420\n",
      "Epoch 21/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6093 - accuracy: 0.6796 - val_loss: 1.4022 - val_accuracy: 0.4309\n",
      "Epoch 22/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6313 - accuracy: 0.6699 - val_loss: 1.4354 - val_accuracy: 0.4420\n",
      "Epoch 23/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6230 - accuracy: 0.6823 - val_loss: 1.3809 - val_accuracy: 0.4309\n",
      "Epoch 24/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6035 - accuracy: 0.7182 - val_loss: 1.4124 - val_accuracy: 0.4254\n",
      "Epoch 25/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6136 - accuracy: 0.6906 - val_loss: 1.6333 - val_accuracy: 0.4254\n",
      "Epoch 26/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6219 - accuracy: 0.6920 - val_loss: 1.5762 - val_accuracy: 0.4530\n",
      "Epoch 27/30\n",
      "91/91 [==============================] - 2s 24ms/step - loss: 0.5820 - accuracy: 0.7210 - val_loss: 1.5563 - val_accuracy: 0.4530\n",
      "Epoch 28/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.5964 - accuracy: 0.7169 - val_loss: 1.6416 - val_accuracy: 0.4530\n",
      "Epoch 29/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.6075 - accuracy: 0.6975 - val_loss: 1.6469 - val_accuracy: 0.4365\n",
      "Epoch 30/30\n",
      "91/91 [==============================] - 2s 23ms/step - loss: 0.5837 - accuracy: 0.7196 - val_loss: 2.1426 - val_accuracy: 0.4475\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 1 0 0 1 2 2 2 2 1 2 2 0 2 2 2 2 2 2 2 2 1 2 2 0 2 0 2 0 1 1 2 2 0 2 2 2\n",
      " 2 2 0 0 2 2 0 2 2 0 2 1 2 2 0 1 2 2 1 2 2 1 2 2 2 0 1 2 2 2 0 2 2 0 2 1 2\n",
      " 2 1 1 0 1 1 2 2 1 2 2 0 2 2 2 1 0 2 2 2 0 2 1 2 0 1 2 0 1 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 0 2 2 1 2 1 2 2 0 0 2 2 0 1 1 2 2 2 2 2 2 2 2 1 2 2 2 0 2 2 2 1 0\n",
      " 1 2 0 2 0 2 2 2 2 2 2 2 2 2 2 0 1 2 2 1 2 2 2 2 1 2 0 2 0 2 2 2 1 2 2 2 2\n",
      " 0 2 2 2 2 1 2 1 2 2 2 2 0 2 1 2 2 1 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 0 2 0 2 2 2 2 2 1 2 0 2 2 2 2 1 2 1 1 2 2 2\n",
      " 2 1 2 2 1 1 2 2 0 0 2 2 2 2 2 0 2 2 0 0 2 2 2 2 1 0 2 1 2 0 0 2 2 1 0 1 2\n",
      " 0 2 2 2 1 2 0 2 2 0 1 2 2 2 2 2 2 0 1 2 2 2 2 2 2 2 2 2 1 2 2 2 0 2 2 2 2\n",
      " 2 2 2 1 2 2 2 1 2 2 2 2 2 2 0 2 2 2 2 2 1 1 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 0 1 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 2 1 1 1 0 0 2 2 0 2 2 1 2 2 2 2 2 1\n",
      " 1 2 2 2 2 2 0 2 0 1 2 2 2 0 0 2 0 2 0 0 0 0 2 2 2 0 0 0 0 2 2 2 0 0 1 1 0\n",
      " 2 2 0 2 1 0 2 2 2 2 2 0 0 1 2 2 2 2 2 2 1 2 0 2 2 2 0 2 2 0 1 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_34 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 4s 42ms/step - loss: 1.0939 - accuracy: 0.4130 - val_loss: 1.0912 - val_accuracy: 0.4199\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0864 - accuracy: 0.4227 - val_loss: 1.0853 - val_accuracy: 0.4199\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 1.0737 - accuracy: 0.4434 - val_loss: 1.0795 - val_accuracy: 0.4199\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 1.0616 - accuracy: 0.4240 - val_loss: 1.0683 - val_accuracy: 0.4199\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0354 - accuracy: 0.4448 - val_loss: 1.0531 - val_accuracy: 0.4199\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.0308 - accuracy: 0.4641 - val_loss: 1.0440 - val_accuracy: 0.4199\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9925 - accuracy: 0.5276 - val_loss: 1.0375 - val_accuracy: 0.4530\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.9986 - accuracy: 0.4986 - val_loss: 1.0433 - val_accuracy: 0.4530\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9711 - accuracy: 0.5304 - val_loss: 1.0226 - val_accuracy: 0.4641\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9528 - accuracy: 0.5276 - val_loss: 1.0234 - val_accuracy: 0.4530\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.9573 - accuracy: 0.5124 - val_loss: 1.0229 - val_accuracy: 0.4309\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9351 - accuracy: 0.5428 - val_loss: 1.0217 - val_accuracy: 0.4696\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9298 - accuracy: 0.5345 - val_loss: 1.0141 - val_accuracy: 0.4696\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8854 - accuracy: 0.5704 - val_loss: 1.0022 - val_accuracy: 0.4862\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9135 - accuracy: 0.5483 - val_loss: 1.0047 - val_accuracy: 0.4862\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8482 - accuracy: 0.5787 - val_loss: 0.9994 - val_accuracy: 0.5083\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.8718 - accuracy: 0.5622 - val_loss: 0.9959 - val_accuracy: 0.4862\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8764 - accuracy: 0.5483 - val_loss: 0.9948 - val_accuracy: 0.5304\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.8449 - accuracy: 0.5677 - val_loss: 0.9914 - val_accuracy: 0.5193\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.8310 - accuracy: 0.5760 - val_loss: 0.9837 - val_accuracy: 0.5028\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.8140 - accuracy: 0.6202 - val_loss: 0.9859 - val_accuracy: 0.5470\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7572 - accuracy: 0.6395 - val_loss: 0.9620 - val_accuracy: 0.5028\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7476 - accuracy: 0.6381 - val_loss: 0.9968 - val_accuracy: 0.4751\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7433 - accuracy: 0.6436 - val_loss: 1.0117 - val_accuracy: 0.4917\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7129 - accuracy: 0.6644 - val_loss: 1.0344 - val_accuracy: 0.4807\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.7447 - accuracy: 0.6298 - val_loss: 1.0495 - val_accuracy: 0.5193\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6889 - accuracy: 0.6727 - val_loss: 1.0151 - val_accuracy: 0.4696\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.7173 - accuracy: 0.6423 - val_loss: 1.0489 - val_accuracy: 0.4972\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6742 - accuracy: 0.6754 - val_loss: 1.0559 - val_accuracy: 0.4972\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6615 - accuracy: 0.6727 - val_loss: 1.0699 - val_accuracy: 0.4917\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[1 1 2 0 1 2 0 0 2 1 0 0 1 2 2 2 2 2 2 2 2 1 2 1 2 1 0 1 1 1 1 1 2 2 2 2 2\n",
      " 1 2 2 1 2 2 0 2 2 0 2 1 2 1 0 1 2 2 1 0 2 1 0 0 2 0 1 0 2 2 0 1 0 0 2 1 1\n",
      " 1 1 0 1 2 0 1 2 0 0 1 0 2 2 2 0 1 2 2 2 0 2 1 1 0 1 2 0 1 0 2 2 1 2 2 2 2\n",
      " 2 2 2 2 0 2 2 1 2 0 1 2 0 0 2 2 1 0 1 2 2 2 2 2 1 2 1 1 2 0 0 0 2 0 0 1 0\n",
      " 1 2 0 2 0 2 1 2 2 2 0 2 2 2 2 2 1 1 2 1 2 2 2 1 0 2 0 2 0 2 2 2 1 2 2 2 2\n",
      " 0 0 2 2 0 0 2 1 2 0 2 0 0 2 1 2 0 1 0 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 1 0 2 0 2 2 2 2 2 2 0 2 2 2 2 2 1 1 0 0 2 2 2 1 2 1 1 2 2 2\n",
      " 0 1 0 0 1 1 2 0 0 0 0 2 2 0 0 1 2 1 0 2 1 2 2 2 0 0 2 2 2 0 1 0 2 2 2 1 2\n",
      " 0 2 2 1 1 2 1 2 2 2 1 1 2 1 2 2 2 0 1 2 2 2 1 2 0 1 2 0 2 2 2 2 0 2 2 2 2\n",
      " 2 2 2 1 2 0 2 1 2 2 1 2 2 2 0 2 2 2 0 1 1 1 0 0 2 2 2 1 2 2 2 0 2 2 2 0 0\n",
      " 0 0 1 2 0 2 2 2 1 2 0 1 2 2 1 0 2 2 0 0 1 1 1 0 0 2 2 0 1 2 0 2 2 2 2 2 1\n",
      " 1 0 2 2 0 2 0 0 0 1 2 1 1 0 1 2 2 1 0 0 1 1 2 2 1 0 0 0 1 2 2 2 0 0 1 1 0\n",
      " 2 1 1 0 1 0 0 0 2 2 2 0 0 1 0 2 2 2 1 2 1 1 0 2 2 0 0 2 2 0 0 2]\n",
      "Shape of train tensor:  (724, 86)\n",
      "Shape of test tensor:  (476, 86)\n",
      "Shape of valid tensor:  (181, 86)\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_35 (Embedding)    (None, 86, 16)            32000     \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 4)                 336       \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 5)                 25        \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,379\n",
      "Trainable params: 32,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "23/23 [==============================] - 4s 60ms/step - loss: 1.0974 - accuracy: 0.3771 - val_loss: 1.0962 - val_accuracy: 0.4199\n",
      "Epoch 2/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0930 - accuracy: 0.4406 - val_loss: 1.0928 - val_accuracy: 0.4199\n",
      "Epoch 3/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 1.0865 - accuracy: 0.4586 - val_loss: 1.0892 - val_accuracy: 0.4309\n",
      "Epoch 4/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0788 - accuracy: 0.4696 - val_loss: 1.0862 - val_accuracy: 0.4365\n",
      "Epoch 5/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 1.0698 - accuracy: 0.4586 - val_loss: 1.0833 - val_accuracy: 0.4309\n",
      "Epoch 6/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0548 - accuracy: 0.4820 - val_loss: 1.0752 - val_accuracy: 0.4586\n",
      "Epoch 7/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 1.0199 - accuracy: 0.5069 - val_loss: 1.0693 - val_accuracy: 0.4365\n",
      "Epoch 8/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9983 - accuracy: 0.5124 - val_loss: 1.0711 - val_accuracy: 0.4365\n",
      "Epoch 9/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9781 - accuracy: 0.5166 - val_loss: 1.0570 - val_accuracy: 0.4420\n",
      "Epoch 10/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.9402 - accuracy: 0.5663 - val_loss: 1.0591 - val_accuracy: 0.4641\n",
      "Epoch 11/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.9064 - accuracy: 0.5912 - val_loss: 1.0535 - val_accuracy: 0.4917\n",
      "Epoch 12/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8861 - accuracy: 0.6077 - val_loss: 1.0531 - val_accuracy: 0.5138\n",
      "Epoch 13/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.8824 - accuracy: 0.5967 - val_loss: 1.0550 - val_accuracy: 0.5028\n",
      "Epoch 14/30\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.8597 - accuracy: 0.6174 - val_loss: 1.0641 - val_accuracy: 0.4641\n",
      "Epoch 15/30\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.8368 - accuracy: 0.6229 - val_loss: 1.0786 - val_accuracy: 0.4586\n",
      "Epoch 16/30\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.8322 - accuracy: 0.6008 - val_loss: 1.1059 - val_accuracy: 0.4254\n",
      "Epoch 17/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.8334 - accuracy: 0.5663 - val_loss: 1.0843 - val_accuracy: 0.4751\n",
      "Epoch 18/30\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.8140 - accuracy: 0.5925 - val_loss: 1.0874 - val_accuracy: 0.4917\n",
      "Epoch 19/30\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.7876 - accuracy: 0.6133 - val_loss: 1.1224 - val_accuracy: 0.4696\n",
      "Epoch 20/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7731 - accuracy: 0.6257 - val_loss: 1.1408 - val_accuracy: 0.4807\n",
      "Epoch 21/30\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.7770 - accuracy: 0.6229 - val_loss: 1.1287 - val_accuracy: 0.4751\n",
      "Epoch 22/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.7787 - accuracy: 0.6064 - val_loss: 1.1582 - val_accuracy: 0.4641\n",
      "Epoch 23/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7869 - accuracy: 0.5981 - val_loss: 1.1968 - val_accuracy: 0.4751\n",
      "Epoch 24/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7529 - accuracy: 0.6257 - val_loss: 1.1798 - val_accuracy: 0.4586\n",
      "Epoch 25/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.7527 - accuracy: 0.6285 - val_loss: 1.1917 - val_accuracy: 0.4807\n",
      "Epoch 26/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7341 - accuracy: 0.6506 - val_loss: 1.1965 - val_accuracy: 0.4751\n",
      "Epoch 27/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7340 - accuracy: 0.6561 - val_loss: 1.1946 - val_accuracy: 0.4751\n",
      "Epoch 28/30\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.7132 - accuracy: 0.6961 - val_loss: 1.2305 - val_accuracy: 0.4641\n",
      "Epoch 29/30\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.7276 - accuracy: 0.6768 - val_loss: 1.2356 - val_accuracy: 0.4530\n",
      "Epoch 30/30\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.7137 - accuracy: 0.6837 - val_loss: 1.2424 - val_accuracy: 0.4475\n",
      "15/15 [==============================] - 1s 4ms/step\n",
      "[2 2 2 0 1 2 0 2 2 1 0 0 2 2 2 2 0 0 2 2 2 2 0 2 2 2 0 1 1 1 2 2 1 0 0 2 2\n",
      " 1 2 2 2 2 2 0 2 2 2 2 1 2 2 2 1 2 2 1 0 2 2 2 0 2 0 1 2 0 1 0 1 0 0 2 1 1\n",
      " 2 1 2 1 2 0 1 1 0 2 1 2 2 0 0 2 1 2 2 2 2 2 1 1 2 1 2 0 1 2 2 0 2 1 2 2 2\n",
      " 2 2 2 2 0 2 2 1 1 2 1 2 0 0 2 2 1 2 1 2 1 2 2 2 2 2 2 2 2 2 0 0 2 0 0 1 0\n",
      " 2 2 0 2 0 1 1 0 2 2 0 2 0 1 2 1 1 1 0 2 1 1 2 2 2 2 0 2 0 1 2 2 2 2 2 2 2\n",
      " 0 0 0 2 2 2 1 1 2 0 2 2 0 2 1 2 2 1 0 2 2 1 0 0 0 2 2 0 2 2 0 2 2 2 2 2 2\n",
      " 2 2 2 0 0 2 2 2 2 2 0 2 2 2 2 2 1 0 0 2 2 1 2 1 2 0 2 2 2 0 1 2 2 2 2 2 2\n",
      " 0 1 0 0 1 1 2 0 0 0 2 2 0 0 2 1 2 1 0 2 2 2 0 2 2 0 2 2 0 0 1 0 2 2 2 1 1\n",
      " 2 0 1 2 1 1 2 2 2 0 1 1 2 1 1 2 2 0 1 1 2 2 1 2 0 1 2 0 2 2 2 0 0 0 2 2 2\n",
      " 2 2 2 1 2 0 2 1 2 2 2 0 2 2 0 2 2 2 0 2 1 1 2 0 2 2 2 2 2 2 2 2 2 0 2 0 2\n",
      " 0 2 1 2 0 2 2 1 2 1 0 2 2 2 2 0 2 2 0 0 1 2 1 0 0 1 2 2 2 1 2 2 2 2 2 1 1\n",
      " 2 0 2 2 2 2 0 0 0 2 2 2 1 0 0 1 2 2 2 0 2 2 1 2 1 0 2 0 1 2 2 0 2 0 2 1 0\n",
      " 1 2 1 0 1 0 1 2 2 2 1 0 0 1 1 2 0 2 2 2 1 1 0 2 1 2 2 2 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "for e in epochs:\n",
    "    for b in batch_sizes:\n",
    "        max_len = get_max_length(df_944601)\n",
    "        val_acc, test_acc = run_lstm(train=df_944601, test=df_944601_test, max_len=max_len,\n",
    "                                                seed=78516, epoch_val=e, b_size=b)\n",
    "        res_df[\"Dataset\"].append(\"78516\")\n",
    "        res_df[\"Seed\"].append(78516)\n",
    "        res_df[\"Epoch\"].append(e)\n",
    "        res_df[\"Batch-Size\"].append(b)\n",
    "        res_df[\"Val-Acc\"].append(val_acc)\n",
    "        res_df[\"Test-Acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Batch-Size</th>\n",
       "      <th>Val-Acc</th>\n",
       "      <th>Test-Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>0.531161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.453039</td>\n",
       "      <td>0.417551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.561834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.430939</td>\n",
       "      <td>0.433983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386740</td>\n",
       "      <td>0.556395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.475138</td>\n",
       "      <td>0.497725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.572305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.441989</td>\n",
       "      <td>0.381459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.616244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.524862</td>\n",
       "      <td>0.593523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.427534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.535912</td>\n",
       "      <td>0.583706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.469613</td>\n",
       "      <td>0.555461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.570432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.456052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.441989</td>\n",
       "      <td>0.457137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.434652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>0.578307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.458564</td>\n",
       "      <td>0.482683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.524862</td>\n",
       "      <td>0.573719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.524862</td>\n",
       "      <td>0.555287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.546961</td>\n",
       "      <td>0.560599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.533558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.588650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.453039</td>\n",
       "      <td>0.455040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.583008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.475138</td>\n",
       "      <td>0.456556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.441989</td>\n",
       "      <td>0.371103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>0.549748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.453039</td>\n",
       "      <td>0.560087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.475389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.450702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.567907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.601211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.592715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>78516</td>\n",
       "      <td>78516</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.557753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset   Seed  Epoch  Batch-Size   Val-Acc  Test-Acc\n",
       "0     5768   5768     10           4  0.480663  0.531161\n",
       "1     5768   5768     10           8  0.453039  0.417551\n",
       "2     5768   5768     10          16  0.491713  0.561834\n",
       "3     5768   5768     10          32  0.430939  0.433983\n",
       "4     5768   5768     20           4  0.386740  0.556395\n",
       "5     5768   5768     20           8  0.475138  0.497725\n",
       "6     5768   5768     20          16  0.519337  0.572305\n",
       "7     5768   5768     20          32  0.441989  0.381459\n",
       "8     5768   5768     30           4  0.502762  0.616244\n",
       "9     5768   5768     30           8  0.524862  0.593523\n",
       "10    5768   5768     30          16  0.447514  0.427534\n",
       "11    5768   5768     30          32  0.535912  0.583706\n",
       "12   78516  78516     10           4  0.469613  0.555461\n",
       "13   78516  78516     10           8  0.519337  0.570432\n",
       "14   78516  78516     10          16  0.502762  0.456052\n",
       "15   78516  78516     10          32  0.441989  0.457137\n",
       "16   78516  78516     20           4  0.519337  0.434652\n",
       "17   78516  78516     20           8  0.508287  0.578307\n",
       "18   78516  78516     20          16  0.458564  0.482683\n",
       "19   78516  78516     20          32  0.524862  0.573719\n",
       "20   78516  78516     30           4  0.524862  0.555287\n",
       "21   78516  78516     30           8  0.546961  0.560599\n",
       "22   78516  78516     30          16  0.552486  0.533558\n",
       "23   78516  78516     30          32  0.519337  0.588650\n",
       "24   78516  78516     10           4  0.453039  0.455040\n",
       "25   78516  78516     10           8  0.552486  0.583008\n",
       "26   78516  78516     10          16  0.475138  0.456556\n",
       "27   78516  78516     10          32  0.441989  0.371103\n",
       "28   78516  78516     20           4  0.480663  0.549748\n",
       "29   78516  78516     20           8  0.453039  0.560087\n",
       "30   78516  78516     20          16  0.491713  0.475389\n",
       "31   78516  78516     20          32  0.447514  0.450702\n",
       "32   78516  78516     30           4  0.541436  0.567907\n",
       "33   78516  78516     30           8  0.447514  0.601211\n",
       "34   78516  78516     30          16  0.491713  0.592715\n",
       "35   78516  78516     30          32  0.447514  0.557753"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check result\n",
    "t = pd.DataFrame(res_df)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Batch-Size</th>\n",
       "      <th>Val-Acc</th>\n",
       "      <th>Test-Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5768</td>\n",
       "      <td>5768</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.616244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Seed  Epoch  Batch-Size   Val-Acc  Test-Acc\n",
       "8    5768  5768     30           4  0.502762  0.616244"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the best result\n",
    "t[t[\"Test-Acc\"] == t[\"Test-Acc\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml135_env_sp23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
